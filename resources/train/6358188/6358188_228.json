{"test_class": {"identifier": "IndexTaskTest", "superclass": "extends IngestionTestBase", "interfaces": "", "fields": [{"original_string": "@Rule\n  public TemporaryFolder temporaryFolder = new TemporaryFolder();", "modifier": "@Rule\n  public", "type": "TemporaryFolder", "declarator": "temporaryFolder = new TemporaryFolder()", "var_name": "temporaryFolder"}, {"original_string": "@Rule\n  public ExpectedException expectedException = ExpectedException.none();", "modifier": "@Rule\n  public", "type": "ExpectedException", "declarator": "expectedException = ExpectedException.none()", "var_name": "expectedException"}, {"original_string": "private static final TimestampSpec DEFAULT_TIMESTAMP_SPEC = new TimestampSpec(\"ts\", \"auto\", null);", "modifier": "private static final", "type": "TimestampSpec", "declarator": "DEFAULT_TIMESTAMP_SPEC = new TimestampSpec(\"ts\", \"auto\", null)", "var_name": "DEFAULT_TIMESTAMP_SPEC"}, {"original_string": "private static final DimensionsSpec DEFAULT_DIMENSIONS_SPEC = new DimensionsSpec(\n      DimensionsSpec.getDefaultSchemas(Arrays.asList(\"ts\", \"dim\"))\n  );", "modifier": "private static final", "type": "DimensionsSpec", "declarator": "DEFAULT_DIMENSIONS_SPEC = new DimensionsSpec(\n      DimensionsSpec.getDefaultSchemas(Arrays.asList(\"ts\", \"dim\"))\n  )", "var_name": "DEFAULT_DIMENSIONS_SPEC"}, {"original_string": "private static final ParseSpec DEFAULT_PARSE_SPEC = new CSVParseSpec(\n      DEFAULT_TIMESTAMP_SPEC,\n      DEFAULT_DIMENSIONS_SPEC,\n      null,\n      Arrays.asList(\"ts\", \"dim\", \"val\"),\n      false,\n      0\n  );", "modifier": "private static final", "type": "ParseSpec", "declarator": "DEFAULT_PARSE_SPEC = new CSVParseSpec(\n      DEFAULT_TIMESTAMP_SPEC,\n      DEFAULT_DIMENSIONS_SPEC,\n      null,\n      Arrays.asList(\"ts\", \"dim\", \"val\"),\n      false,\n      0\n  )", "var_name": "DEFAULT_PARSE_SPEC"}, {"original_string": "private static final InputFormat DEFAULT_INPUT_FORMAT = new CsvInputFormat(\n      Arrays.asList(\"ts\", \"dim\", \"val\"),\n      null,\n      null,\n      false,\n      0\n  );", "modifier": "private static final", "type": "InputFormat", "declarator": "DEFAULT_INPUT_FORMAT = new CsvInputFormat(\n      Arrays.asList(\"ts\", \"dim\", \"val\"),\n      null,\n      null,\n      false,\n      0\n  )", "var_name": "DEFAULT_INPUT_FORMAT"}, {"original_string": "private static final IndexSpec INDEX_SPEC = new IndexSpec();", "modifier": "private static final", "type": "IndexSpec", "declarator": "INDEX_SPEC = new IndexSpec()", "var_name": "INDEX_SPEC"}, {"original_string": "private final ObjectMapper jsonMapper;", "modifier": "private final", "type": "ObjectMapper", "declarator": "jsonMapper", "var_name": "jsonMapper"}, {"original_string": "private final IndexIO indexIO;", "modifier": "private final", "type": "IndexIO", "declarator": "indexIO", "var_name": "indexIO"}, {"original_string": "private final RowIngestionMetersFactory rowIngestionMetersFactory;", "modifier": "private final", "type": "RowIngestionMetersFactory", "declarator": "rowIngestionMetersFactory", "var_name": "rowIngestionMetersFactory"}, {"original_string": "private final LockGranularity lockGranularity;", "modifier": "private final", "type": "LockGranularity", "declarator": "lockGranularity", "var_name": "lockGranularity"}, {"original_string": "private final boolean useInputFormatApi;", "modifier": "private final", "type": "boolean", "declarator": "useInputFormatApi", "var_name": "useInputFormatApi"}, {"original_string": "private AppenderatorsManager appenderatorsManager;", "modifier": "private", "type": "AppenderatorsManager", "declarator": "appenderatorsManager", "var_name": "appenderatorsManager"}, {"original_string": "private SegmentLoader segmentLoader;", "modifier": "private", "type": "SegmentLoader", "declarator": "segmentLoader", "var_name": "segmentLoader"}, {"original_string": "private TestTaskRunner taskRunner;", "modifier": "private", "type": "TestTaskRunner", "declarator": "taskRunner", "var_name": "taskRunner"}], "file": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/IndexTaskTest.java"}, "test_case": {"identifier": "testOverwriteWithSameSegmentGranularity", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testOverwriteWithSameSegmentGranularity() throws Exception\n  {\n    final File tmpDir = temporaryFolder.newFolder();\n    final File tmpFile = File.createTempFile(\"druid\", \"index\", tmpDir);\n\n    populateRollupTestData(tmpFile);\n\n    for (int i = 0; i < 2; i++) {\n      final IndexTask indexTask = new IndexTask(\n          null,\n          null,\n          createDefaultIngestionSpec(\n              jsonMapper,\n              tmpDir,\n              new UniformGranularitySpec(\n                  Granularities.DAY,\n                  Granularities.DAY,\n                  true,\n                  null\n              ),\n              null,\n              createTuningConfig(3, 2, null, 2L, null, false, true),\n              false\n          ),\n          null\n      );\n\n      final List<DataSegment> segments = runTask(indexTask).rhs;\n\n      Assert.assertEquals(5, segments.size());\n\n      final Interval expectedInterval = Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\");\n      for (int j = 0; j < 5; j++) {\n        final DataSegment segment = segments.get(j);\n        Assert.assertEquals(\"test\", segment.getDataSource());\n        Assert.assertEquals(expectedInterval, segment.getInterval());\n        if (i == 0) {\n          Assert.assertEquals(NumberedShardSpec.class, segment.getShardSpec().getClass());\n          Assert.assertEquals(j, segment.getShardSpec().getPartitionNum());\n        } else {\n          if (lockGranularity == LockGranularity.SEGMENT) {\n            Assert.assertEquals(NumberedOverwriteShardSpec.class, segment.getShardSpec().getClass());\n            final NumberedOverwriteShardSpec numberedOverwriteShardSpec =\n                (NumberedOverwriteShardSpec) segment.getShardSpec();\n            Assert.assertEquals(\n                j + PartitionIds.NON_ROOT_GEN_START_PARTITION_ID,\n                numberedOverwriteShardSpec.getPartitionNum()\n            );\n            Assert.assertEquals(1, numberedOverwriteShardSpec.getMinorVersion());\n            Assert.assertEquals(5, numberedOverwriteShardSpec.getAtomicUpdateGroupSize());\n            Assert.assertEquals(0, numberedOverwriteShardSpec.getStartRootPartitionId());\n            Assert.assertEquals(5, numberedOverwriteShardSpec.getEndRootPartitionId());\n          } else {\n            Assert.assertEquals(NumberedShardSpec.class, segment.getShardSpec().getClass());\n            final NumberedShardSpec numberedShardSpec = (NumberedShardSpec) segment.getShardSpec();\n            Assert.assertEquals(j, numberedShardSpec.getPartitionNum());\n          }\n        }\n      }\n    }\n  }", "signature": "void testOverwriteWithSameSegmentGranularity()", "full_signature": "@Test public void testOverwriteWithSameSegmentGranularity()", "class_method_signature": "IndexTaskTest.testOverwriteWithSameSegmentGranularity()", "testcase": true, "constructor": false, "invocations": ["newFolder", "createTempFile", "populateRollupTestData", "createDefaultIngestionSpec", "createTuningConfig", "runTask", "assertEquals", "size", "of", "get", "assertEquals", "getDataSource", "assertEquals", "getInterval", "assertEquals", "getClass", "getShardSpec", "assertEquals", "getPartitionNum", "getShardSpec", "assertEquals", "getClass", "getShardSpec", "getShardSpec", "assertEquals", "getPartitionNum", "assertEquals", "getMinorVersion", "assertEquals", "getAtomicUpdateGroupSize", "assertEquals", "getStartRootPartitionId", "assertEquals", "getEndRootPartitionId", "assertEquals", "getClass", "getShardSpec", "getShardSpec", "assertEquals", "getPartitionNum"]}, "focal_class": {"identifier": "IndexTask", "superclass": "extends AbstractBatchIndexTask", "interfaces": "implements ChatHandler", "fields": [{"original_string": "public static final HashFunction HASH_FUNCTION = Hashing.murmur3_128();", "modifier": "public static final", "type": "HashFunction", "declarator": "HASH_FUNCTION = Hashing.murmur3_128()", "var_name": "HASH_FUNCTION"}, {"original_string": "private static final Logger log = new Logger(IndexTask.class);", "modifier": "private static final", "type": "Logger", "declarator": "log = new Logger(IndexTask.class)", "var_name": "log"}, {"original_string": "private static final String TYPE = \"index\";", "modifier": "private static final", "type": "String", "declarator": "TYPE = \"index\"", "var_name": "TYPE"}, {"original_string": "private final IndexIngestionSpec ingestionSchema;", "modifier": "private final", "type": "IndexIngestionSpec", "declarator": "ingestionSchema", "var_name": "ingestionSchema"}, {"original_string": "private IngestionState ingestionState;", "modifier": "private", "type": "IngestionState", "declarator": "ingestionState", "var_name": "ingestionState"}, {"original_string": "@MonotonicNonNull\n  private ParseExceptionHandler determinePartitionsParseExceptionHandler;", "modifier": "@MonotonicNonNull\n  private", "type": "ParseExceptionHandler", "declarator": "determinePartitionsParseExceptionHandler", "var_name": "determinePartitionsParseExceptionHandler"}, {"original_string": "@MonotonicNonNull\n  private ParseExceptionHandler buildSegmentsParseExceptionHandler;", "modifier": "@MonotonicNonNull\n  private", "type": "ParseExceptionHandler", "declarator": "buildSegmentsParseExceptionHandler", "var_name": "buildSegmentsParseExceptionHandler"}, {"original_string": "@MonotonicNonNull\n  private AuthorizerMapper authorizerMapper;", "modifier": "@MonotonicNonNull\n  private", "type": "AuthorizerMapper", "declarator": "authorizerMapper", "var_name": "authorizerMapper"}, {"original_string": "@MonotonicNonNull\n  private RowIngestionMeters determinePartitionsMeters;", "modifier": "@MonotonicNonNull\n  private", "type": "RowIngestionMeters", "declarator": "determinePartitionsMeters", "var_name": "determinePartitionsMeters"}, {"original_string": "@MonotonicNonNull\n  private RowIngestionMeters buildSegmentsMeters;", "modifier": "@MonotonicNonNull\n  private", "type": "RowIngestionMeters", "declarator": "buildSegmentsMeters", "var_name": "buildSegmentsMeters"}, {"original_string": "@Nullable\n  private String errorMsg;", "modifier": "@Nullable\n  private", "type": "String", "declarator": "errorMsg", "var_name": "errorMsg"}], "methods": [{"identifier": "makeGroupId", "parameters": "(IndexIngestionSpec ingestionSchema)", "modifiers": "private static", "return": "String", "signature": "String makeGroupId(IndexIngestionSpec ingestionSchema)", "full_signature": "private static String makeGroupId(IndexIngestionSpec ingestionSchema)", "class_method_signature": "IndexTask.makeGroupId(IndexIngestionSpec ingestionSchema)", "testcase": false, "constructor": false}, {"identifier": "makeGroupId", "parameters": "(boolean isAppendToExisting, String dataSource)", "modifiers": "private static", "return": "String", "signature": "String makeGroupId(boolean isAppendToExisting, String dataSource)", "full_signature": "private static String makeGroupId(boolean isAppendToExisting, String dataSource)", "class_method_signature": "IndexTask.makeGroupId(boolean isAppendToExisting, String dataSource)", "testcase": false, "constructor": false}, {"identifier": "IndexTask", "parameters": "(\n      @JsonProperty(\"id\") final String id,\n      @JsonProperty(\"resource\") final TaskResource taskResource,\n      @JsonProperty(\"spec\") final IndexIngestionSpec ingestionSchema,\n      @JsonProperty(\"context\") final Map<String, Object> context\n  )", "modifiers": "@JsonCreator public", "return": "", "signature": " IndexTask(\n      @JsonProperty(\"id\") final String id,\n      @JsonProperty(\"resource\") final TaskResource taskResource,\n      @JsonProperty(\"spec\") final IndexIngestionSpec ingestionSchema,\n      @JsonProperty(\"context\") final Map<String, Object> context\n  )", "full_signature": "@JsonCreator public  IndexTask(\n      @JsonProperty(\"id\") final String id,\n      @JsonProperty(\"resource\") final TaskResource taskResource,\n      @JsonProperty(\"spec\") final IndexIngestionSpec ingestionSchema,\n      @JsonProperty(\"context\") final Map<String, Object> context\n  )", "class_method_signature": "IndexTask.IndexTask(\n      @JsonProperty(\"id\") final String id,\n      @JsonProperty(\"resource\") final TaskResource taskResource,\n      @JsonProperty(\"spec\") final IndexIngestionSpec ingestionSchema,\n      @JsonProperty(\"context\") final Map<String, Object> context\n  )", "testcase": false, "constructor": true}, {"identifier": "IndexTask", "parameters": "(\n      String id,\n      String groupId,\n      TaskResource resource,\n      String dataSource,\n      IndexIngestionSpec ingestionSchema,\n      Map<String, Object> context\n  )", "modifiers": "public", "return": "", "signature": " IndexTask(\n      String id,\n      String groupId,\n      TaskResource resource,\n      String dataSource,\n      IndexIngestionSpec ingestionSchema,\n      Map<String, Object> context\n  )", "full_signature": "public  IndexTask(\n      String id,\n      String groupId,\n      TaskResource resource,\n      String dataSource,\n      IndexIngestionSpec ingestionSchema,\n      Map<String, Object> context\n  )", "class_method_signature": "IndexTask.IndexTask(\n      String id,\n      String groupId,\n      TaskResource resource,\n      String dataSource,\n      IndexIngestionSpec ingestionSchema,\n      Map<String, Object> context\n  )", "testcase": false, "constructor": true}, {"identifier": "getType", "parameters": "()", "modifiers": "@Override public", "return": "String", "signature": "String getType()", "full_signature": "@Override public String getType()", "class_method_signature": "IndexTask.getType()", "testcase": false, "constructor": false}, {"identifier": "isReady", "parameters": "(TaskActionClient taskActionClient)", "modifiers": "@Override public", "return": "boolean", "signature": "boolean isReady(TaskActionClient taskActionClient)", "full_signature": "@Override public boolean isReady(TaskActionClient taskActionClient)", "class_method_signature": "IndexTask.isReady(TaskActionClient taskActionClient)", "testcase": false, "constructor": false}, {"identifier": "requireLockExistingSegments", "parameters": "()", "modifiers": "@Override public", "return": "boolean", "signature": "boolean requireLockExistingSegments()", "full_signature": "@Override public boolean requireLockExistingSegments()", "class_method_signature": "IndexTask.requireLockExistingSegments()", "testcase": false, "constructor": false}, {"identifier": "findSegmentsToLock", "parameters": "(TaskActionClient taskActionClient, List<Interval> intervals)", "modifiers": "@Override public", "return": "List<DataSegment>", "signature": "List<DataSegment> findSegmentsToLock(TaskActionClient taskActionClient, List<Interval> intervals)", "full_signature": "@Override public List<DataSegment> findSegmentsToLock(TaskActionClient taskActionClient, List<Interval> intervals)", "class_method_signature": "IndexTask.findSegmentsToLock(TaskActionClient taskActionClient, List<Interval> intervals)", "testcase": false, "constructor": false}, {"identifier": "isPerfectRollup", "parameters": "()", "modifiers": "@Override public", "return": "boolean", "signature": "boolean isPerfectRollup()", "full_signature": "@Override public boolean isPerfectRollup()", "class_method_signature": "IndexTask.isPerfectRollup()", "testcase": false, "constructor": false}, {"identifier": "getSegmentGranularity", "parameters": "()", "modifiers": "@Nullable @Override public", "return": "Granularity", "signature": "Granularity getSegmentGranularity()", "full_signature": "@Nullable @Override public Granularity getSegmentGranularity()", "class_method_signature": "IndexTask.getSegmentGranularity()", "testcase": false, "constructor": false}, {"identifier": "getUnparseableEvents", "parameters": "(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "modifiers": "@GET @Path(\"/unparseableEvents\") @Produces(MediaType.APPLICATION_JSON) public", "return": "Response", "signature": "Response getUnparseableEvents(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "full_signature": "@GET @Path(\"/unparseableEvents\") @Produces(MediaType.APPLICATION_JSON) public Response getUnparseableEvents(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "class_method_signature": "IndexTask.getUnparseableEvents(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "testcase": false, "constructor": false}, {"identifier": "doGetRowStats", "parameters": "(String full)", "modifiers": "private", "return": "Map<String, Object>", "signature": "Map<String, Object> doGetRowStats(String full)", "full_signature": "private Map<String, Object> doGetRowStats(String full)", "class_method_signature": "IndexTask.doGetRowStats(String full)", "testcase": false, "constructor": false}, {"identifier": "getRowStats", "parameters": "(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "modifiers": "@GET @Path(\"/rowStats\") @Produces(MediaType.APPLICATION_JSON) public", "return": "Response", "signature": "Response getRowStats(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "full_signature": "@GET @Path(\"/rowStats\") @Produces(MediaType.APPLICATION_JSON) public Response getRowStats(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "class_method_signature": "IndexTask.getRowStats(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "testcase": false, "constructor": false}, {"identifier": "getLiveReports", "parameters": "(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "modifiers": "@GET @Path(\"/liveReports\") @Produces(MediaType.APPLICATION_JSON) public", "return": "Response", "signature": "Response getLiveReports(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "full_signature": "@GET @Path(\"/liveReports\") @Produces(MediaType.APPLICATION_JSON) public Response getLiveReports(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "class_method_signature": "IndexTask.getLiveReports(\n      @Context final HttpServletRequest req,\n      @QueryParam(\"full\") String full\n  )", "testcase": false, "constructor": false}, {"identifier": "getIngestionSchema", "parameters": "()", "modifiers": "@JsonProperty(\"spec\") public", "return": "IndexIngestionSpec", "signature": "IndexIngestionSpec getIngestionSchema()", "full_signature": "@JsonProperty(\"spec\") public IndexIngestionSpec getIngestionSchema()", "class_method_signature": "IndexTask.getIngestionSchema()", "testcase": false, "constructor": false}, {"identifier": "runTask", "parameters": "(final TaskToolbox toolbox)", "modifiers": "@Override public", "return": "TaskStatus", "signature": "TaskStatus runTask(final TaskToolbox toolbox)", "full_signature": "@Override public TaskStatus runTask(final TaskToolbox toolbox)", "class_method_signature": "IndexTask.runTask(final TaskToolbox toolbox)", "testcase": false, "constructor": false}, {"identifier": "getTaskCompletionReports", "parameters": "()", "modifiers": "private", "return": "Map<String, TaskReport>", "signature": "Map<String, TaskReport> getTaskCompletionReports()", "full_signature": "private Map<String, TaskReport> getTaskCompletionReports()", "class_method_signature": "IndexTask.getTaskCompletionReports()", "testcase": false, "constructor": false}, {"identifier": "getTaskCompletionUnparseableEvents", "parameters": "()", "modifiers": "private", "return": "Map<String, Object>", "signature": "Map<String, Object> getTaskCompletionUnparseableEvents()", "full_signature": "private Map<String, Object> getTaskCompletionUnparseableEvents()", "class_method_signature": "IndexTask.getTaskCompletionUnparseableEvents()", "testcase": false, "constructor": false}, {"identifier": "getTaskCompletionRowStats", "parameters": "()", "modifiers": "private", "return": "Map<String, Object>", "signature": "Map<String, Object> getTaskCompletionRowStats()", "full_signature": "private Map<String, Object> getTaskCompletionRowStats()", "class_method_signature": "IndexTask.getTaskCompletionRowStats()", "testcase": false, "constructor": false}, {"identifier": "determineShardSpecs", "parameters": "(\n      final TaskToolbox toolbox,\n      final InputSource inputSource,\n      final File tmpDir,\n      @Nonnull final PartitionsSpec partitionsSpec\n  )", "modifiers": "private", "return": "PartitionAnalysis", "signature": "PartitionAnalysis determineShardSpecs(\n      final TaskToolbox toolbox,\n      final InputSource inputSource,\n      final File tmpDir,\n      @Nonnull final PartitionsSpec partitionsSpec\n  )", "full_signature": "private PartitionAnalysis determineShardSpecs(\n      final TaskToolbox toolbox,\n      final InputSource inputSource,\n      final File tmpDir,\n      @Nonnull final PartitionsSpec partitionsSpec\n  )", "class_method_signature": "IndexTask.determineShardSpecs(\n      final TaskToolbox toolbox,\n      final InputSource inputSource,\n      final File tmpDir,\n      @Nonnull final PartitionsSpec partitionsSpec\n  )", "testcase": false, "constructor": false}, {"identifier": "createLinearPartitionAnalysis", "parameters": "(\n      GranularitySpec granularitySpec,\n      @Nonnull DynamicPartitionsSpec partitionsSpec\n  )", "modifiers": "private static", "return": "LinearPartitionAnalysis", "signature": "LinearPartitionAnalysis createLinearPartitionAnalysis(\n      GranularitySpec granularitySpec,\n      @Nonnull DynamicPartitionsSpec partitionsSpec\n  )", "full_signature": "private static LinearPartitionAnalysis createLinearPartitionAnalysis(\n      GranularitySpec granularitySpec,\n      @Nonnull DynamicPartitionsSpec partitionsSpec\n  )", "class_method_signature": "IndexTask.createLinearPartitionAnalysis(\n      GranularitySpec granularitySpec,\n      @Nonnull DynamicPartitionsSpec partitionsSpec\n  )", "testcase": false, "constructor": false}, {"identifier": "createShardSpecsFromInput", "parameters": "(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "modifiers": "private", "return": "PartitionAnalysis", "signature": "PartitionAnalysis createShardSpecsFromInput(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "full_signature": "private PartitionAnalysis createShardSpecsFromInput(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "class_method_signature": "IndexTask.createShardSpecsFromInput(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "testcase": false, "constructor": false}, {"identifier": "collectIntervalsAndShardSpecs", "parameters": "(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "modifiers": "private", "return": "Map<Interval, Optional<HyperLogLogCollector>>", "signature": "Map<Interval, Optional<HyperLogLogCollector>> collectIntervalsAndShardSpecs(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "full_signature": "private Map<Interval, Optional<HyperLogLogCollector>> collectIntervalsAndShardSpecs(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "class_method_signature": "IndexTask.collectIntervalsAndShardSpecs(\n      ObjectMapper jsonMapper,\n      IndexIngestionSpec ingestionSchema,\n      InputSource inputSource,\n      File tmpDir,\n      GranularitySpec granularitySpec,\n      @Nonnull PartitionsSpec partitionsSpec,\n      boolean determineIntervals\n  )", "testcase": false, "constructor": false}, {"identifier": "generateAndPublishSegments", "parameters": "(\n      final TaskToolbox toolbox,\n      final DataSchema dataSchema,\n      final InputSource inputSource,\n      final File tmpDir,\n      final PartitionAnalysis partitionAnalysis\n  )", "modifiers": "private", "return": "TaskStatus", "signature": "TaskStatus generateAndPublishSegments(\n      final TaskToolbox toolbox,\n      final DataSchema dataSchema,\n      final InputSource inputSource,\n      final File tmpDir,\n      final PartitionAnalysis partitionAnalysis\n  )", "full_signature": "private TaskStatus generateAndPublishSegments(\n      final TaskToolbox toolbox,\n      final DataSchema dataSchema,\n      final InputSource inputSource,\n      final File tmpDir,\n      final PartitionAnalysis partitionAnalysis\n  )", "class_method_signature": "IndexTask.generateAndPublishSegments(\n      final TaskToolbox toolbox,\n      final DataSchema dataSchema,\n      final InputSource inputSource,\n      final File tmpDir,\n      final PartitionAnalysis partitionAnalysis\n  )", "testcase": false, "constructor": false}, {"identifier": "awaitPublish", "parameters": "(\n      ListenableFuture<SegmentsAndCommitMetadata> publishFuture,\n      long publishTimeout\n  )", "modifiers": "private static", "return": "SegmentsAndCommitMetadata", "signature": "SegmentsAndCommitMetadata awaitPublish(\n      ListenableFuture<SegmentsAndCommitMetadata> publishFuture,\n      long publishTimeout\n  )", "full_signature": "private static SegmentsAndCommitMetadata awaitPublish(\n      ListenableFuture<SegmentsAndCommitMetadata> publishFuture,\n      long publishTimeout\n  )", "class_method_signature": "IndexTask.awaitPublish(\n      ListenableFuture<SegmentsAndCommitMetadata> publishFuture,\n      long publishTimeout\n  )", "testcase": false, "constructor": false}, {"identifier": "getInputFormat", "parameters": "(IndexIngestionSpec ingestionSchema)", "modifiers": "private static", "return": "InputFormat", "signature": "InputFormat getInputFormat(IndexIngestionSpec ingestionSchema)", "full_signature": "private static InputFormat getInputFormat(IndexIngestionSpec ingestionSchema)", "class_method_signature": "IndexTask.getInputFormat(IndexIngestionSpec ingestionSchema)", "testcase": false, "constructor": false}], "file": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java"}, "focal_method": {"identifier": "runTask", "parameters": "(final TaskToolbox toolbox)", "modifiers": "@Override public", "return": "TaskStatus", "body": "@Override\n  public TaskStatus runTask(final TaskToolbox toolbox)\n  {\n    try {\n      log.debug(\"Found chat handler of class[%s]\", toolbox.getChatHandlerProvider().getClass().getName());\n\n      if (toolbox.getChatHandlerProvider().get(getId()).isPresent()) {\n        // This is a workaround for ParallelIndexSupervisorTask to avoid double registering when it runs in the\n        // sequential mode. See ParallelIndexSupervisorTask.runSequential().\n        // Note that all HTTP endpoints are not available in this case. This works only for\n        // ParallelIndexSupervisorTask because it doesn't support APIs for live ingestion reports.\n        log.warn(\"Chat handler is already registered. Skipping chat handler registration.\");\n      } else {\n        toolbox.getChatHandlerProvider().register(getId(), this, false);\n      }\n\n      this.authorizerMapper = toolbox.getAuthorizerMapper();\n      this.determinePartitionsMeters = toolbox.getRowIngestionMetersFactory().createRowIngestionMeters();\n      this.buildSegmentsMeters = toolbox.getRowIngestionMetersFactory().createRowIngestionMeters();\n      this.determinePartitionsParseExceptionHandler = new ParseExceptionHandler(\n          determinePartitionsMeters,\n          ingestionSchema.getTuningConfig().isLogParseExceptions(),\n          ingestionSchema.getTuningConfig().getMaxParseExceptions(),\n          ingestionSchema.getTuningConfig().getMaxSavedParseExceptions()\n      );\n      this.buildSegmentsParseExceptionHandler = new ParseExceptionHandler(\n          buildSegmentsMeters,\n          ingestionSchema.getTuningConfig().isLogParseExceptions(),\n          ingestionSchema.getTuningConfig().getMaxParseExceptions(),\n          ingestionSchema.getTuningConfig().getMaxSavedParseExceptions()\n      );\n\n      final boolean determineIntervals = !ingestionSchema.getDataSchema()\n                                                         .getGranularitySpec()\n                                                         .bucketIntervals()\n                                                         .isPresent();\n\n      final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n          ingestionSchema.getDataSchema().getParser()\n      );\n\n      final File tmpDir = toolbox.getIndexingTmpDir();\n\n      ingestionState = IngestionState.DETERMINE_PARTITIONS;\n\n      // Initialize maxRowsPerSegment and maxTotalRows lazily\n      final IndexTuningConfig tuningConfig = ingestionSchema.tuningConfig;\n      final PartitionsSpec partitionsSpec = tuningConfig.getGivenOrDefaultPartitionsSpec();\n      final PartitionAnalysis partitionAnalysis = determineShardSpecs(\n          toolbox,\n          inputSource,\n          tmpDir,\n          partitionsSpec\n      );\n      final List<Interval> allocateIntervals = new ArrayList<>(partitionAnalysis.getAllIntervalsToIndex());\n      final DataSchema dataSchema;\n      if (determineIntervals) {\n        if (!determineLockGranularityandTryLock(toolbox.getTaskActionClient(), allocateIntervals)) {\n          throw new ISE(\"Failed to get locks for intervals[%s]\", allocateIntervals);\n        }\n\n        dataSchema = ingestionSchema.getDataSchema().withGranularitySpec(\n            ingestionSchema.getDataSchema()\n                           .getGranularitySpec()\n                           .withIntervals(JodaUtils.condenseIntervals(allocateIntervals))\n        );\n      } else {\n        dataSchema = ingestionSchema.getDataSchema();\n      }\n\n      ingestionState = IngestionState.BUILD_SEGMENTS;\n      return generateAndPublishSegments(\n          toolbox,\n          dataSchema,\n          inputSource,\n          tmpDir,\n          partitionAnalysis\n      );\n    }\n    catch (Exception e) {\n      log.error(e, \"Encountered exception in %s.\", ingestionState);\n      errorMsg = Throwables.getStackTraceAsString(e);\n      toolbox.getTaskReportFileWriter().write(getId(), getTaskCompletionReports());\n      return TaskStatus.failure(\n          getId(),\n          errorMsg\n      );\n    }\n\n    finally {\n      toolbox.getChatHandlerProvider().unregister(getId());\n    }\n  }", "signature": "TaskStatus runTask(final TaskToolbox toolbox)", "full_signature": "@Override public TaskStatus runTask(final TaskToolbox toolbox)", "class_method_signature": "IndexTask.runTask(final TaskToolbox toolbox)", "testcase": false, "constructor": false, "invocations": ["debug", "getName", "getClass", "getChatHandlerProvider", "isPresent", "get", "getChatHandlerProvider", "getId", "warn", "register", "getChatHandlerProvider", "getId", "getAuthorizerMapper", "createRowIngestionMeters", "getRowIngestionMetersFactory", "createRowIngestionMeters", "getRowIngestionMetersFactory", "isLogParseExceptions", "getTuningConfig", "getMaxParseExceptions", "getTuningConfig", "getMaxSavedParseExceptions", "getTuningConfig", "isLogParseExceptions", "getTuningConfig", "getMaxParseExceptions", "getTuningConfig", "getMaxSavedParseExceptions", "getTuningConfig", "isPresent", "bucketIntervals", "getGranularitySpec", "getDataSchema", "getNonNullInputSource", "getIOConfig", "getParser", "getDataSchema", "getIndexingTmpDir", "getGivenOrDefaultPartitionsSpec", "determineShardSpecs", "getAllIntervalsToIndex", "determineLockGranularityandTryLock", "getTaskActionClient", "withGranularitySpec", "getDataSchema", "withIntervals", "getGranularitySpec", "getDataSchema", "condenseIntervals", "getDataSchema", "generateAndPublishSegments", "error", "getStackTraceAsString", "write", "getTaskReportFileWriter", "getId", "getTaskCompletionReports", "failure", "getId", "unregister", "getChatHandlerProvider", "getId"]}, "repository": {"repo_id": 6358188, "url": "https://github.com/apache/druid", "stars": 9116, "created": "10/23/2012 7:08:07 PM +00:00", "updates": "2020-01-27T21:36:20+00:00", "fork": "False", "license": "licensed"}}