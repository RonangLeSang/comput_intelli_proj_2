{"test_class": {"identifier": "KafkaSupervisorTest", "superclass": "extends EasyMockSupport", "interfaces": "", "fields": [{"original_string": "private static final ObjectMapper OBJECT_MAPPER = TestHelper.makeJsonMapper();", "modifier": "private static final", "type": "ObjectMapper", "declarator": "OBJECT_MAPPER = TestHelper.makeJsonMapper()", "var_name": "OBJECT_MAPPER"}, {"original_string": "private static final InputFormat INPUT_FORMAT = new JsonInputFormat(\n      new JSONPathSpec(true, ImmutableList.of()),\n      ImmutableMap.of(),\n      false\n  );", "modifier": "private static final", "type": "InputFormat", "declarator": "INPUT_FORMAT = new JsonInputFormat(\n      new JSONPathSpec(true, ImmutableList.of()),\n      ImmutableMap.of(),\n      false\n  )", "var_name": "INPUT_FORMAT"}, {"original_string": "private static final String TOPIC_PREFIX = \"testTopic\";", "modifier": "private static final", "type": "String", "declarator": "TOPIC_PREFIX = \"testTopic\"", "var_name": "TOPIC_PREFIX"}, {"original_string": "private static final String DATASOURCE = \"testDS\";", "modifier": "private static final", "type": "String", "declarator": "DATASOURCE = \"testDS\"", "var_name": "DATASOURCE"}, {"original_string": "private static final int NUM_PARTITIONS = 3;", "modifier": "private static final", "type": "int", "declarator": "NUM_PARTITIONS = 3", "var_name": "NUM_PARTITIONS"}, {"original_string": "private static final int TEST_CHAT_THREADS = 3;", "modifier": "private static final", "type": "int", "declarator": "TEST_CHAT_THREADS = 3", "var_name": "TEST_CHAT_THREADS"}, {"original_string": "private static final long TEST_CHAT_RETRIES = 9L;", "modifier": "private static final", "type": "long", "declarator": "TEST_CHAT_RETRIES = 9L", "var_name": "TEST_CHAT_RETRIES"}, {"original_string": "private static final Period TEST_HTTP_TIMEOUT = new Period(\"PT10S\");", "modifier": "private static final", "type": "Period", "declarator": "TEST_HTTP_TIMEOUT = new Period(\"PT10S\")", "var_name": "TEST_HTTP_TIMEOUT"}, {"original_string": "private static final Period TEST_SHUTDOWN_TIMEOUT = new Period(\"PT80S\");", "modifier": "private static final", "type": "Period", "declarator": "TEST_SHUTDOWN_TIMEOUT = new Period(\"PT80S\")", "var_name": "TEST_SHUTDOWN_TIMEOUT"}, {"original_string": "private static TestingCluster zkServer;", "modifier": "private static", "type": "TestingCluster", "declarator": "zkServer", "var_name": "zkServer"}, {"original_string": "private static TestBroker kafkaServer;", "modifier": "private static", "type": "TestBroker", "declarator": "kafkaServer", "var_name": "kafkaServer"}, {"original_string": "private static String kafkaHost;", "modifier": "private static", "type": "String", "declarator": "kafkaHost", "var_name": "kafkaHost"}, {"original_string": "private static DataSchema dataSchema;", "modifier": "private static", "type": "DataSchema", "declarator": "dataSchema", "var_name": "dataSchema"}, {"original_string": "private static int topicPostfix;", "modifier": "private static", "type": "int", "declarator": "topicPostfix", "var_name": "topicPostfix"}, {"original_string": "private final int numThreads;", "modifier": "private final", "type": "int", "declarator": "numThreads", "var_name": "numThreads"}, {"original_string": "private TestableKafkaSupervisor supervisor;", "modifier": "private", "type": "TestableKafkaSupervisor", "declarator": "supervisor", "var_name": "supervisor"}, {"original_string": "private TaskStorage taskStorage;", "modifier": "private", "type": "TaskStorage", "declarator": "taskStorage", "var_name": "taskStorage"}, {"original_string": "private TaskMaster taskMaster;", "modifier": "private", "type": "TaskMaster", "declarator": "taskMaster", "var_name": "taskMaster"}, {"original_string": "private TaskRunner taskRunner;", "modifier": "private", "type": "TaskRunner", "declarator": "taskRunner", "var_name": "taskRunner"}, {"original_string": "private IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator;", "modifier": "private", "type": "IndexerMetadataStorageCoordinator", "declarator": "indexerMetadataStorageCoordinator", "var_name": "indexerMetadataStorageCoordinator"}, {"original_string": "private KafkaIndexTaskClient taskClient;", "modifier": "private", "type": "KafkaIndexTaskClient", "declarator": "taskClient", "var_name": "taskClient"}, {"original_string": "private TaskQueue taskQueue;", "modifier": "private", "type": "TaskQueue", "declarator": "taskQueue", "var_name": "taskQueue"}, {"original_string": "private String topic;", "modifier": "private", "type": "String", "declarator": "topic", "var_name": "topic"}, {"original_string": "private RowIngestionMetersFactory rowIngestionMetersFactory;", "modifier": "private", "type": "RowIngestionMetersFactory", "declarator": "rowIngestionMetersFactory", "var_name": "rowIngestionMetersFactory"}, {"original_string": "private ExceptionCapturingServiceEmitter serviceEmitter;", "modifier": "private", "type": "ExceptionCapturingServiceEmitter", "declarator": "serviceEmitter", "var_name": "serviceEmitter"}, {"original_string": "private SupervisorStateManagerConfig supervisorConfig;", "modifier": "private", "type": "SupervisorStateManagerConfig", "declarator": "supervisorConfig", "var_name": "supervisorConfig"}], "file": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java"}, "test_case": {"identifier": "testDoNotKillCompatibleTasks", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testDoNotKillCompatibleTasks()\n      throws Exception\n  {\n    // This supervisor always returns true for isTaskCurrent -> it should not kill its tasks\n    int numReplicas = 2;\n    supervisor = getTestableSupervisorCustomIsTaskCurrent(\n        numReplicas,\n        1,\n        true,\n        \"PT1H\",\n        new Period(\"P1D\"),\n        new Period(\"P1D\"),\n        false,\n        true\n    );\n\n    addSomeEvents(1);\n\n    Task task = createKafkaIndexTask(\n        \"id1\",\n        DATASOURCE,\n        0,\n        new SeekableStreamStartSequenceNumbers<>(\n            \"topic\",\n            ImmutableMap.of(0, 0L, 2, 0L),\n            ImmutableSet.of()\n        ),\n        new SeekableStreamEndSequenceNumbers<>(\n            \"topic\",\n            ImmutableMap.of(0, Long.MAX_VALUE, 2, Long.MAX_VALUE)\n        ),\n        null,\n        null,\n        supervisor.getTuningConfig()\n    );\n\n    List<Task> existingTasks = ImmutableList.of(task);\n\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskRunner.getRunningTasks()).andReturn(Collections.emptyList()).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(existingTasks).anyTimes();\n    EasyMock.expect(taskStorage.getStatus(\"id1\")).andReturn(Optional.of(TaskStatus.running(\"id1\"))).anyTimes();\n    EasyMock.expect(taskStorage.getTask(\"id1\")).andReturn(Optional.of(task)).anyTimes();\n    EasyMock.expect(taskClient.getStatusAsync(EasyMock.anyString()))\n            .andReturn(Futures.immediateFuture(Status.NOT_STARTED))\n            .anyTimes();\n    EasyMock.expect(taskClient.getStartTimeAsync(EasyMock.anyString()))\n            .andReturn(Futures.immediateFuture(DateTimes.nowUtc()))\n            .anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    EasyMock.expect(taskQueue.add(EasyMock.anyObject(Task.class))).andReturn(true);\n\n    TreeMap<Integer, Map<Integer, Long>> checkpoints1 = new TreeMap<>();\n    checkpoints1.put(0, ImmutableMap.of(0, 0L, 2, 0L));\n\n    EasyMock.expect(taskClient.getCheckpointsAsync(EasyMock.contains(\"id1\"), EasyMock.anyBoolean()))\n            .andReturn(Futures.immediateFuture(checkpoints1))\n            .times(numReplicas);\n\n    replayAll();\n    supervisor.start();\n    supervisor.runInternal();\n    verifyAll();\n  }", "signature": "void testDoNotKillCompatibleTasks()", "full_signature": "@Test public void testDoNotKillCompatibleTasks()", "class_method_signature": "KafkaSupervisorTest.testDoNotKillCompatibleTasks()", "testcase": true, "constructor": false, "invocations": ["getTestableSupervisorCustomIsTaskCurrent", "addSomeEvents", "createKafkaIndexTask", "of", "of", "of", "getTuningConfig", "of", "anyTimes", "andReturn", "expect", "getTaskQueue", "of", "anyTimes", "andReturn", "expect", "getTaskRunner", "of", "anyTimes", "andReturn", "expect", "getRunningTasks", "emptyList", "anyTimes", "andReturn", "expect", "getActiveTasksByDatasource", "anyTimes", "andReturn", "expect", "getStatus", "of", "running", "anyTimes", "andReturn", "expect", "getTask", "of", "anyTimes", "andReturn", "expect", "getStatusAsync", "anyString", "immediateFuture", "anyTimes", "andReturn", "expect", "getStartTimeAsync", "anyString", "immediateFuture", "nowUtc", "anyTimes", "andReturn", "expect", "retrieveDataSourceMetadata", "registerListener", "anyObject", "anyObject", "andReturn", "expect", "add", "anyObject", "put", "of", "times", "andReturn", "expect", "getCheckpointsAsync", "contains", "anyBoolean", "immediateFuture", "replayAll", "start", "runInternal", "verifyAll"]}, "focal_class": {"identifier": "KafkaSupervisor", "superclass": "extends SeekableStreamSupervisor<Integer, Long>", "interfaces": "", "fields": [{"original_string": "public static final TypeReference<TreeMap<Integer, Map<Integer, Long>>> CHECKPOINTS_TYPE_REF =\n      new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n      {\n      };", "modifier": "public static final", "type": "TypeReference<TreeMap<Integer, Map<Integer, Long>>>", "declarator": "CHECKPOINTS_TYPE_REF =\n      new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n      {\n      }", "var_name": "CHECKPOINTS_TYPE_REF"}, {"original_string": "private static final EmittingLogger log = new EmittingLogger(KafkaSupervisor.class);", "modifier": "private static final", "type": "EmittingLogger", "declarator": "log = new EmittingLogger(KafkaSupervisor.class)", "var_name": "log"}, {"original_string": "private static final Long NOT_SET = -1L;", "modifier": "private static final", "type": "Long", "declarator": "NOT_SET = -1L", "var_name": "NOT_SET"}, {"original_string": "private static final Long END_OF_PARTITION = Long.MAX_VALUE;", "modifier": "private static final", "type": "Long", "declarator": "END_OF_PARTITION = Long.MAX_VALUE", "var_name": "END_OF_PARTITION"}, {"original_string": "private final ServiceEmitter emitter;", "modifier": "private final", "type": "ServiceEmitter", "declarator": "emitter", "var_name": "emitter"}, {"original_string": "private final DruidMonitorSchedulerConfig monitorSchedulerConfig;", "modifier": "private final", "type": "DruidMonitorSchedulerConfig", "declarator": "monitorSchedulerConfig", "var_name": "monitorSchedulerConfig"}, {"original_string": "private volatile Map<Integer, Long> latestSequenceFromStream;", "modifier": "private volatile", "type": "Map<Integer, Long>", "declarator": "latestSequenceFromStream", "var_name": "latestSequenceFromStream"}, {"original_string": "private final KafkaSupervisorSpec spec;", "modifier": "private final", "type": "KafkaSupervisorSpec", "declarator": "spec", "var_name": "spec"}], "methods": [{"identifier": "KafkaSupervisor", "parameters": "(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "modifiers": "public", "return": "", "signature": " KafkaSupervisor(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "full_signature": "public  KafkaSupervisor(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "class_method_signature": "KafkaSupervisor.KafkaSupervisor(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "testcase": false, "constructor": true}, {"identifier": "setupRecordSupplier", "parameters": "()", "modifiers": "@Override protected", "return": "RecordSupplier<Integer, Long>", "signature": "RecordSupplier<Integer, Long> setupRecordSupplier()", "full_signature": "@Override protected RecordSupplier<Integer, Long> setupRecordSupplier()", "class_method_signature": "KafkaSupervisor.setupRecordSupplier()", "testcase": false, "constructor": false}, {"identifier": "getTaskGroupIdForPartition", "parameters": "(Integer partitionId)", "modifiers": "@Override protected", "return": "int", "signature": "int getTaskGroupIdForPartition(Integer partitionId)", "full_signature": "@Override protected int getTaskGroupIdForPartition(Integer partitionId)", "class_method_signature": "KafkaSupervisor.getTaskGroupIdForPartition(Integer partitionId)", "testcase": false, "constructor": false}, {"identifier": "checkSourceMetadataMatch", "parameters": "(DataSourceMetadata metadata)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean checkSourceMetadataMatch(DataSourceMetadata metadata)", "full_signature": "@Override protected boolean checkSourceMetadataMatch(DataSourceMetadata metadata)", "class_method_signature": "KafkaSupervisor.checkSourceMetadataMatch(DataSourceMetadata metadata)", "testcase": false, "constructor": false}, {"identifier": "doesTaskTypeMatchSupervisor", "parameters": "(Task task)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean doesTaskTypeMatchSupervisor(Task task)", "full_signature": "@Override protected boolean doesTaskTypeMatchSupervisor(Task task)", "class_method_signature": "KafkaSupervisor.doesTaskTypeMatchSupervisor(Task task)", "testcase": false, "constructor": false}, {"identifier": "createReportPayload", "parameters": "(\n      int numPartitions,\n      boolean includeOffsets\n  )", "modifiers": "@Override protected", "return": "SeekableStreamSupervisorReportPayload<Integer, Long>", "signature": "SeekableStreamSupervisorReportPayload<Integer, Long> createReportPayload(\n      int numPartitions,\n      boolean includeOffsets\n  )", "full_signature": "@Override protected SeekableStreamSupervisorReportPayload<Integer, Long> createReportPayload(\n      int numPartitions,\n      boolean includeOffsets\n  )", "class_method_signature": "KafkaSupervisor.createReportPayload(\n      int numPartitions,\n      boolean includeOffsets\n  )", "testcase": false, "constructor": false}, {"identifier": "createTaskIoConfig", "parameters": "(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "modifiers": "@Override protected", "return": "SeekableStreamIndexTaskIOConfig", "signature": "SeekableStreamIndexTaskIOConfig createTaskIoConfig(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "full_signature": "@Override protected SeekableStreamIndexTaskIOConfig createTaskIoConfig(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "class_method_signature": "KafkaSupervisor.createTaskIoConfig(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "testcase": false, "constructor": false}, {"identifier": "createIndexTasks", "parameters": "(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "modifiers": "@Override protected", "return": "List<SeekableStreamIndexTask<Integer, Long>>", "signature": "List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "full_signature": "@Override protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "class_method_signature": "KafkaSupervisor.createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "testcase": false, "constructor": false}, {"identifier": "getPartitionRecordLag", "parameters": "()", "modifiers": "@Override protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getPartitionRecordLag()", "full_signature": "@Override protected Map<Integer, Long> getPartitionRecordLag()", "class_method_signature": "KafkaSupervisor.getPartitionRecordLag()", "testcase": false, "constructor": false}, {"identifier": "getPartitionTimeLag", "parameters": "()", "modifiers": "@Nullable @Override protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getPartitionTimeLag()", "full_signature": "@Nullable @Override protected Map<Integer, Long> getPartitionTimeLag()", "class_method_signature": "KafkaSupervisor.getPartitionTimeLag()", "testcase": false, "constructor": false}, {"identifier": "getRecordLagPerPartition", "parameters": "(Map<Integer, Long> currentOffsets)", "modifiers": "@Override // suppress use of CollectionUtils.mapValues() since the valueMapper function is dependent on map key here @SuppressWarnings(\"SSBasedInspection\") protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getRecordLagPerPartition(Map<Integer, Long> currentOffsets)", "full_signature": "@Override // suppress use of CollectionUtils.mapValues() since the valueMapper function is dependent on map key here @SuppressWarnings(\"SSBasedInspection\") protected Map<Integer, Long> getRecordLagPerPartition(Map<Integer, Long> currentOffsets)", "class_method_signature": "KafkaSupervisor.getRecordLagPerPartition(Map<Integer, Long> currentOffsets)", "testcase": false, "constructor": false}, {"identifier": "getTimeLagPerPartition", "parameters": "(Map<Integer, Long> currentOffsets)", "modifiers": "@Override protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getTimeLagPerPartition(Map<Integer, Long> currentOffsets)", "full_signature": "@Override protected Map<Integer, Long> getTimeLagPerPartition(Map<Integer, Long> currentOffsets)", "class_method_signature": "KafkaSupervisor.getTimeLagPerPartition(Map<Integer, Long> currentOffsets)", "testcase": false, "constructor": false}, {"identifier": "createDataSourceMetaDataForReset", "parameters": "(String topic, Map<Integer, Long> map)", "modifiers": "@Override protected", "return": "KafkaDataSourceMetadata", "signature": "KafkaDataSourceMetadata createDataSourceMetaDataForReset(String topic, Map<Integer, Long> map)", "full_signature": "@Override protected KafkaDataSourceMetadata createDataSourceMetaDataForReset(String topic, Map<Integer, Long> map)", "class_method_signature": "KafkaSupervisor.createDataSourceMetaDataForReset(String topic, Map<Integer, Long> map)", "testcase": false, "constructor": false}, {"identifier": "makeSequenceNumber", "parameters": "(Long seq, boolean isExclusive)", "modifiers": "@Override protected", "return": "OrderedSequenceNumber<Long>", "signature": "OrderedSequenceNumber<Long> makeSequenceNumber(Long seq, boolean isExclusive)", "full_signature": "@Override protected OrderedSequenceNumber<Long> makeSequenceNumber(Long seq, boolean isExclusive)", "class_method_signature": "KafkaSupervisor.makeSequenceNumber(Long seq, boolean isExclusive)", "testcase": false, "constructor": false}, {"identifier": "getNotSetMarker", "parameters": "()", "modifiers": "@Override protected", "return": "Long", "signature": "Long getNotSetMarker()", "full_signature": "@Override protected Long getNotSetMarker()", "class_method_signature": "KafkaSupervisor.getNotSetMarker()", "testcase": false, "constructor": false}, {"identifier": "getEndOfPartitionMarker", "parameters": "()", "modifiers": "@Override protected", "return": "Long", "signature": "Long getEndOfPartitionMarker()", "full_signature": "@Override protected Long getEndOfPartitionMarker()", "class_method_signature": "KafkaSupervisor.getEndOfPartitionMarker()", "testcase": false, "constructor": false}, {"identifier": "isEndOfShard", "parameters": "(Long seqNum)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean isEndOfShard(Long seqNum)", "full_signature": "@Override protected boolean isEndOfShard(Long seqNum)", "class_method_signature": "KafkaSupervisor.isEndOfShard(Long seqNum)", "testcase": false, "constructor": false}, {"identifier": "isShardExpirationMarker", "parameters": "(Long seqNum)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean isShardExpirationMarker(Long seqNum)", "full_signature": "@Override protected boolean isShardExpirationMarker(Long seqNum)", "class_method_signature": "KafkaSupervisor.isShardExpirationMarker(Long seqNum)", "testcase": false, "constructor": false}, {"identifier": "useExclusiveStartSequenceNumberForNonFirstSequence", "parameters": "()", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean useExclusiveStartSequenceNumberForNonFirstSequence()", "full_signature": "@Override protected boolean useExclusiveStartSequenceNumberForNonFirstSequence()", "class_method_signature": "KafkaSupervisor.useExclusiveStartSequenceNumberForNonFirstSequence()", "testcase": false, "constructor": false}, {"identifier": "updatePartitionLagFromStream", "parameters": "()", "modifiers": "@Override protected", "return": "void", "signature": "void updatePartitionLagFromStream()", "full_signature": "@Override protected void updatePartitionLagFromStream()", "class_method_signature": "KafkaSupervisor.updatePartitionLagFromStream()", "testcase": false, "constructor": false}, {"identifier": "baseTaskName", "parameters": "()", "modifiers": "@Override protected", "return": "String", "signature": "String baseTaskName()", "full_signature": "@Override protected String baseTaskName()", "class_method_signature": "KafkaSupervisor.baseTaskName()", "testcase": false, "constructor": false}, {"identifier": "getIoConfig", "parameters": "()", "modifiers": "@Override @VisibleForTesting public", "return": "KafkaSupervisorIOConfig", "signature": "KafkaSupervisorIOConfig getIoConfig()", "full_signature": "@Override @VisibleForTesting public KafkaSupervisorIOConfig getIoConfig()", "class_method_signature": "KafkaSupervisor.getIoConfig()", "testcase": false, "constructor": false}, {"identifier": "getTuningConfig", "parameters": "()", "modifiers": "@VisibleForTesting public", "return": "KafkaSupervisorTuningConfig", "signature": "KafkaSupervisorTuningConfig getTuningConfig()", "full_signature": "@VisibleForTesting public KafkaSupervisorTuningConfig getTuningConfig()", "class_method_signature": "KafkaSupervisor.getTuningConfig()", "testcase": false, "constructor": false}], "file": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java"}, "focal_method": {"identifier": "getTuningConfig", "parameters": "()", "modifiers": "@VisibleForTesting public", "return": "KafkaSupervisorTuningConfig", "body": "@VisibleForTesting\n  public KafkaSupervisorTuningConfig getTuningConfig()\n  {\n    return spec.getTuningConfig();\n  }", "signature": "KafkaSupervisorTuningConfig getTuningConfig()", "full_signature": "@VisibleForTesting public KafkaSupervisorTuningConfig getTuningConfig()", "class_method_signature": "KafkaSupervisor.getTuningConfig()", "testcase": false, "constructor": false, "invocations": ["getTuningConfig"]}, "repository": {"repo_id": 6358188, "url": "https://github.com/apache/druid", "stars": 9116, "created": "10/23/2012 7:08:07 PM +00:00", "updates": "2020-01-27T21:36:20+00:00", "fork": "False", "license": "licensed"}}