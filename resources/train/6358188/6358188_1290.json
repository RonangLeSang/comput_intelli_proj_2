{"test_class": {"identifier": "KafkaSupervisorTest", "superclass": "extends EasyMockSupport", "interfaces": "", "fields": [{"original_string": "private static final ObjectMapper OBJECT_MAPPER = TestHelper.makeJsonMapper();", "modifier": "private static final", "type": "ObjectMapper", "declarator": "OBJECT_MAPPER = TestHelper.makeJsonMapper()", "var_name": "OBJECT_MAPPER"}, {"original_string": "private static final InputFormat INPUT_FORMAT = new JsonInputFormat(\n      new JSONPathSpec(true, ImmutableList.of()),\n      ImmutableMap.of(),\n      false\n  );", "modifier": "private static final", "type": "InputFormat", "declarator": "INPUT_FORMAT = new JsonInputFormat(\n      new JSONPathSpec(true, ImmutableList.of()),\n      ImmutableMap.of(),\n      false\n  )", "var_name": "INPUT_FORMAT"}, {"original_string": "private static final String TOPIC_PREFIX = \"testTopic\";", "modifier": "private static final", "type": "String", "declarator": "TOPIC_PREFIX = \"testTopic\"", "var_name": "TOPIC_PREFIX"}, {"original_string": "private static final String DATASOURCE = \"testDS\";", "modifier": "private static final", "type": "String", "declarator": "DATASOURCE = \"testDS\"", "var_name": "DATASOURCE"}, {"original_string": "private static final int NUM_PARTITIONS = 3;", "modifier": "private static final", "type": "int", "declarator": "NUM_PARTITIONS = 3", "var_name": "NUM_PARTITIONS"}, {"original_string": "private static final int TEST_CHAT_THREADS = 3;", "modifier": "private static final", "type": "int", "declarator": "TEST_CHAT_THREADS = 3", "var_name": "TEST_CHAT_THREADS"}, {"original_string": "private static final long TEST_CHAT_RETRIES = 9L;", "modifier": "private static final", "type": "long", "declarator": "TEST_CHAT_RETRIES = 9L", "var_name": "TEST_CHAT_RETRIES"}, {"original_string": "private static final Period TEST_HTTP_TIMEOUT = new Period(\"PT10S\");", "modifier": "private static final", "type": "Period", "declarator": "TEST_HTTP_TIMEOUT = new Period(\"PT10S\")", "var_name": "TEST_HTTP_TIMEOUT"}, {"original_string": "private static final Period TEST_SHUTDOWN_TIMEOUT = new Period(\"PT80S\");", "modifier": "private static final", "type": "Period", "declarator": "TEST_SHUTDOWN_TIMEOUT = new Period(\"PT80S\")", "var_name": "TEST_SHUTDOWN_TIMEOUT"}, {"original_string": "private static TestingCluster zkServer;", "modifier": "private static", "type": "TestingCluster", "declarator": "zkServer", "var_name": "zkServer"}, {"original_string": "private static TestBroker kafkaServer;", "modifier": "private static", "type": "TestBroker", "declarator": "kafkaServer", "var_name": "kafkaServer"}, {"original_string": "private static String kafkaHost;", "modifier": "private static", "type": "String", "declarator": "kafkaHost", "var_name": "kafkaHost"}, {"original_string": "private static DataSchema dataSchema;", "modifier": "private static", "type": "DataSchema", "declarator": "dataSchema", "var_name": "dataSchema"}, {"original_string": "private static int topicPostfix;", "modifier": "private static", "type": "int", "declarator": "topicPostfix", "var_name": "topicPostfix"}, {"original_string": "private final int numThreads;", "modifier": "private final", "type": "int", "declarator": "numThreads", "var_name": "numThreads"}, {"original_string": "private TestableKafkaSupervisor supervisor;", "modifier": "private", "type": "TestableKafkaSupervisor", "declarator": "supervisor", "var_name": "supervisor"}, {"original_string": "private TaskStorage taskStorage;", "modifier": "private", "type": "TaskStorage", "declarator": "taskStorage", "var_name": "taskStorage"}, {"original_string": "private TaskMaster taskMaster;", "modifier": "private", "type": "TaskMaster", "declarator": "taskMaster", "var_name": "taskMaster"}, {"original_string": "private TaskRunner taskRunner;", "modifier": "private", "type": "TaskRunner", "declarator": "taskRunner", "var_name": "taskRunner"}, {"original_string": "private IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator;", "modifier": "private", "type": "IndexerMetadataStorageCoordinator", "declarator": "indexerMetadataStorageCoordinator", "var_name": "indexerMetadataStorageCoordinator"}, {"original_string": "private KafkaIndexTaskClient taskClient;", "modifier": "private", "type": "KafkaIndexTaskClient", "declarator": "taskClient", "var_name": "taskClient"}, {"original_string": "private TaskQueue taskQueue;", "modifier": "private", "type": "TaskQueue", "declarator": "taskQueue", "var_name": "taskQueue"}, {"original_string": "private String topic;", "modifier": "private", "type": "String", "declarator": "topic", "var_name": "topic"}, {"original_string": "private RowIngestionMetersFactory rowIngestionMetersFactory;", "modifier": "private", "type": "RowIngestionMetersFactory", "declarator": "rowIngestionMetersFactory", "var_name": "rowIngestionMetersFactory"}, {"original_string": "private ExceptionCapturingServiceEmitter serviceEmitter;", "modifier": "private", "type": "ExceptionCapturingServiceEmitter", "declarator": "serviceEmitter", "var_name": "serviceEmitter"}, {"original_string": "private SupervisorStateManagerConfig supervisorConfig;", "modifier": "private", "type": "SupervisorStateManagerConfig", "declarator": "supervisorConfig", "var_name": "supervisorConfig"}], "file": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java"}, "test_case": {"identifier": "testQueueNextTasksOnSuccess", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testQueueNextTasksOnSuccess() throws Exception\n  {\n    supervisor = getTestableSupervisor(2, 2, true, \"PT1H\", null, null);\n    addSomeEvents(1);\n\n    Capture<Task> captured = Capture.newInstance(CaptureType.ALL);\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskRunner.getRunningTasks()).andReturn(Collections.emptyList()).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(taskClient.getStatusAsync(EasyMock.anyString()))\n            .andReturn(Futures.immediateFuture(Status.NOT_STARTED))\n            .anyTimes();\n    EasyMock.expect(taskClient.getStartTimeAsync(EasyMock.anyString()))\n            .andReturn(Futures.immediateFuture(DateTimes.nowUtc()))\n            .anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true).times(4);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n\n    replayAll();\n\n    supervisor.start();\n    supervisor.runInternal();\n    verifyAll();\n\n    List<Task> tasks = captured.getValues();\n\n    EasyMock.reset(taskStorage);\n    EasyMock.reset(taskClient);\n\n    EasyMock.expect(taskClient.getStatusAsync(EasyMock.anyString()))\n            .andReturn(Futures.immediateFuture(Status.NOT_STARTED))\n            .anyTimes();\n    EasyMock.expect(taskClient.getStartTimeAsync(EasyMock.anyString()))\n            .andReturn(Futures.immediateFuture(DateTimes.nowUtc()))\n            .anyTimes();\n    TreeMap<Integer, Map<Integer, Long>> checkpoints1 = new TreeMap<>();\n    checkpoints1.put(0, ImmutableMap.of(0, 0L, 2, 0L));\n    TreeMap<Integer, Map<Integer, Long>> checkpoints2 = new TreeMap<>();\n    checkpoints2.put(0, ImmutableMap.of(1, 0L));\n    // there would be 4 tasks, 2 for each task group\n    EasyMock.expect(taskClient.getCheckpointsAsync(EasyMock.contains(\"sequenceName-0\"), EasyMock.anyBoolean()))\n            .andReturn(Futures.immediateFuture(checkpoints1))\n            .times(2);\n    EasyMock.expect(taskClient.getCheckpointsAsync(EasyMock.contains(\"sequenceName-1\"), EasyMock.anyBoolean()))\n            .andReturn(Futures.immediateFuture(checkpoints2))\n            .times(2);\n\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(tasks).anyTimes();\n    for (Task task : tasks) {\n      EasyMock.expect(taskStorage.getStatus(task.getId()))\n              .andReturn(Optional.of(TaskStatus.running(task.getId())))\n              .anyTimes();\n      EasyMock.expect(taskStorage.getTask(task.getId())).andReturn(Optional.of(task)).anyTimes();\n    }\n    EasyMock.replay(taskStorage);\n    EasyMock.replay(taskClient);\n\n    supervisor.runInternal();\n    verifyAll();\n\n    // test that a task succeeding causes a new task to be re-queued with the next offset range and causes any replica\n    // tasks to be shutdown\n    Capture<Task> newTasksCapture = Capture.newInstance(CaptureType.ALL);\n    Capture<String> shutdownTaskIdCapture = Capture.newInstance();\n    List<Task> imStillRunning = tasks.subList(1, 4);\n    KafkaIndexTask iAmSuccess = (KafkaIndexTask) tasks.get(0);\n    EasyMock.reset(taskStorage);\n    EasyMock.reset(taskQueue);\n    EasyMock.reset(taskClient);\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(imStillRunning).anyTimes();\n    for (Task task : imStillRunning) {\n      EasyMock.expect(taskStorage.getStatus(task.getId()))\n              .andReturn(Optional.of(TaskStatus.running(task.getId())))\n              .anyTimes();\n      EasyMock.expect(taskStorage.getTask(task.getId())).andReturn(Optional.of(task)).anyTimes();\n    }\n    EasyMock.expect(taskStorage.getStatus(iAmSuccess.getId()))\n            .andReturn(Optional.of(TaskStatus.success(iAmSuccess.getId())));\n    EasyMock.expect(taskStorage.getTask(iAmSuccess.getId())).andReturn(Optional.of(iAmSuccess)).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(newTasksCapture))).andReturn(true).times(2);\n    EasyMock.expect(taskClient.stopAsync(EasyMock.capture(shutdownTaskIdCapture), EasyMock.eq(false)))\n            .andReturn(Futures.immediateFuture(true));\n    EasyMock.replay(taskStorage);\n    EasyMock.replay(taskQueue);\n    EasyMock.replay(taskClient);\n\n    supervisor.runInternal();\n    verifyAll();\n\n    // make sure we killed the right task (sequenceName for replicas are the same)\n    Assert.assertTrue(shutdownTaskIdCapture.getValue().contains(iAmSuccess.getIOConfig().getBaseSequenceName()));\n  }", "signature": "void testQueueNextTasksOnSuccess()", "full_signature": "@Test public void testQueueNextTasksOnSuccess()", "class_method_signature": "KafkaSupervisorTest.testQueueNextTasksOnSuccess()", "testcase": true, "constructor": false, "invocations": ["getTestableSupervisor", "addSomeEvents", "newInstance", "anyTimes", "andReturn", "expect", "getTaskQueue", "of", "anyTimes", "andReturn", "expect", "getTaskRunner", "of", "anyTimes", "andReturn", "expect", "getRunningTasks", "emptyList", "anyTimes", "andReturn", "expect", "getActiveTasksByDatasource", "of", "anyTimes", "andReturn", "expect", "getStatusAsync", "anyString", "immediateFuture", "anyTimes", "andReturn", "expect", "getStartTimeAsync", "anyString", "immediateFuture", "nowUtc", "anyTimes", "andReturn", "expect", "retrieveDataSourceMetadata", "times", "andReturn", "expect", "add", "capture", "registerListener", "anyObject", "anyObject", "replayAll", "start", "runInternal", "verifyAll", "getValues", "reset", "reset", "anyTimes", "andReturn", "expect", "getStatusAsync", "anyString", "immediateFuture", "anyTimes", "andReturn", "expect", "getStartTimeAsync", "anyString", "immediateFuture", "nowUtc", "put", "of", "put", "of", "times", "andReturn", "expect", "getCheckpointsAsync", "contains", "anyBoolean", "immediateFuture", "times", "andReturn", "expect", "getCheckpointsAsync", "contains", "anyBoolean", "immediateFuture", "anyTimes", "andReturn", "expect", "getActiveTasksByDatasource", "anyTimes", "andReturn", "expect", "getStatus", "getId", "of", "running", "getId", "anyTimes", "andReturn", "expect", "getTask", "getId", "of", "replay", "replay", "runInternal", "verifyAll", "newInstance", "newInstance", "subList", "get", "reset", "reset", "reset", "anyTimes", "andReturn", "expect", "getActiveTasksByDatasource", "anyTimes", "andReturn", "expect", "getStatus", "getId", "of", "running", "getId", "anyTimes", "andReturn", "expect", "getTask", "getId", "of", "andReturn", "expect", "getStatus", "getId", "of", "success", "getId", "anyTimes", "andReturn", "expect", "getTask", "getId", "of", "times", "andReturn", "expect", "add", "capture", "andReturn", "expect", "stopAsync", "capture", "eq", "immediateFuture", "replay", "replay", "replay", "runInternal", "verifyAll", "assertTrue", "contains", "getValue", "getBaseSequenceName", "getIOConfig"]}, "focal_class": {"identifier": "KafkaSupervisor", "superclass": "extends SeekableStreamSupervisor<Integer, Long>", "interfaces": "", "fields": [{"original_string": "public static final TypeReference<TreeMap<Integer, Map<Integer, Long>>> CHECKPOINTS_TYPE_REF =\n      new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n      {\n      };", "modifier": "public static final", "type": "TypeReference<TreeMap<Integer, Map<Integer, Long>>>", "declarator": "CHECKPOINTS_TYPE_REF =\n      new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n      {\n      }", "var_name": "CHECKPOINTS_TYPE_REF"}, {"original_string": "private static final EmittingLogger log = new EmittingLogger(KafkaSupervisor.class);", "modifier": "private static final", "type": "EmittingLogger", "declarator": "log = new EmittingLogger(KafkaSupervisor.class)", "var_name": "log"}, {"original_string": "private static final Long NOT_SET = -1L;", "modifier": "private static final", "type": "Long", "declarator": "NOT_SET = -1L", "var_name": "NOT_SET"}, {"original_string": "private static final Long END_OF_PARTITION = Long.MAX_VALUE;", "modifier": "private static final", "type": "Long", "declarator": "END_OF_PARTITION = Long.MAX_VALUE", "var_name": "END_OF_PARTITION"}, {"original_string": "private final ServiceEmitter emitter;", "modifier": "private final", "type": "ServiceEmitter", "declarator": "emitter", "var_name": "emitter"}, {"original_string": "private final DruidMonitorSchedulerConfig monitorSchedulerConfig;", "modifier": "private final", "type": "DruidMonitorSchedulerConfig", "declarator": "monitorSchedulerConfig", "var_name": "monitorSchedulerConfig"}, {"original_string": "private volatile Map<Integer, Long> latestSequenceFromStream;", "modifier": "private volatile", "type": "Map<Integer, Long>", "declarator": "latestSequenceFromStream", "var_name": "latestSequenceFromStream"}, {"original_string": "private final KafkaSupervisorSpec spec;", "modifier": "private final", "type": "KafkaSupervisorSpec", "declarator": "spec", "var_name": "spec"}], "methods": [{"identifier": "KafkaSupervisor", "parameters": "(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "modifiers": "public", "return": "", "signature": " KafkaSupervisor(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "full_signature": "public  KafkaSupervisor(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "class_method_signature": "KafkaSupervisor.KafkaSupervisor(\n      final TaskStorage taskStorage,\n      final TaskMaster taskMaster,\n      final IndexerMetadataStorageCoordinator indexerMetadataStorageCoordinator,\n      final KafkaIndexTaskClientFactory taskClientFactory,\n      final ObjectMapper mapper,\n      final KafkaSupervisorSpec spec,\n      final RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "testcase": false, "constructor": true}, {"identifier": "setupRecordSupplier", "parameters": "()", "modifiers": "@Override protected", "return": "RecordSupplier<Integer, Long>", "signature": "RecordSupplier<Integer, Long> setupRecordSupplier()", "full_signature": "@Override protected RecordSupplier<Integer, Long> setupRecordSupplier()", "class_method_signature": "KafkaSupervisor.setupRecordSupplier()", "testcase": false, "constructor": false}, {"identifier": "getTaskGroupIdForPartition", "parameters": "(Integer partitionId)", "modifiers": "@Override protected", "return": "int", "signature": "int getTaskGroupIdForPartition(Integer partitionId)", "full_signature": "@Override protected int getTaskGroupIdForPartition(Integer partitionId)", "class_method_signature": "KafkaSupervisor.getTaskGroupIdForPartition(Integer partitionId)", "testcase": false, "constructor": false}, {"identifier": "checkSourceMetadataMatch", "parameters": "(DataSourceMetadata metadata)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean checkSourceMetadataMatch(DataSourceMetadata metadata)", "full_signature": "@Override protected boolean checkSourceMetadataMatch(DataSourceMetadata metadata)", "class_method_signature": "KafkaSupervisor.checkSourceMetadataMatch(DataSourceMetadata metadata)", "testcase": false, "constructor": false}, {"identifier": "doesTaskTypeMatchSupervisor", "parameters": "(Task task)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean doesTaskTypeMatchSupervisor(Task task)", "full_signature": "@Override protected boolean doesTaskTypeMatchSupervisor(Task task)", "class_method_signature": "KafkaSupervisor.doesTaskTypeMatchSupervisor(Task task)", "testcase": false, "constructor": false}, {"identifier": "createReportPayload", "parameters": "(\n      int numPartitions,\n      boolean includeOffsets\n  )", "modifiers": "@Override protected", "return": "SeekableStreamSupervisorReportPayload<Integer, Long>", "signature": "SeekableStreamSupervisorReportPayload<Integer, Long> createReportPayload(\n      int numPartitions,\n      boolean includeOffsets\n  )", "full_signature": "@Override protected SeekableStreamSupervisorReportPayload<Integer, Long> createReportPayload(\n      int numPartitions,\n      boolean includeOffsets\n  )", "class_method_signature": "KafkaSupervisor.createReportPayload(\n      int numPartitions,\n      boolean includeOffsets\n  )", "testcase": false, "constructor": false}, {"identifier": "createTaskIoConfig", "parameters": "(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "modifiers": "@Override protected", "return": "SeekableStreamIndexTaskIOConfig", "signature": "SeekableStreamIndexTaskIOConfig createTaskIoConfig(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "full_signature": "@Override protected SeekableStreamIndexTaskIOConfig createTaskIoConfig(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "class_method_signature": "KafkaSupervisor.createTaskIoConfig(\n      int groupId,\n      Map<Integer, Long> startPartitions,\n      Map<Integer, Long> endPartitions,\n      String baseSequenceName,\n      DateTime minimumMessageTime,\n      DateTime maximumMessageTime,\n      Set<Integer> exclusiveStartSequenceNumberPartitions,\n      SeekableStreamSupervisorIOConfig ioConfig\n  )", "testcase": false, "constructor": false}, {"identifier": "createIndexTasks", "parameters": "(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "modifiers": "@Override protected", "return": "List<SeekableStreamIndexTask<Integer, Long>>", "signature": "List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "full_signature": "@Override protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "class_method_signature": "KafkaSupervisor.createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  )", "testcase": false, "constructor": false}, {"identifier": "getPartitionRecordLag", "parameters": "()", "modifiers": "@Override protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getPartitionRecordLag()", "full_signature": "@Override protected Map<Integer, Long> getPartitionRecordLag()", "class_method_signature": "KafkaSupervisor.getPartitionRecordLag()", "testcase": false, "constructor": false}, {"identifier": "getPartitionTimeLag", "parameters": "()", "modifiers": "@Nullable @Override protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getPartitionTimeLag()", "full_signature": "@Nullable @Override protected Map<Integer, Long> getPartitionTimeLag()", "class_method_signature": "KafkaSupervisor.getPartitionTimeLag()", "testcase": false, "constructor": false}, {"identifier": "getRecordLagPerPartition", "parameters": "(Map<Integer, Long> currentOffsets)", "modifiers": "@Override // suppress use of CollectionUtils.mapValues() since the valueMapper function is dependent on map key here @SuppressWarnings(\"SSBasedInspection\") protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getRecordLagPerPartition(Map<Integer, Long> currentOffsets)", "full_signature": "@Override // suppress use of CollectionUtils.mapValues() since the valueMapper function is dependent on map key here @SuppressWarnings(\"SSBasedInspection\") protected Map<Integer, Long> getRecordLagPerPartition(Map<Integer, Long> currentOffsets)", "class_method_signature": "KafkaSupervisor.getRecordLagPerPartition(Map<Integer, Long> currentOffsets)", "testcase": false, "constructor": false}, {"identifier": "getTimeLagPerPartition", "parameters": "(Map<Integer, Long> currentOffsets)", "modifiers": "@Override protected", "return": "Map<Integer, Long>", "signature": "Map<Integer, Long> getTimeLagPerPartition(Map<Integer, Long> currentOffsets)", "full_signature": "@Override protected Map<Integer, Long> getTimeLagPerPartition(Map<Integer, Long> currentOffsets)", "class_method_signature": "KafkaSupervisor.getTimeLagPerPartition(Map<Integer, Long> currentOffsets)", "testcase": false, "constructor": false}, {"identifier": "createDataSourceMetaDataForReset", "parameters": "(String topic, Map<Integer, Long> map)", "modifiers": "@Override protected", "return": "KafkaDataSourceMetadata", "signature": "KafkaDataSourceMetadata createDataSourceMetaDataForReset(String topic, Map<Integer, Long> map)", "full_signature": "@Override protected KafkaDataSourceMetadata createDataSourceMetaDataForReset(String topic, Map<Integer, Long> map)", "class_method_signature": "KafkaSupervisor.createDataSourceMetaDataForReset(String topic, Map<Integer, Long> map)", "testcase": false, "constructor": false}, {"identifier": "makeSequenceNumber", "parameters": "(Long seq, boolean isExclusive)", "modifiers": "@Override protected", "return": "OrderedSequenceNumber<Long>", "signature": "OrderedSequenceNumber<Long> makeSequenceNumber(Long seq, boolean isExclusive)", "full_signature": "@Override protected OrderedSequenceNumber<Long> makeSequenceNumber(Long seq, boolean isExclusive)", "class_method_signature": "KafkaSupervisor.makeSequenceNumber(Long seq, boolean isExclusive)", "testcase": false, "constructor": false}, {"identifier": "getNotSetMarker", "parameters": "()", "modifiers": "@Override protected", "return": "Long", "signature": "Long getNotSetMarker()", "full_signature": "@Override protected Long getNotSetMarker()", "class_method_signature": "KafkaSupervisor.getNotSetMarker()", "testcase": false, "constructor": false}, {"identifier": "getEndOfPartitionMarker", "parameters": "()", "modifiers": "@Override protected", "return": "Long", "signature": "Long getEndOfPartitionMarker()", "full_signature": "@Override protected Long getEndOfPartitionMarker()", "class_method_signature": "KafkaSupervisor.getEndOfPartitionMarker()", "testcase": false, "constructor": false}, {"identifier": "isEndOfShard", "parameters": "(Long seqNum)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean isEndOfShard(Long seqNum)", "full_signature": "@Override protected boolean isEndOfShard(Long seqNum)", "class_method_signature": "KafkaSupervisor.isEndOfShard(Long seqNum)", "testcase": false, "constructor": false}, {"identifier": "isShardExpirationMarker", "parameters": "(Long seqNum)", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean isShardExpirationMarker(Long seqNum)", "full_signature": "@Override protected boolean isShardExpirationMarker(Long seqNum)", "class_method_signature": "KafkaSupervisor.isShardExpirationMarker(Long seqNum)", "testcase": false, "constructor": false}, {"identifier": "useExclusiveStartSequenceNumberForNonFirstSequence", "parameters": "()", "modifiers": "@Override protected", "return": "boolean", "signature": "boolean useExclusiveStartSequenceNumberForNonFirstSequence()", "full_signature": "@Override protected boolean useExclusiveStartSequenceNumberForNonFirstSequence()", "class_method_signature": "KafkaSupervisor.useExclusiveStartSequenceNumberForNonFirstSequence()", "testcase": false, "constructor": false}, {"identifier": "updatePartitionLagFromStream", "parameters": "()", "modifiers": "@Override protected", "return": "void", "signature": "void updatePartitionLagFromStream()", "full_signature": "@Override protected void updatePartitionLagFromStream()", "class_method_signature": "KafkaSupervisor.updatePartitionLagFromStream()", "testcase": false, "constructor": false}, {"identifier": "baseTaskName", "parameters": "()", "modifiers": "@Override protected", "return": "String", "signature": "String baseTaskName()", "full_signature": "@Override protected String baseTaskName()", "class_method_signature": "KafkaSupervisor.baseTaskName()", "testcase": false, "constructor": false}, {"identifier": "getIoConfig", "parameters": "()", "modifiers": "@Override @VisibleForTesting public", "return": "KafkaSupervisorIOConfig", "signature": "KafkaSupervisorIOConfig getIoConfig()", "full_signature": "@Override @VisibleForTesting public KafkaSupervisorIOConfig getIoConfig()", "class_method_signature": "KafkaSupervisor.getIoConfig()", "testcase": false, "constructor": false}, {"identifier": "getTuningConfig", "parameters": "()", "modifiers": "@VisibleForTesting public", "return": "KafkaSupervisorTuningConfig", "signature": "KafkaSupervisorTuningConfig getTuningConfig()", "full_signature": "@VisibleForTesting public KafkaSupervisorTuningConfig getTuningConfig()", "class_method_signature": "KafkaSupervisor.getTuningConfig()", "testcase": false, "constructor": false}], "file": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java"}, "focal_method": {"identifier": "getIoConfig", "parameters": "()", "modifiers": "@Override @VisibleForTesting public", "return": "KafkaSupervisorIOConfig", "body": "@Override\n  @VisibleForTesting\n  public KafkaSupervisorIOConfig getIoConfig()\n  {\n    return spec.getIoConfig();\n  }", "signature": "KafkaSupervisorIOConfig getIoConfig()", "full_signature": "@Override @VisibleForTesting public KafkaSupervisorIOConfig getIoConfig()", "class_method_signature": "KafkaSupervisor.getIoConfig()", "testcase": false, "constructor": false, "invocations": ["getIoConfig"]}, "repository": {"repo_id": 6358188, "url": "https://github.com/apache/druid", "stars": 9116, "created": "10/23/2012 7:08:07 PM +00:00", "updates": "2020-01-27T21:36:20+00:00", "fork": "False", "license": "licensed"}}