{"test_class": {"identifier": "PropertyKeyTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private PropertyKey mTestProperty = new Builder(\"alluxio.test.property\")\n      .setAlias(new String[] {\"alluxio.test.property.alias1\", \"alluxio.test.property.alias2\"})\n      .setDescription(\"test\")\n      .setDefaultValue(false)\n      .setIsHidden(false)\n      .setIgnoredSiteProperty(false)\n      .build();", "modifier": "private", "type": "PropertyKey", "declarator": "mTestProperty = new Builder(\"alluxio.test.property\")\n      .setAlias(new String[] {\"alluxio.test.property.alias1\", \"alluxio.test.property.alias2\"})\n      .setDescription(\"test\")\n      .setDefaultValue(false)\n      .setIsHidden(false)\n      .setIgnoredSiteProperty(false)\n      .build()", "var_name": "mTestProperty"}], "file": "core/common/src/test/java/alluxio/conf/PropertyKeyTest.java"}, "test_case": {"identifier": "isValidParameterized", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void isValidParameterized() throws Exception {\n    // String parameter\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.root.alluxio\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.foo.alluxio\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.FoO.alluxio\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.Fo123.alluxio\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.FoO.alluxio\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.root.option\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.root.option.foo\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.master.mount.table.root.option.alluxio.foo\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.master.mount.table.alluxio\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.master.mount.table..alluxio\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.master.mount.table. .alluxio\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.master.mount.table.foo.alluxio1\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.master.mount.table.root.option.\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.master.mount.table.root.option.foo.\"));\n    // Numeric parameter\n    assertTrue(PropertyKey.isValid(\"alluxio.worker.tieredstore.level1.alias\"));\n    assertTrue(PropertyKey.isValid(\"alluxio.worker.tieredstore.level99.alias\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.worker.tieredstore.level.alias\"));\n    assertFalse(PropertyKey.isValid(\"alluxio.worker.tieredstore.levela.alias\"));\n  }", "signature": "void isValidParameterized()", "full_signature": "@Test public void isValidParameterized()", "class_method_signature": "PropertyKeyTest.isValidParameterized()", "testcase": true, "constructor": false, "invocations": ["assertTrue", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertFalse", "isValid", "assertFalse", "isValid", "assertFalse", "isValid", "assertFalse", "isValid", "assertFalse", "isValid", "assertFalse", "isValid", "assertTrue", "isValid", "assertTrue", "isValid", "assertFalse", "isValid", "assertFalse", "isValid"]}, "focal_class": {"identifier": "PropertyKey", "superclass": "", "interfaces": "implements Comparable<PropertyKey>", "fields": [{"original_string": "private static final Logger LOG = LoggerFactory.getLogger(PropertyKey.class);", "modifier": "private static final", "type": "Logger", "declarator": "LOG = LoggerFactory.getLogger(PropertyKey.class)", "var_name": "LOG"}, {"original_string": "private static final Map<String, PropertyKey> DEFAULT_KEYS_MAP = new ConcurrentHashMap<>();", "modifier": "private static final", "type": "Map<String, PropertyKey>", "declarator": "DEFAULT_KEYS_MAP = new ConcurrentHashMap<>()", "var_name": "DEFAULT_KEYS_MAP"}, {"original_string": "private static final Map<String, PropertyKey> DEFAULT_ALIAS_MAP = new ConcurrentHashMap<>();", "modifier": "private static final", "type": "Map<String, PropertyKey>", "declarator": "DEFAULT_ALIAS_MAP = new ConcurrentHashMap<>()", "var_name": "DEFAULT_ALIAS_MAP"}, {"original_string": "private static final Cache<String, Boolean> REGEXP_CACHE = CacheBuilder.newBuilder()\n      .maximumSize(1024)\n      .build();", "modifier": "private static final", "type": "Cache<String, Boolean>", "declarator": "REGEXP_CACHE = CacheBuilder.newBuilder()\n      .maximumSize(1024)\n      .build()", "var_name": "REGEXP_CACHE"}, {"original_string": "public static final PropertyKey CONF_DIR =\n      new Builder(Name.CONF_DIR)\n          .setDefaultValue(String.format(\"${%s}/conf\", Name.HOME))\n          .setDescription(\"The directory containing files used to configure Alluxio.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "CONF_DIR =\n      new Builder(Name.CONF_DIR)\n          .setDefaultValue(String.format(\"${%s}/conf\", Name.HOME))\n          .setDescription(\"The directory containing files used to configure Alluxio.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "CONF_DIR"}, {"original_string": "public static final PropertyKey CONF_VALIDATION_ENABLED =\n      new Builder(Name.CONF_VALIDATION_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to validate the configuration properties when initializing \"\n              + \"Alluxio clients or server process.\")\n          .setIsHidden(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "CONF_VALIDATION_ENABLED =\n      new Builder(Name.CONF_VALIDATION_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to validate the configuration properties when initializing \"\n              + \"Alluxio clients or server process.\")\n          .setIsHidden(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "CONF_VALIDATION_ENABLED"}, {"original_string": "public static final PropertyKey DEBUG =\n      new Builder(Name.DEBUG)\n          .setDefaultValue(false)\n          .setDescription(\"Set to true to enable debug mode which has additional logging and \"\n              + \"info in the Web UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "DEBUG =\n      new Builder(Name.DEBUG)\n          .setDefaultValue(false)\n          .setDescription(\"Set to true to enable debug mode which has additional logging and \"\n              + \"info in the Web UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "DEBUG"}, {"original_string": "public static final PropertyKey EXTENSIONS_DIR =\n      new Builder(Name.EXTENSIONS_DIR)\n          .setDefaultValue(String.format(\"${%s}/extensions\", Name.HOME))\n          .setDescription(\"The directory containing Alluxio extensions.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "EXTENSIONS_DIR =\n      new Builder(Name.EXTENSIONS_DIR)\n          .setDefaultValue(String.format(\"${%s}/extensions\", Name.HOME))\n          .setDescription(\"The directory containing Alluxio extensions.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "EXTENSIONS_DIR"}, {"original_string": "public static final PropertyKey HOME =\n      new Builder(Name.HOME)\n          .setDefaultValue(\"/opt/alluxio\")\n          .setDescription(\"Alluxio installation directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "HOME =\n      new Builder(Name.HOME)\n          .setDefaultValue(\"/opt/alluxio\")\n          .setDescription(\"Alluxio installation directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "HOME"}, {"original_string": "public static final PropertyKey LOGGER_TYPE =\n      new Builder(Name.LOGGER_TYPE)\n          .setDefaultValue(\"Console\")\n          .setDescription(\"The type of logger.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGGER_TYPE =\n      new Builder(Name.LOGGER_TYPE)\n          .setDefaultValue(\"Console\")\n          .setDescription(\"The type of logger.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOGGER_TYPE"}, {"original_string": "public static final PropertyKey LOGS_DIR =\n      new Builder(Name.LOGS_DIR)\n          .setDefaultValue(String.format(\"${%s}/logs\", Name.WORK_DIR))\n          .setDescription(\"The path under Alluxio home directory to store log files. It has a \"\n              + \"corresponding environment variable $ALLUXIO_LOGS_DIR.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGS_DIR =\n      new Builder(Name.LOGS_DIR)\n          .setDefaultValue(String.format(\"${%s}/logs\", Name.WORK_DIR))\n          .setDescription(\"The path under Alluxio home directory to store log files. It has a \"\n              + \"corresponding environment variable $ALLUXIO_LOGS_DIR.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOGS_DIR"}, {"original_string": "public static final PropertyKey USER_LOGS_DIR =\n      new Builder(Name.USER_LOGS_DIR)\n          .setDefaultValue(String.format(\"${%s}/user\", Name.LOGS_DIR))\n          .setDescription(\"The path to store logs of Alluxio shell. To change its value, one can \"\n              + \" set environment variable $ALLUXIO_USER_LOGS_DIR.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_LOGS_DIR =\n      new Builder(Name.USER_LOGS_DIR)\n          .setDefaultValue(String.format(\"${%s}/user\", Name.LOGS_DIR))\n          .setDescription(\"The path to store logs of Alluxio shell. To change its value, one can \"\n              + \" set environment variable $ALLUXIO_USER_LOGS_DIR.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build()", "var_name": "USER_LOGS_DIR"}, {"original_string": "public static final PropertyKey METRICS_CONF_FILE =\n      new Builder(Name.METRICS_CONF_FILE)\n          .setDefaultValue(String.format(\"${%s}/metrics.properties\", Name.CONF_DIR))\n          .setDescription(\"The file path of the metrics system configuration file. By default \"\n              + \"it is `metrics.properties` in the `conf` directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "METRICS_CONF_FILE =\n      new Builder(Name.METRICS_CONF_FILE)\n          .setDefaultValue(String.format(\"${%s}/metrics.properties\", Name.CONF_DIR))\n          .setDescription(\"The file path of the metrics system configuration file. By default \"\n              + \"it is `metrics.properties` in the `conf` directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "METRICS_CONF_FILE"}, {"original_string": "public static final PropertyKey METRICS_CONTEXT_SHUTDOWN_TIMEOUT =\n      new Builder(Name.METRICS_CONTEXT_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Time to wait for the metrics context to shut down. The main purpose for \"\n              + \"this property is to allow tests to shut down faster.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setIsHidden(true)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "METRICS_CONTEXT_SHUTDOWN_TIMEOUT =\n      new Builder(Name.METRICS_CONTEXT_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Time to wait for the metrics context to shut down. The main purpose for \"\n              + \"this property is to allow tests to shut down faster.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setIsHidden(true)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "METRICS_CONTEXT_SHUTDOWN_TIMEOUT"}, {"original_string": "public static final PropertyKey NETWORK_CONNECTION_AUTH_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_AUTH_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Maximum time to wait for a connection (gRPC channel) to attempt to \"\n              + \"receive an authentication response.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "NETWORK_CONNECTION_AUTH_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_AUTH_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Maximum time to wait for a connection (gRPC channel) to attempt to \"\n              + \"receive an authentication response.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "NETWORK_CONNECTION_AUTH_TIMEOUT"}, {"original_string": "public static final PropertyKey NETWORK_CONNECTION_HEALTH_CHECK_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_HEALTH_CHECK_TIMEOUT)\n          .setAlias(\"alluxio.network.connection.health.check.timeout.ms\")\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Allowed duration for checking health of client connections (gRPC \"\n              + \"channels) before being assigned to a client. If a connection does not become \"\n              + \"active  within configured time, it will be shut down and a new connection will be \"\n              + \"created for the client\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "NETWORK_CONNECTION_HEALTH_CHECK_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_HEALTH_CHECK_TIMEOUT)\n          .setAlias(\"alluxio.network.connection.health.check.timeout.ms\")\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Allowed duration for checking health of client connections (gRPC \"\n              + \"channels) before being assigned to a client. If a connection does not become \"\n              + \"active  within configured time, it will be shut down and a new connection will be \"\n              + \"created for the client\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "NETWORK_CONNECTION_HEALTH_CHECK_TIMEOUT"}, {"original_string": "public static final PropertyKey NETWORK_CONNECTION_SERVER_SHUTDOWN_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_SERVER_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"60sec\")\n          .setDescription(\"Maximum time to wait for gRPC server to stop on shutdown\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "NETWORK_CONNECTION_SERVER_SHUTDOWN_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_SERVER_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"60sec\")\n          .setDescription(\"Maximum time to wait for gRPC server to stop on shutdown\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "NETWORK_CONNECTION_SERVER_SHUTDOWN_TIMEOUT"}, {"original_string": "public static final PropertyKey NETWORK_CONNECTION_SHUTDOWN_GRACEFUL_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_SHUTDOWN_GRACEFUL_TIMEOUT)\n          .setDefaultValue(\"45sec\")\n          .setDescription(\"Maximum time to wait for connections (gRPC channels) to stop on \"\n              + \"shutdown\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "NETWORK_CONNECTION_SHUTDOWN_GRACEFUL_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_SHUTDOWN_GRACEFUL_TIMEOUT)\n          .setDefaultValue(\"45sec\")\n          .setDescription(\"Maximum time to wait for connections (gRPC channels) to stop on \"\n              + \"shutdown\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "NETWORK_CONNECTION_SHUTDOWN_GRACEFUL_TIMEOUT"}, {"original_string": "public static final PropertyKey NETWORK_CONNECTION_SHUTDOWN_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"15sec\")\n          .setDescription(\"Maximum time to wait for connections (gRPC channels) to stop after \"\n              + \"graceful shutdown attempt.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "NETWORK_CONNECTION_SHUTDOWN_TIMEOUT =\n      new Builder(Name.NETWORK_CONNECTION_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"15sec\")\n          .setDescription(\"Maximum time to wait for connections (gRPC channels) to stop after \"\n              + \"graceful shutdown attempt.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "NETWORK_CONNECTION_SHUTDOWN_TIMEOUT"}, {"original_string": "public static final PropertyKey NETWORK_HOST_RESOLUTION_TIMEOUT_MS =\n      new Builder(Name.NETWORK_HOST_RESOLUTION_TIMEOUT_MS)\n          .setAlias(\"alluxio.network.host.resolution.timeout.ms\")\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"During startup of the Master and Worker processes Alluxio needs to \"\n              + \"ensure that they are listening on externally resolvable and reachable host \"\n              + \"names. To do this, Alluxio will automatically attempt to select an \"\n              + \"appropriate host name if one was not explicitly specified. This represents \"\n              + \"the maximum amount of time spent waiting to determine if a candidate host \"\n              + \"name is resolvable over the network.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "NETWORK_HOST_RESOLUTION_TIMEOUT_MS =\n      new Builder(Name.NETWORK_HOST_RESOLUTION_TIMEOUT_MS)\n          .setAlias(\"alluxio.network.host.resolution.timeout.ms\")\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"During startup of the Master and Worker processes Alluxio needs to \"\n              + \"ensure that they are listening on externally resolvable and reachable host \"\n              + \"names. To do this, Alluxio will automatically attempt to select an \"\n              + \"appropriate host name if one was not explicitly specified. This represents \"\n              + \"the maximum amount of time spent waiting to determine if a candidate host \"\n              + \"name is resolvable over the network.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "NETWORK_HOST_RESOLUTION_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey SITE_CONF_DIR =\n      new Builder(Name.SITE_CONF_DIR)\n          .setDefaultSupplier(\n              () -> String.format(\"${%s}/,%s/.alluxio/,/etc/alluxio/\",\n                  Name.CONF_DIR, System.getProperty(\"user.home\")),\n              String.format(\"${%s}/,${user.home}/.alluxio/,/etc/alluxio/\", Name.CONF_DIR))\n          .setDescription(\n              String.format(\"Comma-separated search path for %s.\", Constants.SITE_PROPERTIES))\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SITE_CONF_DIR =\n      new Builder(Name.SITE_CONF_DIR)\n          .setDefaultSupplier(\n              () -> String.format(\"${%s}/,%s/.alluxio/,/etc/alluxio/\",\n                  Name.CONF_DIR, System.getProperty(\"user.home\")),\n              String.format(\"${%s}/,${user.home}/.alluxio/,/etc/alluxio/\", Name.CONF_DIR))\n          .setDescription(\n              String.format(\"Comma-separated search path for %s.\", Constants.SITE_PROPERTIES))\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SITE_CONF_DIR"}, {"original_string": "public static final PropertyKey TEST_MODE =\n      new Builder(Name.TEST_MODE)\n          .setDefaultValue(false)\n          .setDescription(\"Flag used only during tests to allow special behavior.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setIsHidden(true)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TEST_MODE =\n      new Builder(Name.TEST_MODE)\n          .setDefaultValue(false)\n          .setDescription(\"Flag used only during tests to allow special behavior.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setIsHidden(true)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "TEST_MODE"}, {"original_string": "public static final PropertyKey TMP_DIRS =\n      new Builder(Name.TMP_DIRS)\n          .setDefaultValue(\"/tmp\")\n          .setDescription(\"The path(s) to store Alluxio temporary files, use commas as delimiters. \"\n              + \"If multiple paths are specified, one will be selected at random per temporary \"\n              + \"file. Currently, only files to be uploaded to object stores are stored in these \"\n              + \"paths.\")\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TMP_DIRS =\n      new Builder(Name.TMP_DIRS)\n          .setDefaultValue(\"/tmp\")\n          .setDescription(\"The path(s) to store Alluxio temporary files, use commas as delimiters. \"\n              + \"If multiple paths are specified, one will be selected at random per temporary \"\n              + \"file. Currently, only files to be uploaded to object stores are stored in these \"\n              + \"paths.\")\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "TMP_DIRS"}, {"original_string": "public static final PropertyKey VERSION =\n      new Builder(Name.VERSION)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setDefaultValue(ProjectConstants.VERSION)\n          .setDescription(\"Version of Alluxio. User should never modify this property.\")\n          .setIgnoredSiteProperty(true)\n          .setIsHidden(true)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "VERSION =\n      new Builder(Name.VERSION)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setDefaultValue(ProjectConstants.VERSION)\n          .setDescription(\"Version of Alluxio. User should never modify this property.\")\n          .setIgnoredSiteProperty(true)\n          .setIsHidden(true)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "VERSION"}, {"original_string": "public static final PropertyKey WEB_FILE_INFO_ENABLED =\n      new Builder(Name.WEB_FILE_INFO_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether detailed file information are enabled for the web UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WEB_FILE_INFO_ENABLED =\n      new Builder(Name.WEB_FILE_INFO_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether detailed file information are enabled for the web UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "WEB_FILE_INFO_ENABLED"}, {"original_string": "public static final PropertyKey WEB_RESOURCES =\n      new Builder(Name.WEB_RESOURCES)\n          .setDefaultValue(String.format(\"${%s}/webui/\", Name.HOME))\n          .setDescription(\"Path to the web UI resources. User should never modify this property.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .setIsHidden(true)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WEB_RESOURCES =\n      new Builder(Name.WEB_RESOURCES)\n          .setDefaultValue(String.format(\"${%s}/webui/\", Name.HOME))\n          .setDescription(\"Path to the web UI resources. User should never modify this property.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .setIsHidden(true)\n          .build()", "var_name": "WEB_RESOURCES"}, {"original_string": "public static final PropertyKey WEB_THREADS =\n      new Builder(Name.WEB_THREADS)\n          .setDefaultValue(1)\n          .setDescription(\"How many threads to serve Alluxio web UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WEB_THREADS =\n      new Builder(Name.WEB_THREADS)\n          .setDefaultValue(1)\n          .setDescription(\"How many threads to serve Alluxio web UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "WEB_THREADS"}, {"original_string": "public static final PropertyKey WEB_CORS_ENABLED =\n      new Builder(Name.WEB_CORS_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Set to true to enable Cross-Origin Resource Sharing for RESTful API\"\n              + \"endpoints.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WEB_CORS_ENABLED =\n      new Builder(Name.WEB_CORS_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Set to true to enable Cross-Origin Resource Sharing for RESTful API\"\n              + \"endpoints.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "WEB_CORS_ENABLED"}, {"original_string": "public static final PropertyKey WEB_REFRESH_INTERVAL =\n      new Builder(Name.WEB_REFRESH_INTERVAL)\n          .setDefaultValue(\"15s\")\n          .setDescription(\"The amount of time to await before refreshing the Web UI if it is set \"\n              + \"to auto refresh.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WEB_REFRESH_INTERVAL =\n      new Builder(Name.WEB_REFRESH_INTERVAL)\n          .setDefaultValue(\"15s\")\n          .setDescription(\"The amount of time to await before refreshing the Web UI if it is set \"\n              + \"to auto refresh.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "WEB_REFRESH_INTERVAL"}, {"original_string": "public static final PropertyKey WEB_UI_ENABLED =\n      new Builder(Name.WEB_UI_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether the master/worker will have Web UI enabled. \"\n              + \"If set to false, the master/worker will not have Web UI page, but the RESTful \"\n              + \"endpoints and metrics will still be available.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WEB_UI_ENABLED =\n      new Builder(Name.WEB_UI_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether the master/worker will have Web UI enabled. \"\n              + \"If set to false, the master/worker will not have Web UI page, but the RESTful \"\n              + \"endpoints and metrics will still be available.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "WEB_UI_ENABLED"}, {"original_string": "public static final PropertyKey WORK_DIR =\n      new Builder(Name.WORK_DIR)\n          .setDefaultValue(String.format(\"${%s}\", Name.HOME))\n          .setDescription(\"The directory to use for Alluxio's working directory. By default, \"\n              + \"the journal, logs, and under file storage data (if using local filesystem) \"\n              + \"are written here.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORK_DIR =\n      new Builder(Name.WORK_DIR)\n          .setDefaultValue(String.format(\"${%s}\", Name.HOME))\n          .setDescription(\"The directory to use for Alluxio's working directory. By default, \"\n              + \"the journal, logs, and under file storage data (if using local filesystem) \"\n              + \"are written here.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "WORK_DIR"}, {"original_string": "public static final PropertyKey ZOOKEEPER_ADDRESS =\n      new Builder(Name.ZOOKEEPER_ADDRESS)\n          .setDescription(\"Address of ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_ADDRESS =\n      new Builder(Name.ZOOKEEPER_ADDRESS)\n          .setDescription(\"Address of ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "ZOOKEEPER_ADDRESS"}, {"original_string": "public static final PropertyKey ZOOKEEPER_CONNECTION_TIMEOUT =\n      new Builder(Name.ZOOKEEPER_CONNECTION_TIMEOUT)\n          .setDefaultValue(\"15s\") // matches Zookeeper's default\n          .setDescription(\"Connection timeout for Alluxio (job) masters to select \"\n              + \"the leading (job) master when connecting to Zookeeper\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_CONNECTION_TIMEOUT =\n      new Builder(Name.ZOOKEEPER_CONNECTION_TIMEOUT)\n          .setDefaultValue(\"15s\") // matches Zookeeper's default\n          .setDescription(\"Connection timeout for Alluxio (job) masters to select \"\n              + \"the leading (job) master when connecting to Zookeeper\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "ZOOKEEPER_CONNECTION_TIMEOUT"}, {"original_string": "public static final PropertyKey ZOOKEEPER_ELECTION_PATH =\n      new Builder(Name.ZOOKEEPER_ELECTION_PATH)\n          .setDefaultValue(\"/alluxio/election\")\n          .setDescription(\"Election directory in ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_ELECTION_PATH =\n      new Builder(Name.ZOOKEEPER_ELECTION_PATH)\n          .setDefaultValue(\"/alluxio/election\")\n          .setDescription(\"Election directory in ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "ZOOKEEPER_ELECTION_PATH"}, {"original_string": "public static final PropertyKey ZOOKEEPER_ENABLED =\n      new Builder(Name.ZOOKEEPER_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"If true, setup master fault tolerant mode using ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_ENABLED =\n      new Builder(Name.ZOOKEEPER_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"If true, setup master fault tolerant mode using ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "ZOOKEEPER_ENABLED"}, {"original_string": "public static final PropertyKey ZOOKEEPER_LEADER_INQUIRY_RETRY_COUNT =\n      new Builder(Name.ZOOKEEPER_LEADER_INQUIRY_RETRY_COUNT)\n          .setDefaultValue(10)\n          .setDescription(\"The number of retries to inquire leader from ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_LEADER_INQUIRY_RETRY_COUNT =\n      new Builder(Name.ZOOKEEPER_LEADER_INQUIRY_RETRY_COUNT)\n          .setDefaultValue(10)\n          .setDescription(\"The number of retries to inquire leader from ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "ZOOKEEPER_LEADER_INQUIRY_RETRY_COUNT"}, {"original_string": "public static final PropertyKey ZOOKEEPER_LEADER_PATH =\n      new Builder(Name.ZOOKEEPER_LEADER_PATH)\n          .setDefaultValue(\"/alluxio/leader\")\n          .setDescription(\"Leader directory in ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_LEADER_PATH =\n      new Builder(Name.ZOOKEEPER_LEADER_PATH)\n          .setDefaultValue(\"/alluxio/leader\")\n          .setDescription(\"Leader directory in ZooKeeper.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "ZOOKEEPER_LEADER_PATH"}, {"original_string": "public static final PropertyKey ZOOKEEPER_SESSION_TIMEOUT =\n      new Builder(Name.ZOOKEEPER_SESSION_TIMEOUT)\n          .setDefaultValue(\"60s\") // matches Zookeeper's default\n          .setDescription(\"Session timeout to use when connecting to Zookeeper\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_SESSION_TIMEOUT =\n      new Builder(Name.ZOOKEEPER_SESSION_TIMEOUT)\n          .setDefaultValue(\"60s\") // matches Zookeeper's default\n          .setDescription(\"Session timeout to use when connecting to Zookeeper\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "ZOOKEEPER_SESSION_TIMEOUT"}, {"original_string": "public static final PropertyKey ZOOKEEPER_AUTH_ENABLED =\n      new Builder(Name.ZOOKEEPER_AUTH_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"If true, enable client-side Zookeeper authentication.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_AUTH_ENABLED =\n      new Builder(Name.ZOOKEEPER_AUTH_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"If true, enable client-side Zookeeper authentication.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "ZOOKEEPER_AUTH_ENABLED"}, {"original_string": "public static final PropertyKey ZOOKEEPER_LEADER_CONNECTION_ERROR_POLICY =\n      new Builder(Name.ZOOKEEPER_LEADER_CONNECTION_ERROR_POLICY)\n          .setDefaultValue(\"SESSION\")\n          .setDescription(\"Connection error policy defines how errors on zookeeper connections \"\n              + \"to be treated in leader election. \"\n              + \"STANDARD policy treats every connection event as failure.\"\n              + \"SESSION policy relies on zookeeper sessions for judging failures, \"\n              + \"helping leader to retain its status, as long as its session is protected.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_LEADER_CONNECTION_ERROR_POLICY =\n      new Builder(Name.ZOOKEEPER_LEADER_CONNECTION_ERROR_POLICY)\n          .setDefaultValue(\"SESSION\")\n          .setDescription(\"Connection error policy defines how errors on zookeeper connections \"\n              + \"to be treated in leader election. \"\n              + \"STANDARD policy treats every connection event as failure.\"\n              + \"SESSION policy relies on zookeeper sessions for judging failures, \"\n              + \"helping leader to retain its status, as long as its session is protected.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "ZOOKEEPER_LEADER_CONNECTION_ERROR_POLICY"}, {"original_string": "public static final PropertyKey UNDERFS_ALLOW_SET_OWNER_FAILURE =\n      new Builder(Name.UNDERFS_ALLOW_SET_OWNER_FAILURE)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to allow setting owner in UFS to fail. When set to true, \"\n              + \"it is possible file or directory owners diverge between Alluxio and UFS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_ALLOW_SET_OWNER_FAILURE =\n      new Builder(Name.UNDERFS_ALLOW_SET_OWNER_FAILURE)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to allow setting owner in UFS to fail. When set to true, \"\n              + \"it is possible file or directory owners diverge between Alluxio and UFS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "UNDERFS_ALLOW_SET_OWNER_FAILURE"}, {"original_string": "public static final PropertyKey UNDERFS_CLEANUP_ENABLED =\n      new Builder(Name.UNDERFS_CLEANUP_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to clean up under file storage periodically.\"\n              + \"Some ufs operations may not be completed and cleaned up successfully \"\n              + \"in normal ways and leave some intermediate data that needs periodical cleanup.\"\n              + \"If enabled, all the mount points will be cleaned up when a leader master starts \"\n              + \"or cleanup interval is reached. This should be used sparingly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_CLEANUP_ENABLED =\n      new Builder(Name.UNDERFS_CLEANUP_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to clean up under file storage periodically.\"\n              + \"Some ufs operations may not be completed and cleaned up successfully \"\n              + \"in normal ways and leave some intermediate data that needs periodical cleanup.\"\n              + \"If enabled, all the mount points will be cleaned up when a leader master starts \"\n              + \"or cleanup interval is reached. This should be used sparingly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "UNDERFS_CLEANUP_ENABLED"}, {"original_string": "public static final PropertyKey UNDERFS_CLEANUP_INTERVAL =\n      new Builder(Name.UNDERFS_CLEANUP_INTERVAL)\n          .setDefaultValue(\"1day\")\n          .setDescription(\"The interval for periodically cleaning all the \"\n              + \" mounted under file storages.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_CLEANUP_INTERVAL =\n      new Builder(Name.UNDERFS_CLEANUP_INTERVAL)\n          .setDefaultValue(\"1day\")\n          .setDescription(\"The interval for periodically cleaning all the \"\n              + \" mounted under file storages.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "UNDERFS_CLEANUP_INTERVAL"}, {"original_string": "public static final PropertyKey UNDERFS_LISTING_LENGTH =\n      new Builder(Name.UNDERFS_LISTING_LENGTH)\n          .setDefaultValue(1000)\n          .setDescription(\"The maximum number of directory entries to list in a single query \"\n              + \"to under file system. If the total number of entries is greater than the \"\n              + \"specified length, multiple queries will be issued.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_LISTING_LENGTH =\n      new Builder(Name.UNDERFS_LISTING_LENGTH)\n          .setDefaultValue(1000)\n          .setDescription(\"The maximum number of directory entries to list in a single query \"\n              + \"to under file system. If the total number of entries is greater than the \"\n              + \"specified length, multiple queries will be issued.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "UNDERFS_LISTING_LENGTH"}, {"original_string": "public static final PropertyKey UNDERFS_GCS_DEFAULT_MODE =\n      new Builder(Name.UNDERFS_GCS_DEFAULT_MODE)\n          .setDefaultValue(\"0700\")\n          .setDescription(\"Mode (in octal notation) for GCS objects if mode cannot be discovered.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_GCS_DEFAULT_MODE =\n      new Builder(Name.UNDERFS_GCS_DEFAULT_MODE)\n          .setDefaultValue(\"0700\")\n          .setDescription(\"Mode (in octal notation) for GCS objects if mode cannot be discovered.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_GCS_DEFAULT_MODE"}, {"original_string": "public static final PropertyKey UNDERFS_GCS_DIRECTORY_SUFFIX =\n      new Builder(Name.UNDERFS_GCS_DIRECTORY_SUFFIX)\n          .setDefaultValue(\"/\")\n          .setDescription(\"Directories are represented in GCS as zero-byte objects named with \"\n              + \"the specified suffix.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_GCS_DIRECTORY_SUFFIX =\n      new Builder(Name.UNDERFS_GCS_DIRECTORY_SUFFIX)\n          .setDefaultValue(\"/\")\n          .setDescription(\"Directories are represented in GCS as zero-byte objects named with \"\n              + \"the specified suffix.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_GCS_DIRECTORY_SUFFIX"}, {"original_string": "public static final PropertyKey UNDERFS_GCS_OWNER_ID_TO_USERNAME_MAPPING =\n      new Builder(Name.UNDERFS_GCS_OWNER_ID_TO_USERNAME_MAPPING)\n          .setDescription(\"Optionally, specify a preset gcs owner id to Alluxio username \"\n              + \"static mapping in the format \\\"id1=user1;id2=user2\\\". The Google Cloud \"\n              + \"Storage IDs can be found at the console address \"\n              + \"https://console.cloud.google.com/storage/settings . Please use the \"\n              + \"\\\"Owners\\\" one.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_GCS_OWNER_ID_TO_USERNAME_MAPPING =\n      new Builder(Name.UNDERFS_GCS_OWNER_ID_TO_USERNAME_MAPPING)\n          .setDescription(\"Optionally, specify a preset gcs owner id to Alluxio username \"\n              + \"static mapping in the format \\\"id1=user1;id2=user2\\\". The Google Cloud \"\n              + \"Storage IDs can be found at the console address \"\n              + \"https://console.cloud.google.com/storage/settings . Please use the \"\n              + \"\\\"Owners\\\" one.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_GCS_OWNER_ID_TO_USERNAME_MAPPING"}, {"original_string": "public static final PropertyKey UNDERFS_HDFS_CONFIGURATION =\n      new Builder(Name.UNDERFS_HDFS_CONFIGURATION)\n          .setDefaultValue(String.format(\n              \"${%s}/core-site.xml:${%s}/hdfs-site.xml\", Name.CONF_DIR, Name.CONF_DIR))\n          .setDescription(\"Location of the HDFS configuration file to overwrite \"\n              + \"the default HDFS client configuration. Note that, these files must be available\"\n              + \"on every node.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_HDFS_CONFIGURATION =\n      new Builder(Name.UNDERFS_HDFS_CONFIGURATION)\n          .setDefaultValue(String.format(\n              \"${%s}/core-site.xml:${%s}/hdfs-site.xml\", Name.CONF_DIR, Name.CONF_DIR))\n          .setDescription(\"Location of the HDFS configuration file to overwrite \"\n              + \"the default HDFS client configuration. Note that, these files must be available\"\n              + \"on every node.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_HDFS_CONFIGURATION"}, {"original_string": "public static final PropertyKey UNDERFS_HDFS_IMPL =\n      new Builder(Name.UNDERFS_HDFS_IMPL)\n          .setDefaultValue(\"org.apache.hadoop.hdfs.DistributedFileSystem\")\n          .setDescription(\"The implementation class of the HDFS as the under storage system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_HDFS_IMPL =\n      new Builder(Name.UNDERFS_HDFS_IMPL)\n          .setDefaultValue(\"org.apache.hadoop.hdfs.DistributedFileSystem\")\n          .setDescription(\"The implementation class of the HDFS as the under storage system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_HDFS_IMPL"}, {"original_string": "public static final PropertyKey UNDERFS_HDFS_PREFIXES =\n      new Builder(Name.UNDERFS_HDFS_PREFIXES)\n          .setDefaultValue(\"hdfs://,glusterfs:///\")\n          .setDescription(\"Optionally, specify which prefixes should run through the HDFS \"\n              + \"implementation of UnderFileSystem. The delimiter is any whitespace \"\n              + \"and/or ','.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_HDFS_PREFIXES =\n      new Builder(Name.UNDERFS_HDFS_PREFIXES)\n          .setDefaultValue(\"hdfs://,glusterfs:///\")\n          .setDescription(\"Optionally, specify which prefixes should run through the HDFS \"\n              + \"implementation of UnderFileSystem. The delimiter is any whitespace \"\n              + \"and/or ','.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_HDFS_PREFIXES"}, {"original_string": "public static final PropertyKey UNDERFS_HDFS_REMOTE =\n      new Builder(Name.UNDERFS_HDFS_REMOTE)\n          .setDefaultValue(true)\n          .setDescription(\"Boolean indicating whether or not the under storage worker nodes \"\n              + \"are remote with respect to Alluxio worker nodes. If set to true, Alluxio \"\n              + \"will not attempt to discover locality information from the under storage \"\n              + \"because locality is impossible. This will improve performance. The default \"\n              + \"value is true.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_HDFS_REMOTE =\n      new Builder(Name.UNDERFS_HDFS_REMOTE)\n          .setDefaultValue(true)\n          .setDescription(\"Boolean indicating whether or not the under storage worker nodes \"\n              + \"are remote with respect to Alluxio worker nodes. If set to true, Alluxio \"\n              + \"will not attempt to discover locality information from the under storage \"\n              + \"because locality is impossible. This will improve performance. The default \"\n              + \"value is true.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_HDFS_REMOTE"}, {"original_string": "public static final PropertyKey UNDERFS_WEB_HEADER_LAST_MODIFIED =\n      new Builder(Name.UNDERFS_WEB_HEADER_LAST_MODIFIED)\n          .setDefaultValue(\"EEE, dd MMM yyyy HH:mm:ss zzz\")\n          .setDescription(\"Date format of last modified for a http response header.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_WEB_HEADER_LAST_MODIFIED =\n      new Builder(Name.UNDERFS_WEB_HEADER_LAST_MODIFIED)\n          .setDefaultValue(\"EEE, dd MMM yyyy HH:mm:ss zzz\")\n          .setDescription(\"Date format of last modified for a http response header.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_WEB_HEADER_LAST_MODIFIED"}, {"original_string": "public static final PropertyKey UNDERFS_WEB_CONNECTION_TIMEOUT =\n      new Builder(Name.UNDERFS_WEB_CONNECTION_TIMEOUT)\n          .setDefaultValue(\"60s\")\n          .setDescription(\"Default timeout for a http connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_WEB_CONNECTION_TIMEOUT =\n      new Builder(Name.UNDERFS_WEB_CONNECTION_TIMEOUT)\n          .setDefaultValue(\"60s\")\n          .setDescription(\"Default timeout for a http connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_WEB_CONNECTION_TIMEOUT"}, {"original_string": "public static final PropertyKey UNDERFS_WEB_PARENT_NAMES =\n      new Builder(Name.UNDERFS_WEB_PARENT_NAMES)\n          .setDefaultValue(\"Parent Directory,..,../\")\n          .setDescription(\"The text of the http link for the parent directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_WEB_PARENT_NAMES =\n      new Builder(Name.UNDERFS_WEB_PARENT_NAMES)\n          .setDefaultValue(\"Parent Directory,..,../\")\n          .setDescription(\"The text of the http link for the parent directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_WEB_PARENT_NAMES"}, {"original_string": "public static final PropertyKey UNDERFS_WEB_TITLES =\n      new Builder(Name.UNDERFS_WEB_TITLES)\n          .setDefaultValue(\"Index of,Directory listing for\")\n          .setDescription(\"The title of the content for a http url.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_WEB_TITLES =\n      new Builder(Name.UNDERFS_WEB_TITLES)\n          .setDefaultValue(\"Index of,Directory listing for\")\n          .setDescription(\"The title of the content for a http url.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_WEB_TITLES"}, {"original_string": "public static final PropertyKey UNDERFS_OBJECT_STORE_BREADCRUMBS_ENABLED =\n      new Builder(Name.UNDERFS_OBJECT_STORE_BREADCRUMBS_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Set this to false to prevent Alluxio from creating zero byte objects \"\n              + \"during read or list operations on object store UFS. Leaving this on enables more\"\n              + \" efficient listing of prefixes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OBJECT_STORE_BREADCRUMBS_ENABLED =\n      new Builder(Name.UNDERFS_OBJECT_STORE_BREADCRUMBS_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Set this to false to prevent Alluxio from creating zero byte objects \"\n              + \"during read or list operations on object store UFS. Leaving this on enables more\"\n              + \" efficient listing of prefixes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OBJECT_STORE_BREADCRUMBS_ENABLED"}, {"original_string": "public static final PropertyKey UNDERFS_OBJECT_STORE_MULTI_RANGE_CHUNK_SIZE =\n      new Builder(Name.UNDERFS_OBJECT_STORE_MULTI_RANGE_CHUNK_SIZE)\n          .setDefaultValue(String.format(\"${%s}\", Name.USER_BLOCK_SIZE_BYTES_DEFAULT))\n          .setDescription(\"Default chunk size for ranged reads from multi-range object input \"\n              + \"streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OBJECT_STORE_MULTI_RANGE_CHUNK_SIZE =\n      new Builder(Name.UNDERFS_OBJECT_STORE_MULTI_RANGE_CHUNK_SIZE)\n          .setDefaultValue(String.format(\"${%s}\", Name.USER_BLOCK_SIZE_BYTES_DEFAULT))\n          .setDescription(\"Default chunk size for ranged reads from multi-range object input \"\n              + \"streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OBJECT_STORE_MULTI_RANGE_CHUNK_SIZE"}, {"original_string": "public static final PropertyKey UNDERFS_OBJECT_STORE_SERVICE_THREADS =\n      new Builder(Name.UNDERFS_OBJECT_STORE_SERVICE_THREADS)\n          .setDefaultValue(20)\n          .setDescription(\"The number of threads in executor pool for parallel object store \"\n              + \"UFS operations, such as directory renames and deletes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OBJECT_STORE_SERVICE_THREADS =\n      new Builder(Name.UNDERFS_OBJECT_STORE_SERVICE_THREADS)\n          .setDefaultValue(20)\n          .setDescription(\"The number of threads in executor pool for parallel object store \"\n              + \"UFS operations, such as directory renames and deletes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OBJECT_STORE_SERVICE_THREADS"}, {"original_string": "public static final PropertyKey UNDERFS_OBJECT_STORE_MOUNT_SHARED_PUBLICLY =\n      new Builder(Name.UNDERFS_OBJECT_STORE_MOUNT_SHARED_PUBLICLY)\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to share object storage under storage system \"\n              + \"mounted point with all Alluxio users. Note that this configuration has no \"\n              + \"effect on HDFS nor local UFS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OBJECT_STORE_MOUNT_SHARED_PUBLICLY =\n      new Builder(Name.UNDERFS_OBJECT_STORE_MOUNT_SHARED_PUBLICLY)\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to share object storage under storage system \"\n              + \"mounted point with all Alluxio users. Note that this configuration has no \"\n              + \"effect on HDFS nor local UFS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OBJECT_STORE_MOUNT_SHARED_PUBLICLY"}, {"original_string": "public static final PropertyKey UNDERFS_EVENTUAL_CONSISTENCY_RETRY_BASE_SLEEP_MS =\n      new Builder(Name.UNDERFS_EVENTUAL_CONSISTENCY_RETRY_BASE_SLEEP_MS)\n          .setDefaultValue(\"50ms\")\n          .setDescription(\"To handle eventually consistent storage semantics \"\n              + \"for certain under storages, Alluxio will perform retries \"\n              + \"when under storage metadata doesn't match Alluxio's expectations. \"\n              + \"These retries use exponential backoff. \"\n              + \"This property determines the base time for the exponential backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_EVENTUAL_CONSISTENCY_RETRY_BASE_SLEEP_MS =\n      new Builder(Name.UNDERFS_EVENTUAL_CONSISTENCY_RETRY_BASE_SLEEP_MS)\n          .setDefaultValue(\"50ms\")\n          .setDescription(\"To handle eventually consistent storage semantics \"\n              + \"for certain under storages, Alluxio will perform retries \"\n              + \"when under storage metadata doesn't match Alluxio's expectations. \"\n              + \"These retries use exponential backoff. \"\n              + \"This property determines the base time for the exponential backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_EVENTUAL_CONSISTENCY_RETRY_BASE_SLEEP_MS"}, {"original_string": "public static final PropertyKey UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_NUM =\n      new Builder(Name.UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_NUM)\n          .setDefaultValue(20)\n          .setDescription(\"To handle eventually consistent storage semantics \"\n              + \"for certain under storages, Alluxio will perform retries \"\n              + \"when under storage metadata doesn't match Alluxio's expectations. \"\n              + \"These retries use exponential backoff. \"\n              + \"This property determines the maximum number of retries.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_NUM =\n      new Builder(Name.UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_NUM)\n          .setDefaultValue(20)\n          .setDescription(\"To handle eventually consistent storage semantics \"\n              + \"for certain under storages, Alluxio will perform retries \"\n              + \"when under storage metadata doesn't match Alluxio's expectations. \"\n              + \"These retries use exponential backoff. \"\n              + \"This property determines the maximum number of retries.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_NUM"}, {"original_string": "public static final PropertyKey UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_SLEEP_MS =\n      new Builder(Name.UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_SLEEP_MS)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"To handle eventually consistent storage semantics \"\n              + \"for certain under storages, Alluxio will perform retries \"\n              + \"when under storage metadata doesn't match Alluxio's expectations. \"\n              + \"These retries use exponential backoff. \"\n              + \"This property determines the maximum wait time in the backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_SLEEP_MS =\n      new Builder(Name.UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_SLEEP_MS)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"To handle eventually consistent storage semantics \"\n              + \"for certain under storages, Alluxio will perform retries \"\n              + \"when under storage metadata doesn't match Alluxio's expectations. \"\n              + \"These retries use exponential backoff. \"\n              + \"This property determines the maximum wait time in the backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_EVENTUAL_CONSISTENCY_RETRY_MAX_SLEEP_MS"}, {"original_string": "public static final PropertyKey UNDERFS_OSS_CONNECT_MAX =\n      new Builder(Name.UNDERFS_OSS_CONNECT_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of OSS connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OSS_CONNECT_MAX =\n      new Builder(Name.UNDERFS_OSS_CONNECT_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of OSS connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OSS_CONNECT_MAX"}, {"original_string": "public static final PropertyKey UNDERFS_OSS_CONNECT_TIMEOUT =\n      new Builder(Name.UNDERFS_OSS_CONNECT_TIMEOUT)\n          .setAlias(\"alluxio.underfs.oss.connection.timeout.ms\")\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout when connecting to OSS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OSS_CONNECT_TIMEOUT =\n      new Builder(Name.UNDERFS_OSS_CONNECT_TIMEOUT)\n          .setAlias(\"alluxio.underfs.oss.connection.timeout.ms\")\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout when connecting to OSS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OSS_CONNECT_TIMEOUT"}, {"original_string": "public static final PropertyKey UNDERFS_OSS_CONNECT_TTL =\n      new Builder(Name.UNDERFS_OSS_CONNECT_TTL)\n          .setDefaultValue(-1)\n          .setDescription(\"The TTL of OSS connections in ms.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OSS_CONNECT_TTL =\n      new Builder(Name.UNDERFS_OSS_CONNECT_TTL)\n          .setDefaultValue(-1)\n          .setDescription(\"The TTL of OSS connections in ms.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OSS_CONNECT_TTL"}, {"original_string": "public static final PropertyKey UNDERFS_OSS_SOCKET_TIMEOUT =\n      new Builder(Name.UNDERFS_OSS_SOCKET_TIMEOUT)\n          .setAlias(\"alluxio.underfs.oss.socket.timeout.ms\")\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout of OSS socket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_OSS_SOCKET_TIMEOUT =\n      new Builder(Name.UNDERFS_OSS_SOCKET_TIMEOUT)\n          .setAlias(\"alluxio.underfs.oss.socket.timeout.ms\")\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout of OSS socket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_OSS_SOCKET_TIMEOUT"}, {"original_string": "public static final PropertyKey UNDERFS_S3_ADMIN_THREADS_MAX =\n      new Builder(Name.UNDERFS_S3_ADMIN_THREADS_MAX)\n          .setDefaultValue(20)\n          .setDescription(\"The maximum number of threads to use for metadata operations when \"\n              + \"communicating with S3. These operations may be fairly concurrent and \"\n              + \"frequent but should not take much time to process.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_ADMIN_THREADS_MAX =\n      new Builder(Name.UNDERFS_S3_ADMIN_THREADS_MAX)\n          .setDefaultValue(20)\n          .setDescription(\"The maximum number of threads to use for metadata operations when \"\n              + \"communicating with S3. These operations may be fairly concurrent and \"\n              + \"frequent but should not take much time to process.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_ADMIN_THREADS_MAX"}, {"original_string": "public static final PropertyKey UNDERFS_S3_DISABLE_DNS_BUCKETS =\n      new Builder(Name.UNDERFS_S3_DISABLE_DNS_BUCKETS)\n          .setDefaultValue(false)\n          .setDescription(\"Optionally, specify to make all S3 requests path style.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_DISABLE_DNS_BUCKETS =\n      new Builder(Name.UNDERFS_S3_DISABLE_DNS_BUCKETS)\n          .setDefaultValue(false)\n          .setDescription(\"Optionally, specify to make all S3 requests path style.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_DISABLE_DNS_BUCKETS"}, {"original_string": "public static final PropertyKey UNDERFS_S3_ENDPOINT =\n      new Builder(Name.UNDERFS_S3_ENDPOINT)\n          .setDescription(\"Optionally, to reduce data latency or visit resources which are \"\n              + \"separated in different AWS regions, specify a regional endpoint to make aws \"\n              + \"requests. An endpoint is a URL that is the entry point for a web service. \"\n              + \"For example, s3.cn-north-1.amazonaws.com.cn is an entry point for the Amazon \"\n              + \"S3 service in beijing region.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_ENDPOINT =\n      new Builder(Name.UNDERFS_S3_ENDPOINT)\n          .setDescription(\"Optionally, to reduce data latency or visit resources which are \"\n              + \"separated in different AWS regions, specify a regional endpoint to make aws \"\n              + \"requests. An endpoint is a URL that is the entry point for a web service. \"\n              + \"For example, s3.cn-north-1.amazonaws.com.cn is an entry point for the Amazon \"\n              + \"S3 service in beijing region.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_ENDPOINT"}, {"original_string": "public static final PropertyKey UNDERFS_S3_OWNER_ID_TO_USERNAME_MAPPING =\n      new Builder(Name.UNDERFS_S3_OWNER_ID_TO_USERNAME_MAPPING)\n          .setDescription(\"Optionally, specify a preset s3 canonical id to Alluxio username \"\n              + \"static mapping, in the format \\\"id1=user1;id2=user2\\\". The AWS S3 canonical \"\n              + \"ID can be found at the console address \"\n              + \"https://console.aws.amazon.com/iam/home?#security_credential . Please expand \"\n              + \"the \\\"Account Identifiers\\\" tab and refer to \\\"Canonical User ID\\\". \"\n              + \"Unspecified owner id will map to a default empty username\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_OWNER_ID_TO_USERNAME_MAPPING =\n      new Builder(Name.UNDERFS_S3_OWNER_ID_TO_USERNAME_MAPPING)\n          .setDescription(\"Optionally, specify a preset s3 canonical id to Alluxio username \"\n              + \"static mapping, in the format \\\"id1=user1;id2=user2\\\". The AWS S3 canonical \"\n              + \"ID can be found at the console address \"\n              + \"https://console.aws.amazon.com/iam/home?#security_credential . Please expand \"\n              + \"the \\\"Account Identifiers\\\" tab and refer to \\\"Canonical User ID\\\". \"\n              + \"Unspecified owner id will map to a default empty username\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_OWNER_ID_TO_USERNAME_MAPPING"}, {"original_string": "public static final PropertyKey UNDERFS_S3_PROXY_HOST =\n      new Builder(Name.UNDERFS_S3_PROXY_HOST)\n          .setDescription(\"Optionally, specify a proxy host for communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_PROXY_HOST =\n      new Builder(Name.UNDERFS_S3_PROXY_HOST)\n          .setDescription(\"Optionally, specify a proxy host for communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_PROXY_HOST"}, {"original_string": "public static final PropertyKey UNDERFS_S3_PROXY_PORT =\n      new Builder(Name.UNDERFS_S3_PROXY_PORT)\n          .setDescription(\"Optionally, specify a proxy port for communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_PROXY_PORT =\n      new Builder(Name.UNDERFS_S3_PROXY_PORT)\n          .setDescription(\"Optionally, specify a proxy port for communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_PROXY_PORT"}, {"original_string": "public static final PropertyKey UNDERFS_S3_THREADS_MAX =\n      new Builder(Name.UNDERFS_S3_THREADS_MAX)\n          .setDefaultValue(40)\n          .setDescription(\"The maximum number of threads to use for communicating with S3 and \"\n              + \"the maximum number of concurrent connections to S3. Includes both threads \"\n              + \"for data upload and metadata operations. This number should be at least as \"\n              + \"large as the max admin threads plus max upload threads.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_THREADS_MAX =\n      new Builder(Name.UNDERFS_S3_THREADS_MAX)\n          .setDefaultValue(40)\n          .setDescription(\"The maximum number of threads to use for communicating with S3 and \"\n              + \"the maximum number of concurrent connections to S3. Includes both threads \"\n              + \"for data upload and metadata operations. This number should be at least as \"\n              + \"large as the max admin threads plus max upload threads.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_THREADS_MAX"}, {"original_string": "public static final PropertyKey UNDERFS_S3_UPLOAD_THREADS_MAX =\n      new Builder(Name.UNDERFS_S3_UPLOAD_THREADS_MAX)\n          .setDefaultValue(20)\n          .setDescription(\"For an Alluxio worker, this is the maximum number of threads to use \"\n              + \"for uploading data to S3 for multipart uploads. These operations can be fairly \"\n              + \"expensive, so multiple threads are encouraged. However, this also splits the \"\n              + \"bandwidth between threads, meaning the overall latency for completing an upload \"\n              + \"will be higher for more threads. For the Alluxio master, this is the maximum \"\n              + \"number of threads used for the rename (copy) operation. It is recommended that \"\n              + \"value should be greater than or equal to \"\n              + Name.UNDERFS_OBJECT_STORE_SERVICE_THREADS)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_UPLOAD_THREADS_MAX =\n      new Builder(Name.UNDERFS_S3_UPLOAD_THREADS_MAX)\n          .setDefaultValue(20)\n          .setDescription(\"For an Alluxio worker, this is the maximum number of threads to use \"\n              + \"for uploading data to S3 for multipart uploads. These operations can be fairly \"\n              + \"expensive, so multiple threads are encouraged. However, this also splits the \"\n              + \"bandwidth between threads, meaning the overall latency for completing an upload \"\n              + \"will be higher for more threads. For the Alluxio master, this is the maximum \"\n              + \"number of threads used for the rename (copy) operation. It is recommended that \"\n              + \"value should be greater than or equal to \"\n              + Name.UNDERFS_OBJECT_STORE_SERVICE_THREADS)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_UPLOAD_THREADS_MAX"}, {"original_string": "public static final PropertyKey UNDERFS_S3_DEFAULT_MODE =\n      new Builder(Name.UNDERFS_S3_DEFAULT_MODE)\n          .setAlias(\"alluxio.underfs.s3a.default.mode\")\n          .setDefaultValue(\"0700\")\n          .setDescription(\"Mode (in octal notation) for S3 objects if mode cannot be discovered.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_DEFAULT_MODE =\n      new Builder(Name.UNDERFS_S3_DEFAULT_MODE)\n          .setAlias(\"alluxio.underfs.s3a.default.mode\")\n          .setDefaultValue(\"0700\")\n          .setDescription(\"Mode (in octal notation) for S3 objects if mode cannot be discovered.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_DEFAULT_MODE"}, {"original_string": "public static final PropertyKey UNDERFS_S3_DIRECTORY_SUFFIX =\n      new Builder(Name.UNDERFS_S3_DIRECTORY_SUFFIX)\n          .setAlias(\"alluxio.underfs.s3a.directory.suffix\")\n          .setDefaultValue(\"/\")\n          .setDescription(\"Directories are represented in S3 as zero-byte objects named with \"\n              + \"the specified suffix.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_DIRECTORY_SUFFIX =\n      new Builder(Name.UNDERFS_S3_DIRECTORY_SUFFIX)\n          .setAlias(\"alluxio.underfs.s3a.directory.suffix\")\n          .setDefaultValue(\"/\")\n          .setDescription(\"Directories are represented in S3 as zero-byte objects named with \"\n              + \"the specified suffix.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_DIRECTORY_SUFFIX"}, {"original_string": "public static final PropertyKey UNDERFS_S3_BULK_DELETE_ENABLED =\n      new Builder(Name.UNDERFS_S3_BULK_DELETE_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.bulk.delete.enabled\")\n          .setDefaultValue(true)\n          .setIsHidden(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_BULK_DELETE_ENABLED =\n      new Builder(Name.UNDERFS_S3_BULK_DELETE_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.bulk.delete.enabled\")\n          .setDefaultValue(true)\n          .setIsHidden(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_BULK_DELETE_ENABLED"}, {"original_string": "public static final PropertyKey UNDERFS_S3_INHERIT_ACL =\n      new Builder(Name.UNDERFS_S3_INHERIT_ACL)\n          .setAlias(\"alluxio.underfs.s3a.inherit_acl\")\n          .setDefaultValue(true)\n          .setDescription(\"Set this property to false to disable inheriting bucket ACLs on \"\n              + \"objects. Note that the translation from bucket ACLs to Alluxio user permissions \"\n              + \"is best effort as some S3-like storage services doe not implement ACLs fully \"\n              + \"compatible with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_INHERIT_ACL =\n      new Builder(Name.UNDERFS_S3_INHERIT_ACL)\n          .setAlias(\"alluxio.underfs.s3a.inherit_acl\")\n          .setDefaultValue(true)\n          .setDescription(\"Set this property to false to disable inheriting bucket ACLs on \"\n              + \"objects. Note that the translation from bucket ACLs to Alluxio user permissions \"\n              + \"is best effort as some S3-like storage services doe not implement ACLs fully \"\n              + \"compatible with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_INHERIT_ACL"}, {"original_string": "public static final PropertyKey UNDERFS_S3_INTERMEDIATE_UPLOAD_CLEAN_AGE =\n      new Builder(Name.UNDERFS_S3_INTERMEDIATE_UPLOAD_CLEAN_AGE)\n          .setAlias(\"alluxio.underfs.s3a.intermediate.upload.clean.age\")\n          .setDefaultValue(\"3day\")\n          .setDescription(\"Streaming uploads may not have been completed/aborted correctly \"\n              + \"and need periodical ufs cleanup. If ufs cleanup is enabled, \"\n              + \"intermediate multipart uploads in all non-readonly S3 mount points \"\n              + \"older than this age will be cleaned. This may impact other \"\n              + \"ongoing upload operations, so a large clean age is encouraged.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_INTERMEDIATE_UPLOAD_CLEAN_AGE =\n      new Builder(Name.UNDERFS_S3_INTERMEDIATE_UPLOAD_CLEAN_AGE)\n          .setAlias(\"alluxio.underfs.s3a.intermediate.upload.clean.age\")\n          .setDefaultValue(\"3day\")\n          .setDescription(\"Streaming uploads may not have been completed/aborted correctly \"\n              + \"and need periodical ufs cleanup. If ufs cleanup is enabled, \"\n              + \"intermediate multipart uploads in all non-readonly S3 mount points \"\n              + \"older than this age will be cleaned. This may impact other \"\n              + \"ongoing upload operations, so a large clean age is encouraged.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_INTERMEDIATE_UPLOAD_CLEAN_AGE"}, {"original_string": "public static final PropertyKey UNDERFS_S3_LIST_OBJECTS_V1 =\n      new Builder(Name.UNDERFS_S3_LIST_OBJECTS_V1)\n          .setAlias(\"alluxio.underfs.s3a.list.objects.v1\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether to use version 1 of GET Bucket (List Objects) API.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_LIST_OBJECTS_V1 =\n      new Builder(Name.UNDERFS_S3_LIST_OBJECTS_V1)\n          .setAlias(\"alluxio.underfs.s3a.list.objects.v1\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether to use version 1 of GET Bucket (List Objects) API.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_LIST_OBJECTS_V1"}, {"original_string": "public static final PropertyKey UNDERFS_S3_MAX_ERROR_RETRY =\n      new Builder(Name.UNDERFS_S3_MAX_ERROR_RETRY)\n          .setAlias(\"alluxio.underfs.s3a.max.error.retry\")\n          .setDescription(\"The maximum number of retry attempts for failed retryable requests.\"\n              + \"Setting this property will override the AWS SDK default.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_MAX_ERROR_RETRY =\n      new Builder(Name.UNDERFS_S3_MAX_ERROR_RETRY)\n          .setAlias(\"alluxio.underfs.s3a.max.error.retry\")\n          .setDescription(\"The maximum number of retry attempts for failed retryable requests.\"\n              + \"Setting this property will override the AWS SDK default.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_MAX_ERROR_RETRY"}, {"original_string": "public static final PropertyKey UNDERFS_S3_REQUEST_TIMEOUT =\n      new Builder(Name.UNDERFS_S3_REQUEST_TIMEOUT)\n          .setAlias(\"alluxio.underfs.s3a.request.timeout.ms\", \"alluxio.underfs.s3a.request.timeout\")\n          .setDefaultValue(\"1min\")\n          .setDescription(\"The timeout for a single request to S3. Infinity if set to 0. \"\n              + \"Setting this property to a non-zero value can improve performance by \"\n              + \"avoiding the long tail of requests to S3. For very slow connections to S3, \"\n              + \"consider increasing this value or setting it to 0.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_REQUEST_TIMEOUT =\n      new Builder(Name.UNDERFS_S3_REQUEST_TIMEOUT)\n          .setAlias(\"alluxio.underfs.s3a.request.timeout.ms\", \"alluxio.underfs.s3a.request.timeout\")\n          .setDefaultValue(\"1min\")\n          .setDescription(\"The timeout for a single request to S3. Infinity if set to 0. \"\n              + \"Setting this property to a non-zero value can improve performance by \"\n              + \"avoiding the long tail of requests to S3. For very slow connections to S3, \"\n              + \"consider increasing this value or setting it to 0.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_REQUEST_TIMEOUT"}, {"original_string": "public static final PropertyKey UNDERFS_S3_SECURE_HTTP_ENABLED =\n      new Builder(Name.UNDERFS_S3_SECURE_HTTP_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.secure.http.enabled\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to use HTTPS protocol when communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_SECURE_HTTP_ENABLED =\n      new Builder(Name.UNDERFS_S3_SECURE_HTTP_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.secure.http.enabled\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to use HTTPS protocol when communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_SECURE_HTTP_ENABLED"}, {"original_string": "public static final PropertyKey UNDERFS_S3_SERVER_SIDE_ENCRYPTION_ENABLED =\n      new Builder(Name.UNDERFS_S3_SERVER_SIDE_ENCRYPTION_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.server.side.encryption.enabled\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to encrypt data stored in S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_SERVER_SIDE_ENCRYPTION_ENABLED =\n      new Builder(Name.UNDERFS_S3_SERVER_SIDE_ENCRYPTION_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.server.side.encryption.enabled\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to encrypt data stored in S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_SERVER_SIDE_ENCRYPTION_ENABLED"}, {"original_string": "public static final PropertyKey UNDERFS_S3_SIGNER_ALGORITHM =\n      new Builder(Name.UNDERFS_S3_SIGNER_ALGORITHM)\n          .setAlias(\"alluxio.underfs.s3a.signer.algorithm\")\n          .setDescription(\"The signature algorithm which should be used to sign requests to \"\n              + \"the s3 service. This is optional, and if not set, the client will \"\n              + \"automatically determine it. For interacting with an S3 endpoint which only \"\n              + \"supports v2 signatures, set this to \\\"S3SignerType\\\".\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_SIGNER_ALGORITHM =\n      new Builder(Name.UNDERFS_S3_SIGNER_ALGORITHM)\n          .setAlias(\"alluxio.underfs.s3a.signer.algorithm\")\n          .setDescription(\"The signature algorithm which should be used to sign requests to \"\n              + \"the s3 service. This is optional, and if not set, the client will \"\n              + \"automatically determine it. For interacting with an S3 endpoint which only \"\n              + \"supports v2 signatures, set this to \\\"S3SignerType\\\".\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_SIGNER_ALGORITHM"}, {"original_string": "public static final PropertyKey UNDERFS_S3_CONNECT_TTL =\n      new Builder(Name.UNDERFS_S3_CONNECT_TTL)\n          .setDefaultValue(-1)\n          .setDescription(\"The expiration time of S3 connections in ms. -1 means the connection \"\n            + \"will never expire.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_CONNECT_TTL =\n      new Builder(Name.UNDERFS_S3_CONNECT_TTL)\n          .setDefaultValue(-1)\n          .setDescription(\"The expiration time of S3 connections in ms. -1 means the connection \"\n            + \"will never expire.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_CONNECT_TTL"}, {"original_string": "public static final PropertyKey UNDERFS_S3_SOCKET_TIMEOUT =\n      new Builder(Name.UNDERFS_S3_SOCKET_TIMEOUT)\n          .setAlias(\"alluxio.underfs.s3a.socket.timeout.ms\", \"alluxio.underfs.s3a.socket.timeout\")\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"Length of the socket timeout when communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_SOCKET_TIMEOUT =\n      new Builder(Name.UNDERFS_S3_SOCKET_TIMEOUT)\n          .setAlias(\"alluxio.underfs.s3a.socket.timeout.ms\", \"alluxio.underfs.s3a.socket.timeout\")\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"Length of the socket timeout when communicating with S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_SOCKET_TIMEOUT"}, {"original_string": "public static final PropertyKey UNDERFS_S3_STREAMING_UPLOAD_ENABLED =\n      new Builder(Name.UNDERFS_S3_STREAMING_UPLOAD_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.streaming.upload.enabled\")\n          .setDefaultValue(false)\n          .setDescription(\"(Experimental) If true, using streaming upload to write to S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_STREAMING_UPLOAD_ENABLED =\n      new Builder(Name.UNDERFS_S3_STREAMING_UPLOAD_ENABLED)\n          .setAlias(\"alluxio.underfs.s3a.streaming.upload.enabled\")\n          .setDefaultValue(false)\n          .setDescription(\"(Experimental) If true, using streaming upload to write to S3.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_STREAMING_UPLOAD_ENABLED"}, {"original_string": "public static final PropertyKey UNDERFS_S3_STREAMING_UPLOAD_PARTITION_SIZE =\n      new Builder(Name.UNDERFS_S3_STREAMING_UPLOAD_PARTITION_SIZE)\n          .setAlias(\"alluxio.underfs.s3a.streaming.upload.partition.size\")\n          .setDefaultValue(\"64MB\")\n          .setDescription(\"Maximum allowable size of a single buffer file when using \"\n              + \"S3A streaming upload. When the buffer file reaches the partition size, \"\n              + \"it will be uploaded and the upcoming data will write to other buffer files.\"\n              + \"If the partition size is too small, S3A upload speed might be affected. \")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_S3_STREAMING_UPLOAD_PARTITION_SIZE =\n      new Builder(Name.UNDERFS_S3_STREAMING_UPLOAD_PARTITION_SIZE)\n          .setAlias(\"alluxio.underfs.s3a.streaming.upload.partition.size\")\n          .setDefaultValue(\"64MB\")\n          .setDescription(\"Maximum allowable size of a single buffer file when using \"\n              + \"S3A streaming upload. When the buffer file reaches the partition size, \"\n              + \"it will be uploaded and the upcoming data will write to other buffer files.\"\n              + \"If the partition size is too small, S3A upload speed might be affected. \")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_S3_STREAMING_UPLOAD_PARTITION_SIZE"}, {"original_string": "public static final PropertyKey UNDERFS_KODO_REQUESTS_MAX =\n      new Builder(Name.UNDERFS_KODO_REQUESTS_MAX)\n          .setDefaultValue(64)\n          .setDescription(\"The maximum number of kodo connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_KODO_REQUESTS_MAX =\n      new Builder(Name.UNDERFS_KODO_REQUESTS_MAX)\n          .setDefaultValue(64)\n          .setDescription(\"The maximum number of kodo connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_KODO_REQUESTS_MAX"}, {"original_string": "public static final PropertyKey UNDERFS_KODO_CONNECT_TIMEOUT =\n      new Builder(Name.UNDERFS_KODO_CONNECT_TIMEOUT)\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The connect timeout of kodo.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_KODO_CONNECT_TIMEOUT =\n      new Builder(Name.UNDERFS_KODO_CONNECT_TIMEOUT)\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The connect timeout of kodo.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "UNDERFS_KODO_CONNECT_TIMEOUT"}, {"original_string": "public static final PropertyKey GCS_ACCESS_KEY = new Builder(Name.GCS_ACCESS_KEY)\n      .setDescription(\"The access key of GCS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "GCS_ACCESS_KEY = new Builder(Name.GCS_ACCESS_KEY)\n      .setDescription(\"The access key of GCS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "GCS_ACCESS_KEY"}, {"original_string": "public static final PropertyKey GCS_SECRET_KEY = new Builder(Name.GCS_SECRET_KEY)\n      .setDescription(\"The secret key of GCS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "GCS_SECRET_KEY = new Builder(Name.GCS_SECRET_KEY)\n      .setDescription(\"The secret key of GCS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "GCS_SECRET_KEY"}, {"original_string": "public static final PropertyKey OSS_ACCESS_KEY = new Builder(Name.OSS_ACCESS_KEY)\n      .setDescription(\"The access key of OSS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "OSS_ACCESS_KEY = new Builder(Name.OSS_ACCESS_KEY)\n      .setDescription(\"The access key of OSS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "OSS_ACCESS_KEY"}, {"original_string": "public static final PropertyKey OSS_ENDPOINT_KEY = new Builder(Name.OSS_ENDPOINT_KEY)\n      .setDescription(\"The endpoint key of OSS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "OSS_ENDPOINT_KEY = new Builder(Name.OSS_ENDPOINT_KEY)\n      .setDescription(\"The endpoint key of OSS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .build()", "var_name": "OSS_ENDPOINT_KEY"}, {"original_string": "public static final PropertyKey OSS_SECRET_KEY = new Builder(Name.OSS_SECRET_KEY)\n      .setDescription(\"The secret key of OSS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "OSS_SECRET_KEY = new Builder(Name.OSS_SECRET_KEY)\n      .setDescription(\"The secret key of OSS bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "OSS_SECRET_KEY"}, {"original_string": "public static final PropertyKey S3A_ACCESS_KEY = new Builder(Name.S3A_ACCESS_KEY)\n      .setDescription(\"The access key of S3 bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "S3A_ACCESS_KEY = new Builder(Name.S3A_ACCESS_KEY)\n      .setDescription(\"The access key of S3 bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "S3A_ACCESS_KEY"}, {"original_string": "public static final PropertyKey S3A_SECRET_KEY = new Builder(Name.S3A_SECRET_KEY)\n      .setDescription(\"The secret key of S3 bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "S3A_SECRET_KEY = new Builder(Name.S3A_SECRET_KEY)\n      .setDescription(\"The secret key of S3 bucket.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.SERVER)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "S3A_SECRET_KEY"}, {"original_string": "public static final PropertyKey SWIFT_AUTH_METHOD_KEY = new Builder(Name.SWIFT_AUTH_METHOD_KEY)\n      .setDescription(\"Choice of authentication method: \"\n          + \"[tempauth (default), swiftauth, keystone, keystonev3].\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_AUTH_METHOD_KEY = new Builder(Name.SWIFT_AUTH_METHOD_KEY)\n      .setDescription(\"Choice of authentication method: \"\n          + \"[tempauth (default), swiftauth, keystone, keystonev3].\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build()", "var_name": "SWIFT_AUTH_METHOD_KEY"}, {"original_string": "public static final PropertyKey SWIFT_AUTH_URL_KEY = new Builder(Name.SWIFT_AUTH_URL_KEY)\n      .setDescription(\"Authentication URL for REST server, e.g., http://server:8090/auth/v1.0.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_AUTH_URL_KEY = new Builder(Name.SWIFT_AUTH_URL_KEY)\n      .setDescription(\"Authentication URL for REST server, e.g., http://server:8090/auth/v1.0.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build()", "var_name": "SWIFT_AUTH_URL_KEY"}, {"original_string": "public static final PropertyKey SWIFT_PASSWORD_KEY = new Builder(Name.SWIFT_PASSWORD_KEY)\n      .setDescription(\"The password used for user:tenant authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_PASSWORD_KEY = new Builder(Name.SWIFT_PASSWORD_KEY)\n      .setDescription(\"The password used for user:tenant authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "SWIFT_PASSWORD_KEY"}, {"original_string": "public static final PropertyKey SWIFT_SIMULATION = new Builder(Name.SWIFT_SIMULATION)\n      .setDescription(\"Whether to simulate a single node Swift backend for testing purposes: \"\n          + \"true or false (default).\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_SIMULATION = new Builder(Name.SWIFT_SIMULATION)\n      .setDescription(\"Whether to simulate a single node Swift backend for testing purposes: \"\n          + \"true or false (default).\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build()", "var_name": "SWIFT_SIMULATION"}, {"original_string": "public static final PropertyKey SWIFT_TENANT_KEY = new Builder(Name.SWIFT_TENANT_KEY)\n      .setDescription(\"Swift user for authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_TENANT_KEY = new Builder(Name.SWIFT_TENANT_KEY)\n      .setDescription(\"Swift user for authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "SWIFT_TENANT_KEY"}, {"original_string": "public static final PropertyKey SWIFT_USER_KEY = new Builder(Name.SWIFT_USER_KEY)\n      .setDescription(\"Swift tenant for authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_USER_KEY = new Builder(Name.SWIFT_USER_KEY)\n      .setDescription(\"Swift tenant for authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setDisplayType(DisplayType.CREDENTIALS)\n      .build()", "var_name": "SWIFT_USER_KEY"}, {"original_string": "public static final PropertyKey SWIFT_REGION_KEY = new Builder(Name.SWIFT_REGION_KEY)\n      .setDescription(\"Service region when using Keystone authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SWIFT_REGION_KEY = new Builder(Name.SWIFT_REGION_KEY)\n      .setDescription(\"Service region when using Keystone authentication.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .build()", "var_name": "SWIFT_REGION_KEY"}, {"original_string": "public static final PropertyKey COS_ACCESS_KEY =\n      new Builder(Name.COS_ACCESS_KEY)\n          .setDescription(\"The access key of COS bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_ACCESS_KEY =\n      new Builder(Name.COS_ACCESS_KEY)\n          .setDescription(\"The access key of COS bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build()", "var_name": "COS_ACCESS_KEY"}, {"original_string": "public static final PropertyKey COS_APP_ID =\n      new Builder(Name.COS_APP_ID)\n          .setDescription(\"The app id of COS bucket.\")\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_APP_ID =\n      new Builder(Name.COS_APP_ID)\n          .setDescription(\"The app id of COS bucket.\")\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "COS_APP_ID"}, {"original_string": "public static final PropertyKey COS_CONNECTION_MAX =\n      new Builder(Name.COS_CONNECTION_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of COS connections.\")\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_CONNECTION_MAX =\n      new Builder(Name.COS_CONNECTION_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of COS connections.\")\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "COS_CONNECTION_MAX"}, {"original_string": "public static final PropertyKey COS_CONNECTION_TIMEOUT =\n      new Builder(Name.COS_CONNECTION_TIMEOUT)\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout of connecting to COS.\")\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_CONNECTION_TIMEOUT =\n      new Builder(Name.COS_CONNECTION_TIMEOUT)\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout of connecting to COS.\")\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "COS_CONNECTION_TIMEOUT"}, {"original_string": "public static final PropertyKey COS_SOCKET_TIMEOUT =\n      new Builder(Name.COS_SOCKET_TIMEOUT)\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout of COS socket.\")\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_SOCKET_TIMEOUT =\n      new Builder(Name.COS_SOCKET_TIMEOUT)\n          .setDefaultValue(\"50sec\")\n          .setDescription(\"The timeout of COS socket.\")\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "COS_SOCKET_TIMEOUT"}, {"original_string": "public static final PropertyKey COS_REGION =\n      new Builder(Name.COS_REGION)\n          .setDescription(\"The region name of COS bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_REGION =\n      new Builder(Name.COS_REGION)\n          .setDescription(\"The region name of COS bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "COS_REGION"}, {"original_string": "public static final PropertyKey COS_SECRET_KEY =\n      new Builder(Name.COS_SECRET_KEY)\n          .setDescription(\"The secret key of COS bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "COS_SECRET_KEY =\n      new Builder(Name.COS_SECRET_KEY)\n          .setDescription(\"The secret key of COS bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build()", "var_name": "COS_SECRET_KEY"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_UFS_OPTION =\n      new Builder(Template.MASTER_JOURNAL_UFS_OPTION)\n          .setDescription(\"The configuration to use for the journal operations.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_UFS_OPTION =\n      new Builder(Template.MASTER_JOURNAL_UFS_OPTION)\n          .setDescription(\"The configuration to use for the journal operations.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_UFS_OPTION"}, {"original_string": "public static final PropertyKey KODO_ACCESS_KEY =\n      new Builder(Name.KODO_ACCESS_KEY)\n          .setDescription(\"The access key of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "KODO_ACCESS_KEY =\n      new Builder(Name.KODO_ACCESS_KEY)\n          .setDescription(\"The access key of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build()", "var_name": "KODO_ACCESS_KEY"}, {"original_string": "public static final PropertyKey KODO_SECRET_KEY =\n      new Builder(Name.KODO_SECRET_KEY)\n          .setDescription(\"The secret key of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "KODO_SECRET_KEY =\n      new Builder(Name.KODO_SECRET_KEY)\n          .setDescription(\"The secret key of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .setDisplayType(DisplayType.CREDENTIALS)\n          .build()", "var_name": "KODO_SECRET_KEY"}, {"original_string": "public static final PropertyKey KODO_DOWNLOAD_HOST =\n      new Builder(Name.KODO_DOWNLOAD_HOST)\n          .setDescription(\"The download domain of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "KODO_DOWNLOAD_HOST =\n      new Builder(Name.KODO_DOWNLOAD_HOST)\n          .setDescription(\"The download domain of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "KODO_DOWNLOAD_HOST"}, {"original_string": "public static final PropertyKey KODO_ENDPOINT =\n      new Builder(Name.KODO_ENDPOINT)\n          .setDescription(\"The endpoint of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "KODO_ENDPOINT =\n      new Builder(Name.KODO_ENDPOINT)\n          .setDescription(\"The endpoint of Kodo bucket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "KODO_ENDPOINT"}, {"original_string": "public static final PropertyKey MASTER_MOUNT_TABLE_ROOT_ALLUXIO =\n      new Builder(Template.MASTER_MOUNT_TABLE_ALLUXIO, \"root\")\n          .setDefaultValue(\"/\")\n          .setDescription(\"Alluxio root mount point.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_MOUNT_TABLE_ROOT_ALLUXIO =\n      new Builder(Template.MASTER_MOUNT_TABLE_ALLUXIO, \"root\")\n          .setDefaultValue(\"/\")\n          .setDescription(\"Alluxio root mount point.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_MOUNT_TABLE_ROOT_ALLUXIO"}, {"original_string": "public static final PropertyKey MASTER_MOUNT_TABLE_ROOT_OPTION =\n      new Builder(Template.MASTER_MOUNT_TABLE_OPTION, \"root\")\n          .setDescription(\"Configuration for the UFS of Alluxio root mount point.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_MOUNT_TABLE_ROOT_OPTION =\n      new Builder(Template.MASTER_MOUNT_TABLE_OPTION, \"root\")\n          .setDescription(\"Configuration for the UFS of Alluxio root mount point.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_MOUNT_TABLE_ROOT_OPTION"}, {"original_string": "public static final PropertyKey MASTER_MOUNT_TABLE_ROOT_READONLY =\n      new Builder(Template.MASTER_MOUNT_TABLE_READONLY, \"root\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether Alluxio root mount point is readonly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_MOUNT_TABLE_ROOT_READONLY =\n      new Builder(Template.MASTER_MOUNT_TABLE_READONLY, \"root\")\n          .setDefaultValue(false)\n          .setDescription(\"Whether Alluxio root mount point is readonly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_MOUNT_TABLE_ROOT_READONLY"}, {"original_string": "public static final PropertyKey MASTER_MOUNT_TABLE_ROOT_SHARED =\n      new Builder(Template.MASTER_MOUNT_TABLE_SHARED, \"root\")\n          .setDefaultValue(true)\n          .setDescription(\"Whether Alluxio root mount point is shared.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_MOUNT_TABLE_ROOT_SHARED =\n      new Builder(Template.MASTER_MOUNT_TABLE_SHARED, \"root\")\n          .setDefaultValue(true)\n          .setDescription(\"Whether Alluxio root mount point is shared.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_MOUNT_TABLE_ROOT_SHARED"}, {"original_string": "public static final PropertyKey MASTER_MOUNT_TABLE_ROOT_UFS =\n      new Builder(Template.MASTER_MOUNT_TABLE_UFS, \"root\")\n          .setAlias(\"alluxio.underfs.address\")\n          .setDescription(\"The storage address of the UFS at the Alluxio root mount point.\")\n          .setDefaultValue(String.format(\"${%s}/underFSStorage\", Name.WORK_DIR))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_MOUNT_TABLE_ROOT_UFS =\n      new Builder(Template.MASTER_MOUNT_TABLE_UFS, \"root\")\n          .setAlias(\"alluxio.underfs.address\")\n          .setDescription(\"The storage address of the UFS at the Alluxio root mount point.\")\n          .setDefaultValue(String.format(\"${%s}/underFSStorage\", Name.WORK_DIR))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_MOUNT_TABLE_ROOT_UFS"}, {"original_string": "public static final PropertyKey MASTER_AUDIT_LOGGING_ENABLED =\n      new Builder(Name.MASTER_AUDIT_LOGGING_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Set to true to enable file system master audit.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_AUDIT_LOGGING_ENABLED =\n      new Builder(Name.MASTER_AUDIT_LOGGING_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Set to true to enable file system master audit.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_AUDIT_LOGGING_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_AUDIT_LOGGING_QUEUE_CAPACITY =\n      new Builder(Name.MASTER_AUDIT_LOGGING_QUEUE_CAPACITY)\n          .setDefaultValue(10000)\n          .setDescription(\"Capacity of the queue used by audit logging.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_AUDIT_LOGGING_QUEUE_CAPACITY =\n      new Builder(Name.MASTER_AUDIT_LOGGING_QUEUE_CAPACITY)\n          .setDefaultValue(10000)\n          .setDescription(\"Capacity of the queue used by audit logging.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_AUDIT_LOGGING_QUEUE_CAPACITY"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_DIRECTORY =\n      new Builder(Name.MASTER_BACKUP_DIRECTORY)\n          .setDefaultValue(\"/alluxio_backups\")\n          .setDescription(\"Default directory for writing master metadata backups. This path is \"\n              + \"an absolute path of the root UFS. For example, if the root ufs \"\n              + \"directory is hdfs://host:port/alluxio/data, the default backup directory will be \"\n              + \"hdfs://host:port/alluxio_backups.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_DIRECTORY =\n      new Builder(Name.MASTER_BACKUP_DIRECTORY)\n          .setDefaultValue(\"/alluxio_backups\")\n          .setDescription(\"Default directory for writing master metadata backups. This path is \"\n              + \"an absolute path of the root UFS. For example, if the root ufs \"\n              + \"directory is hdfs://host:port/alluxio/data, the default backup directory will be \"\n              + \"hdfs://host:port/alluxio_backups.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_DIRECTORY"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_ENTRY_BUFFER_COUNT =\n      new Builder(Name.MASTER_BACKUP_ENTRY_BUFFER_COUNT)\n          .setDefaultValue(\"10000\")\n          .setDescription(\"How many journal entries to buffer during a back-up.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_ENTRY_BUFFER_COUNT =\n      new Builder(Name.MASTER_BACKUP_ENTRY_BUFFER_COUNT)\n          .setDefaultValue(\"10000\")\n          .setDescription(\"How many journal entries to buffer during a back-up.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_ENTRY_BUFFER_COUNT"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_DELEGATION_ENABLED =\n      new Builder(Name.MASTER_BACKUP_DELEGATION_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to delegate journals to stand-by masters in HA cluster.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_DELEGATION_ENABLED =\n      new Builder(Name.MASTER_BACKUP_DELEGATION_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to delegate journals to stand-by masters in HA cluster.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_DELEGATION_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_TRANSPORT_TIMEOUT =\n      new Builder(Name.MASTER_BACKUP_TRANSPORT_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Request timeout for backup messaging.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_TRANSPORT_TIMEOUT =\n      new Builder(Name.MASTER_BACKUP_TRANSPORT_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Request timeout for backup messaging.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_TRANSPORT_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_BACKUP_HEARTBEAT_INTERVAL)\n          .setDefaultValue(\"2sec\")\n          .setDescription(\"Interval at which follower updates the leader on ongoing backup.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_BACKUP_HEARTBEAT_INTERVAL)\n          .setDefaultValue(\"2sec\")\n          .setDescription(\"Interval at which follower updates the leader on ongoing backup.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_HEARTBEAT_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_CONNECT_INTERVAL_MIN =\n      new Builder(Name.MASTER_BACKUP_CONNECT_INTERVAL_MIN)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Minimum delay between each connection attempt to backup-leader.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_CONNECT_INTERVAL_MIN =\n      new Builder(Name.MASTER_BACKUP_CONNECT_INTERVAL_MIN)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Minimum delay between each connection attempt to backup-leader.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_CONNECT_INTERVAL_MIN"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_CONNECT_INTERVAL_MAX =\n      new Builder(Name.MASTER_BACKUP_CONNECT_INTERVAL_MAX)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Maximum delay between each connection attempt to backup-leader.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_CONNECT_INTERVAL_MAX =\n      new Builder(Name.MASTER_BACKUP_CONNECT_INTERVAL_MAX)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Maximum delay between each connection attempt to backup-leader.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_CONNECT_INTERVAL_MAX"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_ABANDON_TIMEOUT =\n      new Builder(Name.MASTER_BACKUP_ABANDON_TIMEOUT)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"Duration after which leader will abandon the backup\"\n              + \" if not received heartbeat from backup-worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_ABANDON_TIMEOUT =\n      new Builder(Name.MASTER_BACKUP_ABANDON_TIMEOUT)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"Duration after which leader will abandon the backup\"\n              + \" if not received heartbeat from backup-worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_ABANDON_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_STATE_LOCK_EXCLUSIVE_DURATION =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_EXCLUSIVE_DURATION)\n          .setDefaultValue(\"0ms\")\n          .setDescription(\"Alluxio master will allow only exclusive locking of \"\n              + \"the state-lock for this duration. This duration starts after masters \"\n              + \"are started for the first time. \"\n              + \"User RPCs will fail to acquire state-lock during this phase and \"\n              + \"a backup is guaranteed take the state-lock meanwhile.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_STATE_LOCK_EXCLUSIVE_DURATION =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_EXCLUSIVE_DURATION)\n          .setDefaultValue(\"0ms\")\n          .setDescription(\"Alluxio master will allow only exclusive locking of \"\n              + \"the state-lock for this duration. This duration starts after masters \"\n              + \"are started for the first time. \"\n              + \"User RPCs will fail to acquire state-lock during this phase and \"\n              + \"a backup is guaranteed take the state-lock meanwhile.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_STATE_LOCK_EXCLUSIVE_DURATION"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_ENABLED =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"This controls whether RPCs that are waiting/holding state-lock \"\n              + \"in shared-mode will be interrupted while state-lock is taken exclusively.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_ENABLED =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"This controls whether RPCs that are waiting/holding state-lock \"\n              + \"in shared-mode will be interrupted while state-lock is taken exclusively.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_STATE_LOCK_FORCED_DURATION =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_FORCED_DURATION)\n          .setDefaultValue(\"15min\")\n          .setDescription(\"Exclusive locking of the state-lock will timeout after \"\n              + \"this duration is spent on forced phase.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_STATE_LOCK_FORCED_DURATION =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_FORCED_DURATION)\n          .setDefaultValue(\"15min\")\n          .setDescription(\"Exclusive locking of the state-lock will timeout after \"\n              + \"this duration is spent on forced phase.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_STATE_LOCK_FORCED_DURATION"}, {"original_string": "public static final PropertyKey MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_INTERVAL =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_INTERVAL)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The interval at which the RPCs that are waiting/holding state-lock \"\n              + \"in shared-mode will be interrupted while state-lock is taken exclusively.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_INTERVAL =\n      new Builder(Name.MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_INTERVAL)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The interval at which the RPCs that are waiting/holding state-lock \"\n              + \"in shared-mode will be interrupted while state-lock is taken exclusively.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BACKUP_STATE_LOCK_INTERRUPT_CYCLE_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_ENABLED =\n      new Builder(Name.MASTER_DAILY_BACKUP_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to enable daily primary master \"\n              + \"metadata backup.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_ENABLED =\n      new Builder(Name.MASTER_DAILY_BACKUP_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether or not to enable daily primary master \"\n              + \"metadata backup.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_FILES_RETAINED =\n      new Builder(Name.MASTER_DAILY_BACKUP_FILES_RETAINED)\n          .setDefaultValue(3)\n          .setDescription(\"The maximum number of backup files to keep in the backup directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_FILES_RETAINED =\n      new Builder(Name.MASTER_DAILY_BACKUP_FILES_RETAINED)\n          .setDefaultValue(3)\n          .setDescription(\"The maximum number of backup files to keep in the backup directory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_FILES_RETAINED"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_TIME =\n      new Builder(Name.MASTER_DAILY_BACKUP_TIME)\n          .setDefaultValue(\"05:00\")\n          .setDescription(\"Default UTC time for writing daily master metadata backups. \"\n              + \"The accepted time format is hour:minute which is based on a 24-hour clock \"\n              + \"(E.g., 05:30, 06:00, and 22:04). \"\n              + \"Backing up metadata requires a pause in master metadata changes, \"\n              + \"so please set this value to an off-peak time \"\n              + \"to avoid interfering with other users of the system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_TIME =\n      new Builder(Name.MASTER_DAILY_BACKUP_TIME)\n          .setDefaultValue(\"05:00\")\n          .setDescription(\"Default UTC time for writing daily master metadata backups. \"\n              + \"The accepted time format is hour:minute which is based on a 24-hour clock \"\n              + \"(E.g., 05:30, 06:00, and 22:04). \"\n              + \"Backing up metadata requires a pause in master metadata changes, \"\n              + \"so please set this value to an off-peak time \"\n              + \"to avoid interfering with other users of the system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_TIME"}, {"original_string": "public static final PropertyKey MASTER_SHELL_BACKUP_STATE_LOCK_GRACE_MODE =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_GRACE_MODE)\n          .setDefaultValue(\"TIMEOUT\")\n          .setDescription(\"Grace mode helps taking the state-lock exclusively for backup \"\n              + \"with minimum disruption to existing RPCs. This low-impact locking phase \"\n              + \"is called grace-cycle. Two modes are supported: TIMEOUT/FORCED.\"\n              + \"TIMEOUT: Means exclusive locking will timeout if it cannot acquire the lock\"\n              + \"with grace-cycle. \"\n              + \"FORCED: Means the state-lock will be taken forcefully if grace-cycle fails \"\n              + \"to acquire it. Forced phase might trigger interrupting of existing RPCs if \"\n              + \"it is enabled.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_SHELL_BACKUP_STATE_LOCK_GRACE_MODE =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_GRACE_MODE)\n          .setDefaultValue(\"TIMEOUT\")\n          .setDescription(\"Grace mode helps taking the state-lock exclusively for backup \"\n              + \"with minimum disruption to existing RPCs. This low-impact locking phase \"\n              + \"is called grace-cycle. Two modes are supported: TIMEOUT/FORCED.\"\n              + \"TIMEOUT: Means exclusive locking will timeout if it cannot acquire the lock\"\n              + \"with grace-cycle. \"\n              + \"FORCED: Means the state-lock will be taken forcefully if grace-cycle fails \"\n              + \"to acquire it. Forced phase might trigger interrupting of existing RPCs if \"\n              + \"it is enabled.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_SHELL_BACKUP_STATE_LOCK_GRACE_MODE"}, {"original_string": "public static final PropertyKey MASTER_SHELL_BACKUP_STATE_LOCK_TRY_DURATION =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_TRY_DURATION)\n          .setDefaultValue(\"1m\")\n          .setDescription(\"The duration that controls how long the state-lock is \"\n              + \"tried within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_SHELL_BACKUP_STATE_LOCK_TRY_DURATION =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_TRY_DURATION)\n          .setDefaultValue(\"1m\")\n          .setDescription(\"The duration that controls how long the state-lock is \"\n              + \"tried within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_SHELL_BACKUP_STATE_LOCK_TRY_DURATION"}, {"original_string": "public static final PropertyKey MASTER_SHELL_BACKUP_STATE_LOCK_SLEEP_DURATION =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_SLEEP_DURATION)\n          .setDefaultValue(\"0\")\n          .setDescription(\"The duration that controls how long the lock waiter \"\n              + \"sleeps within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_SHELL_BACKUP_STATE_LOCK_SLEEP_DURATION =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_SLEEP_DURATION)\n          .setDefaultValue(\"0\")\n          .setDescription(\"The duration that controls how long the lock waiter \"\n              + \"sleeps within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_SHELL_BACKUP_STATE_LOCK_SLEEP_DURATION"}, {"original_string": "public static final PropertyKey MASTER_SHELL_BACKUP_STATE_LOCK_TIMEOUT =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_TIMEOUT)\n          .setDefaultValue(\"1m\")\n          .setDescription(\"The max duration for a grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_SHELL_BACKUP_STATE_LOCK_TIMEOUT =\n      new Builder(Name.MASTER_SHELL_BACKUP_STATE_LOCK_TIMEOUT)\n          .setDefaultValue(\"1m\")\n          .setDescription(\"The max duration for a grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_SHELL_BACKUP_STATE_LOCK_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_STATE_LOCK_GRACE_MODE =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_GRACE_MODE)\n          .setDefaultValue(\"FORCED\")\n          .setDescription(\"Grace mode helps taking the state-lock exclusively for backup \"\n              + \"with minimum disruption to existing RPCs. This low-impact locking phase \"\n              + \"is called grace-cycle. Two modes are supported: TIMEOUT/FORCED.\"\n              + \"TIMEOUT: Means exclusive locking will timeout if it cannot acquire the lock\"\n              + \"with grace-cycle. \"\n              + \"FORCED: Means the state-lock will be taken forcefully if grace-cycle fails \"\n              + \"to acquire it. Forced phase might trigger interrupting of existing RPCs if \"\n              + \"it is enabled.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_STATE_LOCK_GRACE_MODE =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_GRACE_MODE)\n          .setDefaultValue(\"FORCED\")\n          .setDescription(\"Grace mode helps taking the state-lock exclusively for backup \"\n              + \"with minimum disruption to existing RPCs. This low-impact locking phase \"\n              + \"is called grace-cycle. Two modes are supported: TIMEOUT/FORCED.\"\n              + \"TIMEOUT: Means exclusive locking will timeout if it cannot acquire the lock\"\n              + \"with grace-cycle. \"\n              + \"FORCED: Means the state-lock will be taken forcefully if grace-cycle fails \"\n              + \"to acquire it. Forced phase might trigger interrupting of existing RPCs if \"\n              + \"it is enabled.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_STATE_LOCK_GRACE_MODE"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_STATE_LOCK_TRY_DURATION =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_TRY_DURATION)\n          .setDefaultValue(\"30s\")\n          .setDescription(\"The duration that controls how long the state-lock is \"\n              + \"tried within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_STATE_LOCK_TRY_DURATION =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_TRY_DURATION)\n          .setDefaultValue(\"30s\")\n          .setDescription(\"The duration that controls how long the state-lock is \"\n              + \"tried within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_STATE_LOCK_TRY_DURATION"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_STATE_LOCK_SLEEP_DURATION =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_SLEEP_DURATION)\n          .setDefaultValue(\"10m\")\n          .setDescription(\"The duration that controls how long the lock waiter \"\n              + \"sleeps within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_STATE_LOCK_SLEEP_DURATION =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_SLEEP_DURATION)\n          .setDefaultValue(\"10m\")\n          .setDescription(\"The duration that controls how long the lock waiter \"\n              + \"sleeps within a single grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_STATE_LOCK_SLEEP_DURATION"}, {"original_string": "public static final PropertyKey MASTER_DAILY_BACKUP_STATE_LOCK_TIMEOUT =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_TIMEOUT)\n          .setDefaultValue(\"12h\")\n          .setDescription(\"The max duration for a grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_DAILY_BACKUP_STATE_LOCK_TIMEOUT =\n      new Builder(Name.MASTER_DAILY_BACKUP_STATE_LOCK_TIMEOUT)\n          .setDefaultValue(\"12h\")\n          .setDescription(\"The max duration for a grace-cycle.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_DAILY_BACKUP_STATE_LOCK_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_BIND_HOST =\n      new Builder(Name.MASTER_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname that Alluxio master binds to.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_BIND_HOST =\n      new Builder(Name.MASTER_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname that Alluxio master binds to.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_BIND_HOST"}, {"original_string": "public static final PropertyKey MASTER_CLUSTER_METRICS_UPDATE_INTERVAL =\n      new Builder(Name.MASTER_CLUSTER_METRICS_UPDATE_INTERVAL)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"The interval for periodically updating the cluster level metrics.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .setIsHidden(true)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_CLUSTER_METRICS_UPDATE_INTERVAL =\n      new Builder(Name.MASTER_CLUSTER_METRICS_UPDATE_INTERVAL)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"The interval for periodically updating the cluster level metrics.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .setIsHidden(true)\n          .build()", "var_name": "MASTER_CLUSTER_METRICS_UPDATE_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_PROXY_HOST =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_PROXY_HOST)\n          .setDescription(String.format(\n              \"Used to bind embedded journal servers to a proxied host.\"\n                  + \"Proxy hostname will still make use of %s for bind port.\",\n              Name.MASTER_EMBEDDED_JOURNAL_PORT))\n          // No default value for proxy-host. Server will bind to \"alluxio.master.hostname\"\n          // as default.\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_PROXY_HOST =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_PROXY_HOST)\n          .setDescription(String.format(\n              \"Used to bind embedded journal servers to a proxied host.\"\n                  + \"Proxy hostname will still make use of %s for bind port.\",\n              Name.MASTER_EMBEDDED_JOURNAL_PORT))\n          // No default value for proxy-host. Server will bind to \"alluxio.master.hostname\"\n          // as default.\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_PROXY_HOST"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_ADDRESSES =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_ADDRESSES)\n          .setDescription(String.format(\"A comma-separated list of journal addresses for all \"\n              + \"masters in the cluster. The format is 'hostname1:port1,hostname2:port2,...'. When \"\n              + \"left unset, Alluxio uses ${%s}:${%s} by default\", Name.MASTER_HOSTNAME,\n              Name.MASTER_EMBEDDED_JOURNAL_PORT))\n          // We intentionally don't set a default value here. That way, we can use isSet() to check\n          // whether the user explicitly set these addresses. If they did, we determine job master\n          // embedded journal addresses using the same hostnames the user set here. Otherwise, we\n          // use jobMasterHostname:jobMasterEmbeddedJournalPort by default.\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_ADDRESSES =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_ADDRESSES)\n          .setDescription(String.format(\"A comma-separated list of journal addresses for all \"\n              + \"masters in the cluster. The format is 'hostname1:port1,hostname2:port2,...'. When \"\n              + \"left unset, Alluxio uses ${%s}:${%s} by default\", Name.MASTER_HOSTNAME,\n              Name.MASTER_EMBEDDED_JOURNAL_PORT))\n          // We intentionally don't set a default value here. That way, we can use isSet() to check\n          // whether the user explicitly set these addresses. If they did, we determine job master\n          // embedded journal addresses using the same hostnames the user set here. Otherwise, we\n          // use jobMasterHostname:jobMasterEmbeddedJournalPort by default.\n          .setScope(Scope.ALL)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_ADDRESSES"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT)\n          .setDescription(\n              \"The election timeout for the embedded journal. When this period elapses without a \"\n                  + \"master receiving any messages, the master will attempt to become the primary.\"\n                  + \"Election timeout will be waited initially when the cluster is forming. \"\n                  + \"So larger values for election timeout will cause longer start-up time. \"\n                  + \"Smaller values might introduce instability to leadership.\")\n          .setDefaultValue(\"10s\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT)\n          .setDescription(\n              \"The election timeout for the embedded journal. When this period elapses without a \"\n                  + \"master receiving any messages, the master will attempt to become the primary.\"\n                  + \"Election timeout will be waited initially when the cluster is forming. \"\n                  + \"So larger values for election timeout will cause longer start-up time. \"\n                  + \"Smaller values might introduce instability to leadership.\")\n          .setDefaultValue(\"10s\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_HEARTBEAT_INTERVAL)\n          .setDescription(\n              \"The period between sending heartbeats from the embedded journal primary to \"\n                  + \"followers. This should be less than half of the election timeout \"\n                  + String.format(\"{%s}\", Name.MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT)\n                  + \", because the election is driven by heart beats.\")\n          .setDefaultValue(\"3s\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_HEARTBEAT_INTERVAL)\n          .setDescription(\n              \"The period between sending heartbeats from the embedded journal primary to \"\n                  + \"followers. This should be less than half of the election timeout \"\n                  + String.format(\"{%s}\", Name.MASTER_EMBEDDED_JOURNAL_ELECTION_TIMEOUT)\n                  + \", because the election is driven by heart beats.\")\n          .setDefaultValue(\"3s\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_HEARTBEAT_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_APPENDER_BATCH_SIZE =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_APPENDER_BATCH_SIZE)\n          .setDescription(\"Amount of data that is appended from leader to followers \"\n              + \"in a single heartbeat. Setting higher values might require increasing \"\n              + \"election timeout due to increased network delay. Setting lower values \"\n              + \"might stall knowledge propagation between the leader and followers.\")\n          .setDefaultValue(\"512KB\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_APPENDER_BATCH_SIZE =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_APPENDER_BATCH_SIZE)\n          .setDescription(\"Amount of data that is appended from leader to followers \"\n              + \"in a single heartbeat. Setting higher values might require increasing \"\n              + \"election timeout due to increased network delay. Setting lower values \"\n              + \"might stall knowledge propagation between the leader and followers.\")\n          .setDefaultValue(\"512KB\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_APPENDER_BATCH_SIZE"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_CATCHUP_RETRY_WAIT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_CATCHUP_RETRY_WAIT)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"Time for embedded journal leader to wait before retrying a catch up.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_CATCHUP_RETRY_WAIT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_CATCHUP_RETRY_WAIT)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"Time for embedded journal leader to wait before retrying a catch up.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_CATCHUP_RETRY_WAIT"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_PORT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_PORT)\n          .setDescription(\"The port to use for embedded journal communication with other masters.\")\n          .setDefaultValue(19200)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_PORT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_PORT)\n          .setDescription(\"The port to use for embedded journal communication with other masters.\")\n          .setDefaultValue(19200)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_PORT"}, {"original_string": "@Deprecated\n  public static final PropertyKey MASTER_EMBEDDED_JOURNAL_STORAGE_LEVEL =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_STORAGE_LEVEL)\n          .setDescription(\"The storage level for storing embedded journal logs. Use DISK for \"\n              + \"maximum durability. Use MAPPED for better performance, but some risk of \"\n              + \"losing state in case of power loss or host failure. Use MEMORY for \"\n              + \"optimal performance, but no state persistence across cluster restarts.\")\n          .setDefaultValue(\"DISK\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_STORAGE_LEVEL =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_STORAGE_LEVEL)\n          .setDescription(\"The storage level for storing embedded journal logs. Use DISK for \"\n              + \"maximum durability. Use MAPPED for better performance, but some risk of \"\n              + \"losing state in case of power loss or host failure. Use MEMORY for \"\n              + \"optimal performance, but no state persistence across cluster restarts.\")\n          .setDefaultValue(\"DISK\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_STORAGE_LEVEL"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_SHUTDOWN_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"Maximum time to wait for embedded journal to stop on shutdown.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_SHUTDOWN_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"Maximum time to wait for embedded journal to stop on shutdown.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_SHUTDOWN_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_WRITE_LOCAL_FIRST_ENABLED =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_WRITE_LOCAL_FIRST_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether the journal writer will attempt to write entry locally before \"\n              + \"falling back to a full remote raft client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_WRITE_LOCAL_FIRST_ENABLED =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_WRITE_LOCAL_FIRST_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether the journal writer will attempt to write entry locally before \"\n              + \"falling back to a full remote raft client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_WRITE_LOCAL_FIRST_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_WRITE_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_WRITE_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Maximum time to wait for a write/flush on embedded journal.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_WRITE_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_WRITE_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Maximum time to wait for a write/flush on embedded journal.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_WRITE_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_SNAPSHOT_REPLICATION_CHUNK_SIZE =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_SNAPSHOT_REPLICATION_CHUNK_SIZE)\n          .setDefaultValue(\"4MB\")\n          .setDescription(\"The stream chunk size used by masters to replicate snapshots.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_SNAPSHOT_REPLICATION_CHUNK_SIZE =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_SNAPSHOT_REPLICATION_CHUNK_SIZE)\n          .setDefaultValue(\"4MB\")\n          .setDescription(\"The stream chunk size used by masters to replicate snapshots.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_SNAPSHOT_REPLICATION_CHUNK_SIZE"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_TRIGGERED_SNAPSHOT_WAIT_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_TRIGGERED_SNAPSHOT_WAIT_TIMEOUT)\n          .setDefaultValue(\"2hour\")\n          .setDescription(\"Maximum time to wait for the triggered snapshot to finish.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_TRIGGERED_SNAPSHOT_WAIT_TIMEOUT =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_TRIGGERED_SNAPSHOT_WAIT_TIMEOUT)\n          .setDefaultValue(\"2hour\")\n          .setDescription(\"Maximum time to wait for the triggered snapshot to finish.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_TRIGGERED_SNAPSHOT_WAIT_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_TRANSPORT_REQUEST_TIMEOUT_MS =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_TRANSPORT_REQUEST_TIMEOUT_MS)\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Timeout for requests between embedded journal masters.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_TRANSPORT_REQUEST_TIMEOUT_MS =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_TRANSPORT_REQUEST_TIMEOUT_MS)\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Timeout for requests between embedded journal masters.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_TRANSPORT_REQUEST_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey MASTER_EMBEDDED_JOURNAL_TRANSPORT_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_TRANSPORT_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The maximum size of a message that can be sent to the \"\n              + \"embedded journal server node.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_EMBEDDED_JOURNAL_TRANSPORT_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.MASTER_EMBEDDED_JOURNAL_TRANSPORT_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The maximum size of a message that can be sent to the \"\n              + \"embedded journal server node.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_EMBEDDED_JOURNAL_TRANSPORT_MAX_INBOUND_MESSAGE_SIZE"}, {"original_string": "public static final PropertyKey MASTER_RPC_ADDRESSES =\n      new Builder(Name.MASTER_RPC_ADDRESSES).setDescription(\n          \"A list of comma-separated host:port RPC addresses where the client should look for \"\n              + \"masters when using multiple masters without Zookeeper. This property is not \"\n              + \"used when Zookeeper is enabled, since Zookeeper already stores the master \"\n              + \"addresses.\")\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_ADDRESSES =\n      new Builder(Name.MASTER_RPC_ADDRESSES).setDescription(\n          \"A list of comma-separated host:port RPC addresses where the client should look for \"\n              + \"masters when using multiple masters without Zookeeper. This property is not \"\n              + \"used when Zookeeper is enabled, since Zookeeper already stores the master \"\n              + \"addresses.\")\n          .setScope(Scope.ALL)\n          .build()", "var_name": "MASTER_RPC_ADDRESSES"}, {"original_string": "public static final PropertyKey MASTER_FILE_ACCESS_TIME_JOURNAL_FLUSH_INTERVAL =\n      new Builder(Name.MASTER_FILE_ACCESS_TIME_JOURNAL_FLUSH_INTERVAL)\n          .setDefaultValue(\"1h\")\n          .setDescription(\"The minimum interval between files access time update journal entries \"\n              + \"get flushed asynchronously. Setting it to a non-positive value will make the the \"\n              + \"journal update synchronous. Asynchronous update reduces the performance impact of \"\n              + \"tracking access time but can lose some access time update when master stops \"\n              + \"unexpectedly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_FILE_ACCESS_TIME_JOURNAL_FLUSH_INTERVAL =\n      new Builder(Name.MASTER_FILE_ACCESS_TIME_JOURNAL_FLUSH_INTERVAL)\n          .setDefaultValue(\"1h\")\n          .setDescription(\"The minimum interval between files access time update journal entries \"\n              + \"get flushed asynchronously. Setting it to a non-positive value will make the the \"\n              + \"journal update synchronous. Asynchronous update reduces the performance impact of \"\n              + \"tracking access time but can lose some access time update when master stops \"\n              + \"unexpectedly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_FILE_ACCESS_TIME_JOURNAL_FLUSH_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_FILE_ACCESS_TIME_UPDATE_PRECISION =\n      new Builder(Name.MASTER_FILE_ACCESS_TIME_UPDATE_PRECISION)\n          .setDefaultValue(\"1d\")\n          .setDescription(\"The file last access time is precise up to this value. Setting it to\"\n              + \"a non-positive value will update last access time on every file access operation.\"\n              + \"Longer precision will help reduce the performance impact of tracking access time \"\n              + \"by reduce the amount of metadata writes occur while reading the same group of \"\n              + \"files repetitively.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_FILE_ACCESS_TIME_UPDATE_PRECISION =\n      new Builder(Name.MASTER_FILE_ACCESS_TIME_UPDATE_PRECISION)\n          .setDefaultValue(\"1d\")\n          .setDescription(\"The file last access time is precise up to this value. Setting it to\"\n              + \"a non-positive value will update last access time on every file access operation.\"\n              + \"Longer precision will help reduce the performance impact of tracking access time \"\n              + \"by reduce the amount of metadata writes occur while reading the same group of \"\n              + \"files repetitively.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_FILE_ACCESS_TIME_UPDATE_PRECISION"}, {"original_string": "public static final PropertyKey MASTER_FILE_ACCESS_TIME_UPDATER_SHUTDOWN_TIMEOUT =\n      new Builder(Name.MASTER_FILE_ACCESS_TIME_UPDATER_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Maximum time to wait for access updater to stop on shutdown.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_FILE_ACCESS_TIME_UPDATER_SHUTDOWN_TIMEOUT =\n      new Builder(Name.MASTER_FILE_ACCESS_TIME_UPDATER_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Maximum time to wait for access updater to stop on shutdown.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_FILE_ACCESS_TIME_UPDATER_SHUTDOWN_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_FORMAT_FILE_PREFIX =\n      new Builder(Name.MASTER_FORMAT_FILE_PREFIX)\n          .setAlias(\"alluxio.master.format.file_prefix\")\n          .setDefaultValue(\"_format_\")\n          .setDescription(\"The file prefix of the file generated in the journal directory \"\n              + \"when the journal is formatted. The master will search for a file with this \"\n              + \"prefix when determining if the journal is formatted.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_FORMAT_FILE_PREFIX =\n      new Builder(Name.MASTER_FORMAT_FILE_PREFIX)\n          .setAlias(\"alluxio.master.format.file_prefix\")\n          .setDefaultValue(\"_format_\")\n          .setDescription(\"The file prefix of the file generated in the journal directory \"\n              + \"when the journal is formatted. The master will search for a file with this \"\n              + \"prefix when determining if the journal is formatted.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_FORMAT_FILE_PREFIX"}, {"original_string": "public static final PropertyKey MASTER_STANDBY_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_STANDBY_HEARTBEAT_INTERVAL)\n          .setDefaultValue(\"2min\")\n          .setDescription(\"The heartbeat interval between Alluxio primary master and standby \"\n              + \"masters.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_STANDBY_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_STANDBY_HEARTBEAT_INTERVAL)\n          .setDefaultValue(\"2min\")\n          .setDescription(\"The heartbeat interval between Alluxio primary master and standby \"\n              + \"masters.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_STANDBY_HEARTBEAT_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_METASTORE =\n      new Builder(Name.MASTER_METASTORE)\n          .setDefaultValue(\"HEAP\")\n          .setDescription(\"The type of metastore to use, either HEAP or ROCKS. The heap metastore \"\n              + \"keeps all metadata on-heap, while the rocks metastore stores some metadata on \"\n              + \"heap and some metadata on disk. The rocks metastore has the advantage of being \"\n              + \"able to support a large namespace (1 billion plus files) without needing a \"\n              + \"massive heap size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE =\n      new Builder(Name.MASTER_METASTORE)\n          .setDefaultValue(\"HEAP\")\n          .setDescription(\"The type of metastore to use, either HEAP or ROCKS. The heap metastore \"\n              + \"keeps all metadata on-heap, while the rocks metastore stores some metadata on \"\n              + \"heap and some metadata on disk. The rocks metastore has the advantage of being \"\n              + \"able to support a large namespace (1 billion plus files) without needing a \"\n              + \"massive heap size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_DIR =\n      new Builder(Name.MASTER_METASTORE_DIR)\n          .setDefaultValue(String.format(\"${%s}/metastore\", Name.WORK_DIR))\n          .setDescription(\"The metastore work directory. Only some metastores need disk.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_DIR =\n      new Builder(Name.MASTER_METASTORE_DIR)\n          .setDefaultValue(String.format(\"${%s}/metastore\", Name.WORK_DIR))\n          .setDescription(\"The metastore work directory. Only some metastores need disk.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_DIR"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_CACHE_EVICT_BATCH_SIZE =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_EVICT_BATCH_SIZE)\n          // TODO(andrew): benchmark different batch sizes to improve the default and provide a\n          // tuning guideline\n          .setDefaultValue(\"1000\")\n          .setDescription(\"The batch size for evicting entries from the inode cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_CACHE_EVICT_BATCH_SIZE =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_EVICT_BATCH_SIZE)\n          // TODO(andrew): benchmark different batch sizes to improve the default and provide a\n          // tuning guideline\n          .setDefaultValue(\"1000\")\n          .setDescription(\"The batch size for evicting entries from the inode cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_CACHE_EVICT_BATCH_SIZE"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_CACHE_HIGH_WATER_MARK_RATIO =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_HIGH_WATER_MARK_RATIO)\n          .setDefaultValue(\"0.85\")\n          .setDescription(\"The high water mark for the inode cache, as a ratio from high water \"\n              + \"mark to total cache size. If this is 0.85 and the max size is 10 million, the \"\n              + \"high water mark value is 8.5 million. When the cache reaches the high \"\n              + \"water mark, the eviction process will evict down to the low water mark.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_CACHE_HIGH_WATER_MARK_RATIO =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_HIGH_WATER_MARK_RATIO)\n          .setDefaultValue(\"0.85\")\n          .setDescription(\"The high water mark for the inode cache, as a ratio from high water \"\n              + \"mark to total cache size. If this is 0.85 and the max size is 10 million, the \"\n              + \"high water mark value is 8.5 million. When the cache reaches the high \"\n              + \"water mark, the eviction process will evict down to the low water mark.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_CACHE_HIGH_WATER_MARK_RATIO"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_CACHE_LOW_WATER_MARK_RATIO =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_LOW_WATER_MARK_RATIO)\n          .setDefaultValue(\"0.8\")\n          .setDescription(\"The low water mark for the inode cache, as a ratio from low water mark \"\n              + \"to total cache size. If this is 0.8 and the max size is 10 million, the low \"\n              + \"water mark value is 8 million. When the cache reaches the high \"\n              + \"water mark, the eviction process will evict down to the low water mark.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_CACHE_LOW_WATER_MARK_RATIO =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_LOW_WATER_MARK_RATIO)\n          .setDefaultValue(\"0.8\")\n          .setDescription(\"The low water mark for the inode cache, as a ratio from low water mark \"\n              + \"to total cache size. If this is 0.8 and the max size is 10 million, the low \"\n              + \"water mark value is 8 million. When the cache reaches the high \"\n              + \"water mark, the eviction process will evict down to the low water mark.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_CACHE_LOW_WATER_MARK_RATIO"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_CACHE_MAX_SIZE =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_MAX_SIZE)\n          .setDefaultValue(\"10000000\")\n          .setDescription(\"The number of inodes to cache on-heap. \"\n              + \"This only applies to off-heap metastores, e.g. ROCKS. Set this to 0 to disable \"\n              + \"the on-heap inode cache\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_CACHE_MAX_SIZE =\n      new Builder(Name.MASTER_METASTORE_INODE_CACHE_MAX_SIZE)\n          .setDefaultValue(\"10000000\")\n          .setDescription(\"The number of inodes to cache on-heap. \"\n              + \"This only applies to off-heap metastores, e.g. ROCKS. Set this to 0 to disable \"\n              + \"the on-heap inode cache\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_CACHE_MAX_SIZE"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_ITERATION_CRAWLER_COUNT =\n      new Builder(Name.MASTER_METASTORE_INODE_ITERATION_CRAWLER_COUNT)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"Use {CPU core count} for enumeration\")\n          .setDescription(\"The number of threads used during inode tree enumeration.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_ITERATION_CRAWLER_COUNT =\n      new Builder(Name.MASTER_METASTORE_INODE_ITERATION_CRAWLER_COUNT)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"Use {CPU core count} for enumeration\")\n          .setDescription(\"The number of threads used during inode tree enumeration.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_ITERATION_CRAWLER_COUNT"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_ENUMERATOR_BUFFER_COUNT =\n      new Builder(Name.MASTER_METASTORE_INODE_ENUMERATOR_BUFFER_COUNT)\n          .setDefaultValue(\"10000\")\n          .setDescription(\"The number of entries to buffer during read-ahead enumeration.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_ENUMERATOR_BUFFER_COUNT =\n      new Builder(Name.MASTER_METASTORE_INODE_ENUMERATOR_BUFFER_COUNT)\n          .setDefaultValue(\"10000\")\n          .setDescription(\"The number of entries to buffer during read-ahead enumeration.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_ENUMERATOR_BUFFER_COUNT"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_ITERATOR_READAHEAD_SIZE =\n      new Builder(Name.MASTER_METASTORE_ITERATOR_READAHEAD_SIZE)\n          .setDefaultValue(\"64MB\")\n          .setDescription(\"The read-ahead size (in bytes) for metastore iterators.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_ITERATOR_READAHEAD_SIZE =\n      new Builder(Name.MASTER_METASTORE_ITERATOR_READAHEAD_SIZE)\n          .setDefaultValue(\"64MB\")\n          .setDescription(\"The read-ahead size (in bytes) for metastore iterators.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_ITERATOR_READAHEAD_SIZE"}, {"original_string": "public static final PropertyKey MASTER_METASTORE_INODE_INHERIT_OWNER_AND_GROUP =\n      new Builder(Name.MASTER_METASTORE_INODE_INHERIT_OWNER_AND_GROUP)\n          .setDefaultValue(\"true\")\n          .setDescription(\"Whether to inherit the owner/group from the parent when creating a new \"\n              + \"inode path if empty\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METASTORE_INODE_INHERIT_OWNER_AND_GROUP =\n      new Builder(Name.MASTER_METASTORE_INODE_INHERIT_OWNER_AND_GROUP)\n          .setDefaultValue(\"true\")\n          .setDescription(\"Whether to inherit the owner/group from the parent when creating a new \"\n              + \"inode path if empty\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METASTORE_INODE_INHERIT_OWNER_AND_GROUP"}, {"original_string": "public static final PropertyKey MASTER_METRICS_SERVICE_THREADS =\n      new Builder(Name.MASTER_METRICS_SERVICE_THREADS)\n          .setDefaultValue(5)\n          .setDescription(\"The number of threads in metrics master executor pool \"\n              + \"for parallel processing metrics submitted by workers or clients \"\n              + \"and update cluster metrics.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METRICS_SERVICE_THREADS =\n      new Builder(Name.MASTER_METRICS_SERVICE_THREADS)\n          .setDefaultValue(5)\n          .setDescription(\"The number of threads in metrics master executor pool \"\n              + \"for parallel processing metrics submitted by workers or clients \"\n              + \"and update cluster metrics.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METRICS_SERVICE_THREADS"}, {"original_string": "public static final PropertyKey MASTER_METRICS_TIME_SERIES_INTERVAL =\n      new Builder(Name.MASTER_METRICS_TIME_SERIES_INTERVAL)\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Interval for which the master records metrics information. This affects \"\n              + \"the granularity of the metrics graphed in the UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METRICS_TIME_SERIES_INTERVAL =\n      new Builder(Name.MASTER_METRICS_TIME_SERIES_INTERVAL)\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Interval for which the master records metrics information. This affects \"\n              + \"the granularity of the metrics graphed in the UI.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_METRICS_TIME_SERIES_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_NETWORK_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.MASTER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The maximum size of a message that can be sent to the Alluxio master\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_NETWORK_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.MASTER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The maximum size of a message that can be sent to the Alluxio master\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_NETWORK_MAX_INBOUND_MESSAGE_SIZE"}, {"original_string": "public static final PropertyKey MASTER_LOST_WORKER_FILE_DETECTION_INTERVAL =\n      new Builder(Name.MASTER_LOST_WORKER_FILE_DETECTION_INTERVAL)\n          .setAlias(\"alluxio.master.worker.heartbeat.interval\")\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The interval between Alluxio master detections to find lost workers \"\n              + \"and files based on updates from Alluxio workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_LOST_WORKER_FILE_DETECTION_INTERVAL =\n      new Builder(Name.MASTER_LOST_WORKER_FILE_DETECTION_INTERVAL)\n          .setAlias(\"alluxio.master.worker.heartbeat.interval\")\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The interval between Alluxio master detections to find lost workers \"\n              + \"and files based on updates from Alluxio workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "MASTER_LOST_WORKER_FILE_DETECTION_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_HEARTBEAT_TIMEOUT =\n      new Builder(Name.MASTER_HEARTBEAT_TIMEOUT)\n          .setDefaultValue(\"10min\")\n          .setDescription(\"Timeout between leader master and standby master\"\n              + \" indicating a lost master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_HEARTBEAT_TIMEOUT =\n      new Builder(Name.MASTER_HEARTBEAT_TIMEOUT)\n          .setDefaultValue(\"10min\")\n          .setDescription(\"Timeout between leader master and standby master\"\n              + \" indicating a lost master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_HEARTBEAT_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_HOSTNAME =\n      new Builder(Name.MASTER_HOSTNAME)\n          .setDescription(\"The hostname of Alluxio master.\")\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_HOSTNAME =\n      new Builder(Name.MASTER_HOSTNAME)\n          .setDescription(\"The hostname of Alluxio master.\")\n          .setScope(Scope.ALL)\n          .build()", "var_name": "MASTER_HOSTNAME"}, {"original_string": "public static final PropertyKey MASTER_LOCK_POOL_INITSIZE =\n      new Builder(Name.MASTER_LOCK_POOL_INITSIZE)\n          .setDefaultValue(1000)\n          .setDescription(\"Initial size of the lock pool for master inodes.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_LOCK_POOL_INITSIZE =\n      new Builder(Name.MASTER_LOCK_POOL_INITSIZE)\n          .setDefaultValue(1000)\n          .setDescription(\"Initial size of the lock pool for master inodes.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_LOCK_POOL_INITSIZE"}, {"original_string": "public static final PropertyKey MASTER_LOCK_POOL_LOW_WATERMARK =\n      new Builder(Name.MASTER_LOCK_POOL_LOW_WATERMARK)\n          .setDefaultValue(500000)\n          .setDescription(\"Low watermark of lock pool size. \"\n              + \"When the size grows over the high watermark, a background thread will try to \"\n              + \"evict unused locks until the size reaches the low watermark.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_LOCK_POOL_LOW_WATERMARK =\n      new Builder(Name.MASTER_LOCK_POOL_LOW_WATERMARK)\n          .setDefaultValue(500000)\n          .setDescription(\"Low watermark of lock pool size. \"\n              + \"When the size grows over the high watermark, a background thread will try to \"\n              + \"evict unused locks until the size reaches the low watermark.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_LOCK_POOL_LOW_WATERMARK"}, {"original_string": "public static final PropertyKey MASTER_LOCK_POOL_HIGH_WATERMARK =\n      new Builder(Name.MASTER_LOCK_POOL_HIGH_WATERMARK)\n          .setDefaultValue(1000000)\n          .setDescription(\"High watermark of lock pool size. \"\n              + \"When the size grows over the high watermark, a background thread starts evicting \"\n              + \"unused locks from the pool.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_LOCK_POOL_HIGH_WATERMARK =\n      new Builder(Name.MASTER_LOCK_POOL_HIGH_WATERMARK)\n          .setDefaultValue(1000000)\n          .setDescription(\"High watermark of lock pool size. \"\n              + \"When the size grows over the high watermark, a background thread starts evicting \"\n              + \"unused locks from the pool.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_LOCK_POOL_HIGH_WATERMARK"}, {"original_string": "public static final PropertyKey MASTER_LOCK_POOL_CONCURRENCY_LEVEL =\n      new Builder(Name.MASTER_LOCK_POOL_CONCURRENCY_LEVEL)\n          .setDefaultValue(100)\n          .setDescription(\"Maximum concurrency level for the lock pool\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_LOCK_POOL_CONCURRENCY_LEVEL =\n      new Builder(Name.MASTER_LOCK_POOL_CONCURRENCY_LEVEL)\n          .setDefaultValue(100)\n          .setDescription(\"Maximum concurrency level for the lock pool\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_LOCK_POOL_CONCURRENCY_LEVEL"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_FLUSH_BATCH_TIME_MS =\n      new Builder(Name.MASTER_JOURNAL_FLUSH_BATCH_TIME_MS)\n          .setAlias(\"alluxio.master.journal.flush.batch.time.ms\")\n          .setDefaultValue(\"5ms\")\n          .setDescription(\"Time to wait for batching journal writes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_FLUSH_BATCH_TIME_MS =\n      new Builder(Name.MASTER_JOURNAL_FLUSH_BATCH_TIME_MS)\n          .setAlias(\"alluxio.master.journal.flush.batch.time.ms\")\n          .setDefaultValue(\"5ms\")\n          .setDescription(\"Time to wait for batching journal writes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_FLUSH_BATCH_TIME_MS"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_FLUSH_TIMEOUT_MS =\n      new Builder(Name.MASTER_JOURNAL_FLUSH_TIMEOUT_MS)\n          .setAlias(\"alluxio.master.journal.flush.timeout.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"The amount of time to keep retrying journal \"\n              + \"writes before giving up and shutting down the master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_FLUSH_TIMEOUT_MS =\n      new Builder(Name.MASTER_JOURNAL_FLUSH_TIMEOUT_MS)\n          .setAlias(\"alluxio.master.journal.flush.timeout.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"The amount of time to keep retrying journal \"\n              + \"writes before giving up and shutting down the master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_FLUSH_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_FLUSH_RETRY_INTERVAL =\n      new Builder(Name.MASTER_JOURNAL_FLUSH_RETRY_INTERVAL)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The amount of time to sleep between retrying journal flushes\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_FLUSH_RETRY_INTERVAL =\n      new Builder(Name.MASTER_JOURNAL_FLUSH_RETRY_INTERVAL)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The amount of time to sleep between retrying journal flushes\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_FLUSH_RETRY_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_FOLDER =\n      new Builder(Name.MASTER_JOURNAL_FOLDER)\n          .setDefaultValue(String.format(\"${%s}/journal\", Name.WORK_DIR))\n          .setDescription(\"The path to store master journal logs. When using the UFS journal this \"\n              + \"could be a URI like hdfs://namenode:port/alluxio/journal. When using the embedded \"\n              + \"journal this must be a local path\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_FOLDER =\n      new Builder(Name.MASTER_JOURNAL_FOLDER)\n          .setDefaultValue(String.format(\"${%s}/journal\", Name.WORK_DIR))\n          .setDescription(\"The path to store master journal logs. When using the UFS journal this \"\n              + \"could be a URI like hdfs://namenode:port/alluxio/journal. When using the embedded \"\n              + \"journal this must be a local path\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_FOLDER"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_INIT_FROM_BACKUP =\n      new Builder(Name.MASTER_JOURNAL_INIT_FROM_BACKUP)\n          .setDescription(\"A uri for a backup to initialize the journal from. When the\"\n              + \" master becomes primary, if it sees that its journal is freshly formatted, it will\"\n              + \" restore its state from the backup. When running multiple masters, this property\"\n              + \" must be configured on all masters since it isn't known during startup which\"\n              + \" master will become the first primary.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_INIT_FROM_BACKUP =\n      new Builder(Name.MASTER_JOURNAL_INIT_FROM_BACKUP)\n          .setDescription(\"A uri for a backup to initialize the journal from. When the\"\n              + \" master becomes primary, if it sees that its journal is freshly formatted, it will\"\n              + \" restore its state from the backup. When running multiple masters, this property\"\n              + \" must be configured on all masters since it isn't known during startup which\"\n              + \" master will become the first primary.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_INIT_FROM_BACKUP"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_TOLERATE_CORRUPTION =\n      new Builder(Name.MASTER_JOURNAL_TOLERATE_CORRUPTION)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to tolerate master state corruption \"\n              + \"when standby master replaying journal. If enabled, errors from applying journal \"\n              + \"to master metadata will only be logged instead of forcing master to exit. \"\n              + \"This property should be used sparingly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setIsHidden(true)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_TOLERATE_CORRUPTION =\n      new Builder(Name.MASTER_JOURNAL_TOLERATE_CORRUPTION)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to tolerate master state corruption \"\n              + \"when standby master replaying journal. If enabled, errors from applying journal \"\n              + \"to master metadata will only be logged instead of forcing master to exit. \"\n              + \"This property should be used sparingly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setIsHidden(true)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_TOLERATE_CORRUPTION"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_TYPE =\n      new Builder(Name.MASTER_JOURNAL_TYPE)\n          .setDefaultValue(\"EMBEDDED\")\n          .setDescription(\"The type of journal to use. Valid options are UFS (store journal in \"\n              + \"UFS), EMBEDDED (use a journal embedded in the masters), and NOOP (do not use a \"\n              + \"journal)\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_TYPE =\n      new Builder(Name.MASTER_JOURNAL_TYPE)\n          .setDefaultValue(\"EMBEDDED\")\n          .setDescription(\"The type of journal to use. Valid options are UFS (store journal in \"\n              + \"UFS), EMBEDDED (use a journal embedded in the masters), and NOOP (do not use a \"\n              + \"journal)\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_TYPE"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_LOG_SIZE_BYTES_MAX =\n      new Builder(Name.MASTER_JOURNAL_LOG_SIZE_BYTES_MAX)\n          .setDefaultValue(\"10MB\")\n          .setDescription(\"If a log file is bigger than this value, it will rotate to next \"\n              + \"file.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_LOG_SIZE_BYTES_MAX =\n      new Builder(Name.MASTER_JOURNAL_LOG_SIZE_BYTES_MAX)\n          .setDefaultValue(\"10MB\")\n          .setDescription(\"If a log file is bigger than this value, it will rotate to next \"\n              + \"file.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_LOG_SIZE_BYTES_MAX"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_TAILER_SHUTDOWN_QUIET_WAIT_TIME_MS =\n      new Builder(Name.MASTER_JOURNAL_TAILER_SHUTDOWN_QUIET_WAIT_TIME_MS)\n          .setAlias(\"alluxio.master.journal.tailer.shutdown.quiet.wait.time.ms\")\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Before the standby master shuts down its tailer thread, there \"\n              + \"should be no update to the leader master's journal in this specified time \"\n              + \"period.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_TAILER_SHUTDOWN_QUIET_WAIT_TIME_MS =\n      new Builder(Name.MASTER_JOURNAL_TAILER_SHUTDOWN_QUIET_WAIT_TIME_MS)\n          .setAlias(\"alluxio.master.journal.tailer.shutdown.quiet.wait.time.ms\")\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Before the standby master shuts down its tailer thread, there \"\n              + \"should be no update to the leader master's journal in this specified time \"\n              + \"period.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_TAILER_SHUTDOWN_QUIET_WAIT_TIME_MS"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_TAILER_SLEEP_TIME_MS =\n      new Builder(Name.MASTER_JOURNAL_TAILER_SLEEP_TIME_MS)\n          .setAlias(\"alluxio.master.journal.tailer.sleep.time.ms\")\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Time for the standby master to sleep for when it \"\n              + \"cannot find anything new in leader master's journal.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_TAILER_SLEEP_TIME_MS =\n      new Builder(Name.MASTER_JOURNAL_TAILER_SLEEP_TIME_MS)\n          .setAlias(\"alluxio.master.journal.tailer.sleep.time.ms\")\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"Time for the standby master to sleep for when it \"\n              + \"cannot find anything new in leader master's journal.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_TAILER_SLEEP_TIME_MS"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_CHECKPOINT_PERIOD_ENTRIES =\n      new Builder(Name.MASTER_JOURNAL_CHECKPOINT_PERIOD_ENTRIES)\n          .setDefaultValue(2000000)\n          .setDescription(\"The number of journal entries to write before creating a new \"\n              + \"journal checkpoint.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_CHECKPOINT_PERIOD_ENTRIES =\n      new Builder(Name.MASTER_JOURNAL_CHECKPOINT_PERIOD_ENTRIES)\n          .setDefaultValue(2000000)\n          .setDescription(\"The number of journal entries to write before creating a new \"\n              + \"journal checkpoint.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_CHECKPOINT_PERIOD_ENTRIES"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_GC_PERIOD_MS =\n      new Builder(Name.MASTER_JOURNAL_GC_PERIOD_MS)\n          .setAlias(\"alluxio.master.journal.gc.period.ms\")\n          .setDefaultValue(\"2min\")\n          .setDescription(\"Frequency with which to scan for and delete stale journal checkpoints.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_GC_PERIOD_MS =\n      new Builder(Name.MASTER_JOURNAL_GC_PERIOD_MS)\n          .setAlias(\"alluxio.master.journal.gc.period.ms\")\n          .setDefaultValue(\"2min\")\n          .setDescription(\"Frequency with which to scan for and delete stale journal checkpoints.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_GC_PERIOD_MS"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_GC_THRESHOLD_MS =\n      new Builder(Name.MASTER_JOURNAL_GC_THRESHOLD_MS)\n          .setAlias(\"alluxio.master.journal.gc.threshold.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Minimum age for garbage collecting checkpoints.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_GC_THRESHOLD_MS =\n      new Builder(Name.MASTER_JOURNAL_GC_THRESHOLD_MS)\n          .setAlias(\"alluxio.master.journal.gc.threshold.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Minimum age for garbage collecting checkpoints.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_GC_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey MASTER_JOURNAL_TEMPORARY_FILE_GC_THRESHOLD_MS =\n      new Builder(Name.MASTER_JOURNAL_TEMPORARY_FILE_GC_THRESHOLD_MS)\n          .setAlias(\"alluxio.master.journal.temporary.file.gc.threshold.ms\")\n          .setDescription(\"Minimum age for garbage collecting temporary checkpoint files.\")\n          .setDefaultValue(\"30min\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JOURNAL_TEMPORARY_FILE_GC_THRESHOLD_MS =\n      new Builder(Name.MASTER_JOURNAL_TEMPORARY_FILE_GC_THRESHOLD_MS)\n          .setAlias(\"alluxio.master.journal.temporary.file.gc.threshold.ms\")\n          .setDescription(\"Minimum age for garbage collecting temporary checkpoint files.\")\n          .setDefaultValue(\"30min\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JOURNAL_TEMPORARY_FILE_GC_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey MASTER_KEYTAB_KEY_FILE =\n      new Builder(Name.MASTER_KEYTAB_KEY_FILE)\n          .setDescription(\"Kerberos keytab file for Alluxio master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_KEYTAB_KEY_FILE =\n      new Builder(Name.MASTER_KEYTAB_KEY_FILE)\n          .setDescription(\"Kerberos keytab file for Alluxio master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_KEYTAB_KEY_FILE"}, {"original_string": "public static final PropertyKey MASTER_LOG_CONFIG_REPORT_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_LOG_CONFIG_REPORT_HEARTBEAT_INTERVAL)\n          .setDefaultValue(\"1h\")\n          .setDescription(\"The interval for periodically logging the configuration check report.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_LOG_CONFIG_REPORT_HEARTBEAT_INTERVAL =\n      new Builder(Name.MASTER_LOG_CONFIG_REPORT_HEARTBEAT_INTERVAL)\n          .setDefaultValue(\"1h\")\n          .setDescription(\"The interval for periodically logging the configuration check report.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_LOG_CONFIG_REPORT_HEARTBEAT_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_REPAIR =\n      new Builder(Name.MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_REPAIR)\n          .setDefaultValue(false)\n          .setDescription(\"Whether the system should delete orphaned blocks found during the \"\n              + \"periodic integrity check. This is an experimental feature.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_REPAIR =\n      new Builder(Name.MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_REPAIR)\n          .setDefaultValue(false)\n          .setDescription(\"Whether the system should delete orphaned blocks found during the \"\n              + \"periodic integrity check. This is an experimental feature.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_REPAIR"}, {"original_string": "public static final PropertyKey MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_INTERVAL =\n      new Builder(Name.MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_INTERVAL)\n          .setDefaultValue(\"1hr\")\n          .setDescription(\"The period for the block integrity check, disabled if <= 0.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_INTERVAL =\n      new Builder(Name.MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_INTERVAL)\n          .setDefaultValue(\"1hr\")\n          .setDescription(\"The period for the block integrity check, disabled if <= 0.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERIODIC_BLOCK_INTEGRITY_CHECK_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_PERSISTENCE_CHECKER_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_CHECKER_INTERVAL_MS)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"How often the master checks persistence status for files written using \"\n              + \"ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERSISTENCE_CHECKER_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_CHECKER_INTERVAL_MS)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"How often the master checks persistence status for files written using \"\n              + \"ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERSISTENCE_CHECKER_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_PERSISTENCE_INITIAL_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_INITIAL_INTERVAL_MS)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"How often the  master persistence checker checks persistence status \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERSISTENCE_INITIAL_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_INITIAL_INTERVAL_MS)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"How often the  master persistence checker checks persistence status \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERSISTENCE_INITIAL_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_PERSISTENCE_MAX_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_MAX_INTERVAL_MS)\n          .setDefaultValue(\"1hr\")\n          .setDescription(\"Max wait interval for master persistence checker persistence status \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERSISTENCE_MAX_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_MAX_INTERVAL_MS)\n          .setDefaultValue(\"1hr\")\n          .setDescription(\"Max wait interval for master persistence checker persistence status \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERSISTENCE_MAX_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS =\n      new Builder(Name.MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS)\n          .setDefaultValue(\"1day\")\n          .setDescription(\"Total wait time for master persistence checker persistence status \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS =\n      new Builder(Name.MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS)\n          .setDefaultValue(\"1day\")\n          .setDescription(\"Total wait time for master persistence checker persistence status \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS"}, {"original_string": "public static final PropertyKey MASTER_PERSISTENCE_SCHEDULER_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_SCHEDULER_INTERVAL_MS)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"How often the master schedules persistence jobs \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERSISTENCE_SCHEDULER_INTERVAL_MS =\n      new Builder(Name.MASTER_PERSISTENCE_SCHEDULER_INTERVAL_MS)\n          .setDefaultValue(\"1s\")\n          .setDescription(\"How often the master schedules persistence jobs \"\n              + \"for files written using ASYNC_THROUGH\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_PERSISTENCE_SCHEDULER_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_PERSISTENCE_BLACKLIST =\n      new Builder(Name.MASTER_PERSISTENCE_BLACKLIST)\n          .setDescription(\"Patterns to blacklist persist, comma separated, string match, no regex.\"\n            + \" This affects any async persist call (including ASYNC_THROUGH writes and CLI \"\n            + \"persist) but does not affect CACHE_THROUGH writes. Users may want to specify \"\n            + \"temporary files in the blacklist to avoid unnecessary I/O and errors. Some \"\n            + \"examples are `.staging` and `.tmp`.\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PERSISTENCE_BLACKLIST =\n      new Builder(Name.MASTER_PERSISTENCE_BLACKLIST)\n          .setDescription(\"Patterns to blacklist persist, comma separated, string match, no regex.\"\n            + \" This affects any async persist call (including ASYNC_THROUGH writes and CLI \"\n            + \"persist) but does not affect CACHE_THROUGH writes. Users may want to specify \"\n            + \"temporary files in the blacklist to avoid unnecessary I/O and errors. Some \"\n            + \"examples are `.staging` and `.tmp`.\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build()", "var_name": "MASTER_PERSISTENCE_BLACKLIST"}, {"original_string": "public static final PropertyKey MASTER_REPLICATION_CHECK_INTERVAL_MS =\n      new Builder(Name.MASTER_REPLICATION_CHECK_INTERVAL_MS)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"How often the master runs background process to check replication \"\n              + \"level for files\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_REPLICATION_CHECK_INTERVAL_MS =\n      new Builder(Name.MASTER_REPLICATION_CHECK_INTERVAL_MS)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"How often the master runs background process to check replication \"\n              + \"level for files\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_REPLICATION_CHECK_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_PRINCIPAL = new Builder(Name.MASTER_PRINCIPAL)\n      .setDescription(\"Kerberos principal for Alluxio master.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.MASTER)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_PRINCIPAL = new Builder(Name.MASTER_PRINCIPAL)\n      .setDescription(\"Kerberos principal for Alluxio master.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.MASTER)\n      .build()", "var_name": "MASTER_PRINCIPAL"}, {"original_string": "public static final PropertyKey MASTER_RPC_PORT =\n      new Builder(Name.MASTER_RPC_PORT)\n          .setAlias(\"alluxio.master.port\")\n          .setDefaultValue(19998)\n          .setDescription(\"The port for Alluxio master's RPC service.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_PORT =\n      new Builder(Name.MASTER_RPC_PORT)\n          .setAlias(\"alluxio.master.port\")\n          .setDefaultValue(19998)\n          .setDescription(\"The port for Alluxio master's RPC service.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "MASTER_RPC_PORT"}, {"original_string": "public static final PropertyKey MASTER_SERVING_THREAD_TIMEOUT =\n      new Builder(Name.MASTER_SERVING_THREAD_TIMEOUT)\n          .setDefaultValue(\"5m\")\n          .setDescription(\"When stepping down from being the primary, the master will wait this \"\n              + \"long for the gRPC serving thread to stop before giving up and shutting down \"\n              + \"the server\")\n          .setIsHidden(true)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_SERVING_THREAD_TIMEOUT =\n      new Builder(Name.MASTER_SERVING_THREAD_TIMEOUT)\n          .setDefaultValue(\"5m\")\n          .setDescription(\"When stepping down from being the primary, the master will wait this \"\n              + \"long for the gRPC serving thread to stop before giving up and shutting down \"\n              + \"the server\")\n          .setIsHidden(true)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_SERVING_THREAD_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_SKIP_ROOT_ACL_CHECK =\n      new Builder(Name.MASTER_SKIP_ROOT_ACL_CHECK)\n          .setDefaultValue(false)\n          .setDescription(\"Skip root directory ACL check when restarting either from journal or \"\n              + \"backup. This is to allow users to restore a backup from a different cluster onto \"\n              + \"their current one without having to recreate the different clusters owner user.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .setIsHidden(true)\n          .setIgnoredSiteProperty(true)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_SKIP_ROOT_ACL_CHECK =\n      new Builder(Name.MASTER_SKIP_ROOT_ACL_CHECK)\n          .setDefaultValue(false)\n          .setDescription(\"Skip root directory ACL check when restarting either from journal or \"\n              + \"backup. This is to allow users to restore a backup from a different cluster onto \"\n              + \"their current one without having to recreate the different clusters owner user.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .setIsHidden(true)\n          .setIgnoredSiteProperty(true)\n          .build()", "var_name": "MASTER_SKIP_ROOT_ACL_CHECK"}, {"original_string": "public static final PropertyKey MASTER_STARTUP_BLOCK_INTEGRITY_CHECK_ENABLED =\n      new Builder(Name.MASTER_STARTUP_BLOCK_INTEGRITY_CHECK_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether the system should be checked on startup for orphaned blocks \"\n              + \"(blocks having no corresponding files but still taking system resource due to \"\n              + \"various system failures). Orphaned blocks will be deleted during master startup \"\n              + \"if this property is true. This property is available since 1.7.1\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_STARTUP_BLOCK_INTEGRITY_CHECK_ENABLED =\n      new Builder(Name.MASTER_STARTUP_BLOCK_INTEGRITY_CHECK_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether the system should be checked on startup for orphaned blocks \"\n              + \"(blocks having no corresponding files but still taking system resource due to \"\n              + \"various system failures). Orphaned blocks will be deleted during master startup \"\n              + \"if this property is true. This property is available since 1.7.1\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_STARTUP_BLOCK_INTEGRITY_CHECK_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_TIERED_STORE_GLOBAL_LEVEL0_ALIAS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVEL0_ALIAS)\n          .setDefaultValue(\"MEM\")\n          .setDescription(\"The name of the highest storage tier in the entire system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_TIERED_STORE_GLOBAL_LEVEL0_ALIAS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVEL0_ALIAS)\n          .setDefaultValue(\"MEM\")\n          .setDescription(\"The name of the highest storage tier in the entire system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_TIERED_STORE_GLOBAL_LEVEL0_ALIAS"}, {"original_string": "public static final PropertyKey MASTER_TIERED_STORE_GLOBAL_LEVEL1_ALIAS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVEL1_ALIAS)\n          .setDefaultValue(\"SSD\")\n          .setDescription(\"The name of the second highest storage tier in the entire system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_TIERED_STORE_GLOBAL_LEVEL1_ALIAS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVEL1_ALIAS)\n          .setDefaultValue(\"SSD\")\n          .setDescription(\"The name of the second highest storage tier in the entire system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_TIERED_STORE_GLOBAL_LEVEL1_ALIAS"}, {"original_string": "public static final PropertyKey MASTER_TIERED_STORE_GLOBAL_LEVEL2_ALIAS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVEL2_ALIAS)\n          .setDefaultValue(\"HDD\")\n          .setDescription(\"The name of the third highest storage tier in the entire system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_TIERED_STORE_GLOBAL_LEVEL2_ALIAS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVEL2_ALIAS)\n          .setDefaultValue(\"HDD\")\n          .setDescription(\"The name of the third highest storage tier in the entire system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_TIERED_STORE_GLOBAL_LEVEL2_ALIAS"}, {"original_string": "public static final PropertyKey MASTER_TIERED_STORE_GLOBAL_LEVELS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVELS)\n          .setDefaultValue(3)\n          .setDescription(\"The total number of storage tiers in the system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_TIERED_STORE_GLOBAL_LEVELS =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_LEVELS)\n          .setDefaultValue(3)\n          .setDescription(\"The total number of storage tiers in the system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_TIERED_STORE_GLOBAL_LEVELS"}, {"original_string": "public static final PropertyKey MASTER_TIERED_STORE_GLOBAL_MEDIUMTYPE =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_MEDIUMTYPE)\n          .setDefaultValue(\"MEM, SSD, HDD\")\n          .setDescription(\"The list of medium types we support in the system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_TIERED_STORE_GLOBAL_MEDIUMTYPE =\n      new Builder(Name.MASTER_TIERED_STORE_GLOBAL_MEDIUMTYPE)\n          .setDefaultValue(\"MEM, SSD, HDD\")\n          .setDescription(\"The list of medium types we support in the system.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_TIERED_STORE_GLOBAL_MEDIUMTYPE"}, {"original_string": "public static final PropertyKey MASTER_TTL_CHECKER_INTERVAL_MS =\n      new Builder(Name.MASTER_TTL_CHECKER_INTERVAL_MS)\n          .setAlias(\"alluxio.master.ttl.checker.interval.ms\")\n          .setDefaultValue(\"1hour\")\n          .setDescription(\"How often to periodically check and delete the files \"\n              + \"with expired ttl value.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_TTL_CHECKER_INTERVAL_MS =\n      new Builder(Name.MASTER_TTL_CHECKER_INTERVAL_MS)\n          .setAlias(\"alluxio.master.ttl.checker.interval.ms\")\n          .setDefaultValue(\"1hour\")\n          .setDescription(\"How often to periodically check and delete the files \"\n              + \"with expired ttl value.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_TTL_CHECKER_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_INTERVAL =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_INTERVAL)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Time interval to periodically actively sync UFS\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_INTERVAL =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_INTERVAL)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"Time interval to periodically actively sync UFS\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_MAX_AGE =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_MAX_AGE)\n          .setDefaultValue(\"10\")\n          .setDescription(\"The maximum number of intervals we will wait to find a quiet \"\n            + \"period before we have to sync the directories\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_MAX_AGE =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_MAX_AGE)\n          .setDefaultValue(\"10\")\n          .setDescription(\"The maximum number of intervals we will wait to find a quiet \"\n            + \"period before we have to sync the directories\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_MAX_AGE"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_INITIAL_SYNC_ENABLED =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_INITIAL_SYNC_ENABLED)\n          .setDefaultValue(\"true\")\n          .setDescription(\"Whether to perform an initial sync when we add a sync point\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .setIsHidden(true)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_INITIAL_SYNC_ENABLED =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_INITIAL_SYNC_ENABLED)\n          .setDefaultValue(\"true\")\n          .setDescription(\"Whether to perform an initial sync when we add a sync point\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .setIsHidden(true)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_INITIAL_SYNC_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_MAX_ACTIVITIES =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_MAX_ACTIVITIES)\n          .setDefaultValue(\"10\")\n          .setDescription(\"Max number of changes in a directory \"\n              + \"to be considered for active syncing\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_MAX_ACTIVITIES =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_MAX_ACTIVITIES)\n          .setDefaultValue(\"10\")\n          .setDescription(\"Max number of changes in a directory \"\n              + \"to be considered for active syncing\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_MAX_ACTIVITIES"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_THREAD_POOL_SIZE =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_THREAD_POOL_SIZE)\n          .setDefaultSupplier(() -> Math.max(2, Runtime.getRuntime().availableProcessors() / 2),\n              \"The number of threads used by the active sync provider process active sync events.\"\n                  + \" A higher number allow the master to use more CPU to process events from \"\n                  + \"an event stream in parallel. If this value is too low, Alluxio may fall \"\n                  + \"behind processing events. Defaults to # of processors / 2\")\n          .setDescription(\"Max number of threads used to perform active sync\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_THREAD_POOL_SIZE =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_THREAD_POOL_SIZE)\n          .setDefaultSupplier(() -> Math.max(2, Runtime.getRuntime().availableProcessors() / 2),\n              \"The number of threads used by the active sync provider process active sync events.\"\n                  + \" A higher number allow the master to use more CPU to process events from \"\n                  + \"an event stream in parallel. If this value is too low, Alluxio may fall \"\n                  + \"behind processing events. Defaults to # of processors / 2\")\n          .setDescription(\"Max number of threads used to perform active sync\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_THREAD_POOL_SIZE"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_POLL_TIMEOUT =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_POLL_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"Max time to wait before timing out a polling operation\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_POLL_TIMEOUT =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_POLL_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"Max time to wait before timing out a polling operation\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_POLL_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_EVENT_RATE_INTERVAL =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_EVENT_RATE_INTERVAL)\n          .setDefaultValue(\"60sec\")\n          .setDescription(\"The time interval we use to estimate incoming event rate\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_EVENT_RATE_INTERVAL =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_EVENT_RATE_INTERVAL)\n          .setDefaultValue(\"60sec\")\n          .setDescription(\"The time interval we use to estimate incoming event rate\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_EVENT_RATE_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_RETRY_TIMEOUT =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_RETRY_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The max total duration to retry failed active sync operations.\"\n              + \"A large duration is useful to handle transient failures such as an \"\n              + \"unresponsive under storage but can lock the inode tree being synced longer.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_RETRY_TIMEOUT =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_RETRY_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The max total duration to retry failed active sync operations.\"\n              + \"A large duration is useful to handle transient failures such as an \"\n              + \"unresponsive under storage but can lock the inode tree being synced longer.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_RETRY_TIMEOUT"}, {"original_string": "public static final PropertyKey MASTER_UFS_ACTIVE_SYNC_POLL_BATCH_SIZE =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_POLL_BATCH_SIZE)\n          .setDefaultValue(\"1024\")\n          .setDescription(\"The number of event batches that should be submitted together to a \"\n              + \"single thread for processing.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_ACTIVE_SYNC_POLL_BATCH_SIZE =\n      new Builder(Name.MASTER_UFS_ACTIVE_SYNC_POLL_BATCH_SIZE)\n          .setDefaultValue(\"1024\")\n          .setDescription(\"The number of event batches that should be submitted together to a \"\n              + \"single thread for processing.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_ACTIVE_SYNC_POLL_BATCH_SIZE"}, {"original_string": "public static final PropertyKey MASTER_UFS_BLOCK_LOCATION_CACHE_CAPACITY =\n      new Builder(Name.MASTER_UFS_BLOCK_LOCATION_CACHE_CAPACITY)\n          .setDefaultValue(1000000)\n          .setDescription(\"The capacity of the UFS block locations cache. \"\n              + \"This cache caches UFS block locations for files that are persisted \"\n              + \"but not in Alluxio space, so that listing status of these files do not need to \"\n              + \"repeatedly ask UFS for their block locations. If this is set to 0, the cache \"\n              + \"will be disabled.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_BLOCK_LOCATION_CACHE_CAPACITY =\n      new Builder(Name.MASTER_UFS_BLOCK_LOCATION_CACHE_CAPACITY)\n          .setDefaultValue(1000000)\n          .setDescription(\"The capacity of the UFS block locations cache. \"\n              + \"This cache caches UFS block locations for files that are persisted \"\n              + \"but not in Alluxio space, so that listing status of these files do not need to \"\n              + \"repeatedly ask UFS for their block locations. If this is set to 0, the cache \"\n              + \"will be disabled.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_BLOCK_LOCATION_CACHE_CAPACITY"}, {"original_string": "public static final PropertyKey MASTER_UFS_MANAGED_BLOCKING_ENABLED =\n      new Builder(Name.MASTER_UFS_MANAGED_BLOCKING_ENABLED)\n          .setDescription(\"Whether to run UFS operations with managed blocking. \"\n              + \"This will provide RPC layer a hint that UFS is possible slow.\"\n              + \"The default is true for object stores and false for the rest. \"\n              + \"unless set explicitly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .setIsHidden(true)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_MANAGED_BLOCKING_ENABLED =\n      new Builder(Name.MASTER_UFS_MANAGED_BLOCKING_ENABLED)\n          .setDescription(\"Whether to run UFS operations with managed blocking. \"\n              + \"This will provide RPC layer a hint that UFS is possible slow.\"\n              + \"The default is true for object stores and false for the rest. \"\n              + \"unless set explicitly.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .setIsHidden(true)\n          .build()", "var_name": "MASTER_UFS_MANAGED_BLOCKING_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_UFS_PATH_CACHE_CAPACITY =\n      new Builder(Name.MASTER_UFS_PATH_CACHE_CAPACITY)\n          .setDefaultValue(100000)\n          .setDescription(\"The capacity of the UFS path cache. This cache is used to \"\n              + \"approximate the `ONCE` metadata load behavior (see \"\n              + \"`alluxio.user.file.metadata.load.type`). Larger caches will consume more \"\n              + \"memory, but will better approximate the `ONCE` behavior.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_PATH_CACHE_CAPACITY =\n      new Builder(Name.MASTER_UFS_PATH_CACHE_CAPACITY)\n          .setDefaultValue(100000)\n          .setDescription(\"The capacity of the UFS path cache. This cache is used to \"\n              + \"approximate the `ONCE` metadata load behavior (see \"\n              + \"`alluxio.user.file.metadata.load.type`). Larger caches will consume more \"\n              + \"memory, but will better approximate the `ONCE` behavior.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_PATH_CACHE_CAPACITY"}, {"original_string": "public static final PropertyKey MASTER_UFS_PATH_CACHE_THREADS =\n      new Builder(Name.MASTER_UFS_PATH_CACHE_THREADS)\n          .setDefaultValue(64)\n          .setDescription(\"The maximum size of the thread pool for asynchronously processing \"\n              + \"paths for the UFS path cache. Greater number of threads will decrease the \"\n              + \"amount of staleness in the async cache, but may impact performance. If this \"\n              + \"is set to 0, the cache will be disabled, and \"\n              + \"`alluxio.user.file.metadata.load.type=ONCE` will behave like `ALWAYS`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UFS_PATH_CACHE_THREADS =\n      new Builder(Name.MASTER_UFS_PATH_CACHE_THREADS)\n          .setDefaultValue(64)\n          .setDescription(\"The maximum size of the thread pool for asynchronously processing \"\n              + \"paths for the UFS path cache. Greater number of threads will decrease the \"\n              + \"amount of staleness in the async cache, but may impact performance. If this \"\n              + \"is set to 0, the cache will be disabled, and \"\n              + \"`alluxio.user.file.metadata.load.type=ONCE` will behave like `ALWAYS`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UFS_PATH_CACHE_THREADS"}, {"original_string": "public static final PropertyKey MASTER_UPDATE_CHECK_ENABLED =\n      new Builder(Name.MASTER_UPDATE_CHECK_ENABLED)\n          .setDefaultValue(ProjectConstants.UPDATE_CHECK_ENABLED)\n          .setDescription(\"Whether to check for update availability.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UPDATE_CHECK_ENABLED =\n      new Builder(Name.MASTER_UPDATE_CHECK_ENABLED)\n          .setDefaultValue(ProjectConstants.UPDATE_CHECK_ENABLED)\n          .setDescription(\"Whether to check for update availability.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UPDATE_CHECK_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_UPDATE_CHECK_INTERVAL =\n      new Builder(Name.MASTER_UPDATE_CHECK_INTERVAL)\n          .setDefaultValue(\"7day\")\n          .setDescription(\"The interval to check for update availability.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UPDATE_CHECK_INTERVAL =\n      new Builder(Name.MASTER_UPDATE_CHECK_INTERVAL)\n          .setDefaultValue(\"7day\")\n          .setDescription(\"The interval to check for update availability.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UPDATE_CHECK_INTERVAL"}, {"original_string": "public static final PropertyKey MASTER_UNSAFE_DIRECT_PERSIST_OBJECT_ENABLED =\n      new Builder(Name.MASTER_UNSAFE_DIRECT_PERSIST_OBJECT_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"When set to false, writing files using ASYNC_THROUGH or persist CLI \"\n              + \"with object stores as the UFS will first create temporary objects \"\n              + \"suffixed by \\\".alluxio.TIMESTAMP.tmp\\\" in the object store before \"\n              + \"committed to the final UFS path. When set to true, files will be \"\n              + \"put to the destination path directly in the object store without staging \"\n              + \"with a temp suffix. Enabling this optimization by directly persisting files \"\n              + \"can significantly improve the efficiency writing to object store by making less \"\n              + \"data copy as rename in object store can be slow, \"\n              + \"but leaving a short vulnerability window for undefined behavior if a file \"\n              + \"is written using ASYNC_THROUGH but renamed or removed before the async \"\n              + \"persist operation completes, while this same file path was reused for other new \"\n              + \"files in Alluxio.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_UNSAFE_DIRECT_PERSIST_OBJECT_ENABLED =\n      new Builder(Name.MASTER_UNSAFE_DIRECT_PERSIST_OBJECT_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"When set to false, writing files using ASYNC_THROUGH or persist CLI \"\n              + \"with object stores as the UFS will first create temporary objects \"\n              + \"suffixed by \\\".alluxio.TIMESTAMP.tmp\\\" in the object store before \"\n              + \"committed to the final UFS path. When set to true, files will be \"\n              + \"put to the destination path directly in the object store without staging \"\n              + \"with a temp suffix. Enabling this optimization by directly persisting files \"\n              + \"can significantly improve the efficiency writing to object store by making less \"\n              + \"data copy as rename in object store can be slow, \"\n              + \"but leaving a short vulnerability window for undefined behavior if a file \"\n              + \"is written using ASYNC_THROUGH but renamed or removed before the async \"\n              + \"persist operation completes, while this same file path was reused for other new \"\n              + \"files in Alluxio.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_UNSAFE_DIRECT_PERSIST_OBJECT_ENABLED"}, {"original_string": "public static final PropertyKey MASTER_WEB_BIND_HOST =\n      new Builder(Name.MASTER_WEB_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname Alluxio master web UI binds to.\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WEB_BIND_HOST =\n      new Builder(Name.MASTER_WEB_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname Alluxio master web UI binds to.\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_WEB_BIND_HOST"}, {"original_string": "public static final PropertyKey MASTER_WEB_HOSTNAME =\n      new Builder(Name.MASTER_WEB_HOSTNAME)\n          .setDescription(\"The hostname of Alluxio Master web UI.\")\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WEB_HOSTNAME =\n      new Builder(Name.MASTER_WEB_HOSTNAME)\n          .setDescription(\"The hostname of Alluxio Master web UI.\")\n          .setScope(Scope.ALL)\n          .build()", "var_name": "MASTER_WEB_HOSTNAME"}, {"original_string": "public static final PropertyKey MASTER_WEB_PORT =\n      new Builder(Name.MASTER_WEB_PORT)\n          .setDefaultValue(19999)\n          .setDescription(\"The port Alluxio web UI runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WEB_PORT =\n      new Builder(Name.MASTER_WEB_PORT)\n          .setDefaultValue(19999)\n          .setDescription(\"The port Alluxio web UI runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_WEB_PORT"}, {"original_string": "public static final PropertyKey MASTER_WHITELIST =\n      new Builder(Name.MASTER_WHITELIST)\n          .setDefaultValue(\"/\")\n          .setDescription(\"A comma-separated list of prefixes of the paths which are \"\n              + \"cacheable, separated by semi-colons. Alluxio will try to cache the cacheable \"\n              + \"file when it is read for the first time.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WHITELIST =\n      new Builder(Name.MASTER_WHITELIST)\n          .setDefaultValue(\"/\")\n          .setDescription(\"A comma-separated list of prefixes of the paths which are \"\n              + \"cacheable, separated by semi-colons. Alluxio will try to cache the cacheable \"\n              + \"file when it is read for the first time.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_WHITELIST"}, {"original_string": "public static final PropertyKey MASTER_WORKER_CONNECT_WAIT_TIME =\n      new Builder(Name.MASTER_WORKER_CONNECT_WAIT_TIME)\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Alluxio master will wait a period of time after start up for \"\n              + \"all workers to register, before it starts accepting client requests. \"\n              + \"This property determines the wait time.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n              .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WORKER_CONNECT_WAIT_TIME =\n      new Builder(Name.MASTER_WORKER_CONNECT_WAIT_TIME)\n          .setDefaultValue(\"5sec\")\n          .setDescription(\"Alluxio master will wait a period of time after start up for \"\n              + \"all workers to register, before it starts accepting client requests. \"\n              + \"This property determines the wait time.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n              .build()", "var_name": "MASTER_WORKER_CONNECT_WAIT_TIME"}, {"original_string": "public static final PropertyKey MASTER_WORKER_INFO_CACHE_REFRESH_TIME =\n      new Builder(Name.MASTER_WORKER_INFO_CACHE_REFRESH_TIME)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The worker information list will be refreshed \"\n              + \"after being cached for this time period. If the refresh time is too big, \"\n              + \"operations on the job servers or clients may fail because of \"\n              + \"the stale worker info. If it is too small, \"\n              + \"continuously updating worker information may case lock contention \"\n              + \"in the block master\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WORKER_INFO_CACHE_REFRESH_TIME =\n      new Builder(Name.MASTER_WORKER_INFO_CACHE_REFRESH_TIME)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The worker information list will be refreshed \"\n              + \"after being cached for this time period. If the refresh time is too big, \"\n              + \"operations on the job servers or clients may fail because of \"\n              + \"the stale worker info. If it is too small, \"\n              + \"continuously updating worker information may case lock contention \"\n              + \"in the block master\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_WORKER_INFO_CACHE_REFRESH_TIME"}, {"original_string": "public static final PropertyKey MASTER_WORKER_TIMEOUT_MS =\n      new Builder(Name.MASTER_WORKER_TIMEOUT_MS)\n          .setAlias(\"alluxio.master.worker.timeout.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Timeout between master and worker indicating a lost worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_WORKER_TIMEOUT_MS =\n      new Builder(Name.MASTER_WORKER_TIMEOUT_MS)\n          .setAlias(\"alluxio.master.worker.timeout.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Timeout between master and worker indicating a lost worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_WORKER_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey MASTER_METADATA_SYNC_CONCURRENCY_LEVEL =\n      new Builder(Name.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL)\n          .setDefaultValue(6)\n          .setDescription(\"The maximum number of concurrent sync tasks running for a given sync \"\n              + \"operation\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METADATA_SYNC_CONCURRENCY_LEVEL =\n      new Builder(Name.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL)\n          .setDefaultValue(6)\n          .setDescription(\"The maximum number of concurrent sync tasks running for a given sync \"\n              + \"operation\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build()", "var_name": "MASTER_METADATA_SYNC_CONCURRENCY_LEVEL"}, {"original_string": "public static final PropertyKey MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE =\n      new Builder(Name.MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"The total number of threads which can concurrently execute metadata sync \"\n                  + \"operations.\")\n          .setDescription(\"The number of threads used to execute all metadata sync\"\n              + \"operations\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE =\n      new Builder(Name.MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"The total number of threads which can concurrently execute metadata sync \"\n                  + \"operations.\")\n          .setDescription(\"The number of threads used to execute all metadata sync\"\n              + \"operations\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build()", "var_name": "MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE"}, {"original_string": "public static final PropertyKey MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE =\n      new Builder(Name.MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"The number of threads which can concurrently fetch metadata from UFSes during a \"\n                  + \"metadata sync operations\")\n          .setDescription(\"The number of threads used to fetch UFS objects for all metadata sync\"\n              + \"operations\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE =\n      new Builder(Name.MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"The number of threads which can concurrently fetch metadata from UFSes during a \"\n                  + \"metadata sync operations\")\n          .setDescription(\"The number of threads used to fetch UFS objects for all metadata sync\"\n              + \"operations\")\n          .setScope(Scope.MASTER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .build()", "var_name": "MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE"}, {"original_string": "public static final PropertyKey MASTER_RPC_EXECUTOR_PARALLELISM =\n      new Builder(Name.MASTER_RPC_EXECUTOR_PARALLELISM)\n          .setDefaultSupplier(() -> 2 * Runtime.getRuntime().availableProcessors(),\n              \"2 * {CPU core count}\")\n          .setDescription(\"The parallelism level of master RPC executor service .\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_EXECUTOR_PARALLELISM =\n      new Builder(Name.MASTER_RPC_EXECUTOR_PARALLELISM)\n          .setDefaultSupplier(() -> 2 * Runtime.getRuntime().availableProcessors(),\n              \"2 * {CPU core count}\")\n          .setDescription(\"The parallelism level of master RPC executor service .\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_RPC_EXECUTOR_PARALLELISM"}, {"original_string": "public static final PropertyKey MASTER_RPC_EXECUTOR_MIN_RUNNABLE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_MIN_RUNNABLE)\n          .setDefaultValue(1)\n          .setDescription(\"the minimum allowed number of core threads not blocked. \"\n              + \"To ensure progress, when too few unblocked threads exist and unexecuted tasks may \"\n              + \"exist, new threads are constructed up to the value of \"\n              + Name.MASTER_RPC_EXECUTOR_MAX_POOL_SIZE\n              + \". A value of 1 ensures liveness. A larger value might improve \"\n              + \"throughput but might also increase overhead.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_EXECUTOR_MIN_RUNNABLE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_MIN_RUNNABLE)\n          .setDefaultValue(1)\n          .setDescription(\"the minimum allowed number of core threads not blocked. \"\n              + \"To ensure progress, when too few unblocked threads exist and unexecuted tasks may \"\n              + \"exist, new threads are constructed up to the value of \"\n              + Name.MASTER_RPC_EXECUTOR_MAX_POOL_SIZE\n              + \". A value of 1 ensures liveness. A larger value might improve \"\n              + \"throughput but might also increase overhead.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_RPC_EXECUTOR_MIN_RUNNABLE"}, {"original_string": "public static final PropertyKey MASTER_RPC_EXECUTOR_CORE_POOL_SIZE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_CORE_POOL_SIZE)\n          .setDefaultValue(0)\n          .setDescription(\"the number of threads to keep in thread pool of master RPC executor \"\n              + \"service. By default it is same as the parallelism level, but may be \"\n              + \"set to a larger value to reduce dynamic overhead if tasks regularly block. \"\n              + \"A smaller value (for example 0) is equivalent to the default.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_EXECUTOR_CORE_POOL_SIZE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_CORE_POOL_SIZE)\n          .setDefaultValue(0)\n          .setDescription(\"the number of threads to keep in thread pool of master RPC executor \"\n              + \"service. By default it is same as the parallelism level, but may be \"\n              + \"set to a larger value to reduce dynamic overhead if tasks regularly block. \"\n              + \"A smaller value (for example 0) is equivalent to the default.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_RPC_EXECUTOR_CORE_POOL_SIZE"}, {"original_string": "public static final PropertyKey MASTER_RPC_EXECUTOR_MAX_POOL_SIZE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_MAX_POOL_SIZE)\n          .setDefaultValue(500)\n          .setDescription(\"the maximum number of threads allowed for master RPC executor service.\"\n              + \" When the maximum is reached, attempts to replace blocked threads fail.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_EXECUTOR_MAX_POOL_SIZE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_MAX_POOL_SIZE)\n          .setDefaultValue(500)\n          .setDescription(\"the maximum number of threads allowed for master RPC executor service.\"\n              + \" When the maximum is reached, attempts to replace blocked threads fail.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_RPC_EXECUTOR_MAX_POOL_SIZE"}, {"original_string": "public static final PropertyKey MASTER_RPC_EXECUTOR_KEEPALIVE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_KEEPALIVE)\n          .setDefaultValue(\"60sec\")\n          .setDescription(\"the keep alive time of a thread in master RPC executor service\"\n              + \"last used before this thread is terminated (and replaced if necessary).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_RPC_EXECUTOR_KEEPALIVE =\n      new Builder(Name.MASTER_RPC_EXECUTOR_KEEPALIVE)\n          .setDefaultValue(\"60sec\")\n          .setDescription(\"the keep alive time of a thread in master RPC executor service\"\n              + \"last used before this thread is terminated (and replaced if necessary).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_RPC_EXECUTOR_KEEPALIVE"}, {"original_string": "public static final PropertyKey SECONDARY_MASTER_METASTORE_DIR =\n      new Builder(Name.SECONDARY_MASTER_METASTORE_DIR)\n          .setDefaultValue(String.format(\"${%s}/secondary-metastore\", Name.WORK_DIR))\n          .setDescription(\n              \"The secondary master metastore work directory. Only some metastores need disk.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECONDARY_MASTER_METASTORE_DIR =\n      new Builder(Name.SECONDARY_MASTER_METASTORE_DIR)\n          .setDefaultValue(String.format(\"${%s}/secondary-metastore\", Name.WORK_DIR))\n          .setDescription(\n              \"The secondary master metastore work directory. Only some metastores need disk.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "SECONDARY_MASTER_METASTORE_DIR"}, {"original_string": "public static final PropertyKey MASTER_FILE_SYSTEM_LISTSTATUS_RESULTS_PER_MESSAGE =\n      new Builder(Name.MASTER_FILE_SYSTEM_LISTSTATUS_RESULTS_PER_MESSAGE)\n          .setDefaultValue(10000)\n          .setDescription(\n              \"Count of items on each list-status response message.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_FILE_SYSTEM_LISTSTATUS_RESULTS_PER_MESSAGE =\n      new Builder(Name.MASTER_FILE_SYSTEM_LISTSTATUS_RESULTS_PER_MESSAGE)\n          .setDefaultValue(10000)\n          .setDescription(\n              \"Count of items on each list-status response message.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_FILE_SYSTEM_LISTSTATUS_RESULTS_PER_MESSAGE"}, {"original_string": "public static final PropertyKey WORKER_ALLOCATOR_CLASS =\n      new Builder(Name.WORKER_ALLOCATOR_CLASS)\n          .setDefaultValue(\"alluxio.worker.block.allocator.MaxFreeAllocator\")\n          .setDescription(\"The strategy that a worker uses to allocate space among storage \"\n              + \"directories in certain storage layer. Valid options include: \"\n              + \"`alluxio.worker.block.allocator.MaxFreeAllocator`, \"\n              + \"`alluxio.worker.block.allocator.GreedyAllocator`, \"\n              + \"`alluxio.worker.block.allocator.RoundRobinAllocator`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_ALLOCATOR_CLASS =\n      new Builder(Name.WORKER_ALLOCATOR_CLASS)\n          .setDefaultValue(\"alluxio.worker.block.allocator.MaxFreeAllocator\")\n          .setDescription(\"The strategy that a worker uses to allocate space among storage \"\n              + \"directories in certain storage layer. Valid options include: \"\n              + \"`alluxio.worker.block.allocator.MaxFreeAllocator`, \"\n              + \"`alluxio.worker.block.allocator.GreedyAllocator`, \"\n              + \"`alluxio.worker.block.allocator.RoundRobinAllocator`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_ALLOCATOR_CLASS"}, {"original_string": "public static final PropertyKey WORKER_BIND_HOST =\n      new Builder(Name.WORKER_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname Alluxio's worker node binds to.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BIND_HOST =\n      new Builder(Name.WORKER_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname Alluxio's worker node binds to.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BIND_HOST"}, {"original_string": "public static final PropertyKey WORKER_BLOCK_HEARTBEAT_INTERVAL_MS =\n      new Builder(Name.WORKER_BLOCK_HEARTBEAT_INTERVAL_MS)\n          .setAlias(\"alluxio.worker.block.heartbeat.interval.ms\")\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The interval between block workers' heartbeats to update \"\n              + \"block status, storage health and other workers' information to Alluxio Master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BLOCK_HEARTBEAT_INTERVAL_MS =\n      new Builder(Name.WORKER_BLOCK_HEARTBEAT_INTERVAL_MS)\n          .setAlias(\"alluxio.worker.block.heartbeat.interval.ms\")\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The interval between block workers' heartbeats to update \"\n              + \"block status, storage health and other workers' information to Alluxio Master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BLOCK_HEARTBEAT_INTERVAL_MS"}, {"original_string": "public static final PropertyKey WORKER_BLOCK_HEARTBEAT_TIMEOUT_MS =\n      new Builder(Name.WORKER_BLOCK_HEARTBEAT_TIMEOUT_MS)\n          .setAlias(\"alluxio.worker.block.heartbeat.timeout.ms\")\n          .setDefaultValue(String.format(\"${%s}\", Name.WORKER_MASTER_CONNECT_RETRY_TIMEOUT))\n          .setDescription(\"The timeout value of block workers' heartbeats. If the worker can't \"\n              + \"connect to master before this interval expires, the worker will exit.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BLOCK_HEARTBEAT_TIMEOUT_MS =\n      new Builder(Name.WORKER_BLOCK_HEARTBEAT_TIMEOUT_MS)\n          .setAlias(\"alluxio.worker.block.heartbeat.timeout.ms\")\n          .setDefaultValue(String.format(\"${%s}\", Name.WORKER_MASTER_CONNECT_RETRY_TIMEOUT))\n          .setDescription(\"The timeout value of block workers' heartbeats. If the worker can't \"\n              + \"connect to master before this interval expires, the worker will exit.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BLOCK_HEARTBEAT_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey WORKER_CONTAINER_HOSTNAME =\n      new Builder(Name.WORKER_CONTAINER_HOSTNAME)\n          .setDescription(\"The container hostname if worker is running in a container.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_CONTAINER_HOSTNAME =\n      new Builder(Name.WORKER_CONTAINER_HOSTNAME)\n          .setDescription(\"The container hostname if worker is running in a container.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_CONTAINER_HOSTNAME"}, {"original_string": "public static final PropertyKey WORKER_DATA_FOLDER =\n      new Builder(Name.WORKER_DATA_FOLDER)\n          .setDefaultValue(\"/alluxioworker/\")\n          .setDescription(\"A relative path within each storage directory used as the data \"\n              + \"folder for Alluxio worker to put data for tiered store.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_FOLDER =\n      new Builder(Name.WORKER_DATA_FOLDER)\n          .setDefaultValue(\"/alluxioworker/\")\n          .setDescription(\"A relative path within each storage directory used as the data \"\n              + \"folder for Alluxio worker to put data for tiered store.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_DATA_FOLDER"}, {"original_string": "public static final PropertyKey WORKER_DATA_FOLDER_PERMISSIONS =\n      new Builder(Name.WORKER_DATA_FOLDER_PERMISSIONS)\n          .setDefaultValue(\"rwxrwxrwx\")\n          .setDescription(\"The permission set for the worker data folder. If short circuit is used \"\n              + \"this folder should be accessible by all users (rwxrwxrwx).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_FOLDER_PERMISSIONS =\n      new Builder(Name.WORKER_DATA_FOLDER_PERMISSIONS)\n          .setDefaultValue(\"rwxrwxrwx\")\n          .setDescription(\"The permission set for the worker data folder. If short circuit is used \"\n              + \"this folder should be accessible by all users (rwxrwxrwx).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_DATA_FOLDER_PERMISSIONS"}, {"original_string": "public static final PropertyKey WORKER_DATA_SERVER_CLASS =\n      new Builder(Name.WORKER_DATA_SERVER_CLASS)\n          .setDefaultValue(\"alluxio.worker.grpc.GrpcDataServer\")\n          .setDescription(\"Selects the networking stack to run the worker with. Valid options \"\n              + \"are: `alluxio.worker.grpc.GrpcDataServer`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_SERVER_CLASS =\n      new Builder(Name.WORKER_DATA_SERVER_CLASS)\n          .setDefaultValue(\"alluxio.worker.grpc.GrpcDataServer\")\n          .setDescription(\"Selects the networking stack to run the worker with. Valid options \"\n              + \"are: `alluxio.worker.grpc.GrpcDataServer`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_DATA_SERVER_CLASS"}, {"original_string": "public static final PropertyKey WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS =\n      new Builder(Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS)\n          .setDescription(\"The path to the domain socket. Short-circuit reads make use of a \"\n              + \"UNIX domain socket when this is set (non-empty). This is a special path in \"\n              + \"the file system that allows the client and the AlluxioWorker to communicate. \"\n              + \"You will need to set a path to this socket. The AlluxioWorker needs to be \"\n              + \"able to create the path. If \" + Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID\n              + \" is set, the path should be the home directory for the domain socket. The full \"\n              + \"path for the domain socket with be {path}/{uuid}.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS =\n      new Builder(Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS)\n          .setDescription(\"The path to the domain socket. Short-circuit reads make use of a \"\n              + \"UNIX domain socket when this is set (non-empty). This is a special path in \"\n              + \"the file system that allows the client and the AlluxioWorker to communicate. \"\n              + \"You will need to set a path to this socket. The AlluxioWorker needs to be \"\n              + \"able to create the path. If \" + Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID\n              + \" is set, the path should be the home directory for the domain socket. The full \"\n              + \"path for the domain socket with be {path}/{uuid}.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS"}, {"original_string": "public static final PropertyKey WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID =\n      new Builder(Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID)\n          .setDefaultValue(\"false\")\n          .setDescription(\"If true, the property \" + Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS\n              + \"is the path to the home directory for the domain socket and a unique identifier \"\n              + \"is used as the domain socket name. If false, the property is the absolute path \"\n              + \"to the UNIX domain socket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID =\n      new Builder(Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID)\n          .setDefaultValue(\"false\")\n          .setDescription(\"If true, the property \" + Name.WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS\n              + \"is the path to the home directory for the domain socket and a unique identifier \"\n              + \"is used as the domain socket name. If false, the property is the absolute path \"\n              + \"to the UNIX domain socket.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "WORKER_DATA_SERVER_DOMAIN_SOCKET_AS_UUID"}, {"original_string": "public static final PropertyKey WORKER_DATA_TMP_FOLDER =\n      new Builder(Name.WORKER_DATA_TMP_FOLDER)\n          .setDefaultValue(\".tmp_blocks\")\n          .setDescription(\"A relative path in alluxio.worker.data.folder used to store the \"\n              + \"temporary data for uncommitted files.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_TMP_FOLDER =\n      new Builder(Name.WORKER_DATA_TMP_FOLDER)\n          .setDefaultValue(\".tmp_blocks\")\n          .setDescription(\"A relative path in alluxio.worker.data.folder used to store the \"\n              + \"temporary data for uncommitted files.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_DATA_TMP_FOLDER"}, {"original_string": "public static final PropertyKey WORKER_DATA_TMP_SUBDIR_MAX =\n      new Builder(Name.WORKER_DATA_TMP_SUBDIR_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of sub-directories allowed to be created in \"\n              + \"${alluxio.worker.data.tmp.folder}.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_DATA_TMP_SUBDIR_MAX =\n      new Builder(Name.WORKER_DATA_TMP_SUBDIR_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of sub-directories allowed to be created in \"\n              + \"${alluxio.worker.data.tmp.folder}.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_DATA_TMP_SUBDIR_MAX"}, {"original_string": "@Deprecated(message = \"Use WORKER_BLOCK_ANNOTATOR_CLASS instead.\")\n  public static final PropertyKey WORKER_EVICTOR_CLASS =\n      new Builder(Name.WORKER_EVICTOR_CLASS)\n          .setDescription(\"The strategy that a worker uses to evict block files when a \"\n              + \"storage layer runs out of space. Valid options include \"\n              + \"`alluxio.worker.block.evictor.LRFUEvictor`, \"\n              + \"`alluxio.worker.block.evictor.GreedyEvictor`, \"\n              + \"`alluxio.worker.block.evictor.LRUEvictor`, \"\n              + \"`alluxio.worker.block.evictor.PartialLRUEvictor`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "@Deprecated(message = \"Use WORKER_BLOCK_ANNOTATOR_CLASS instead.\")\n  public static final", "type": "PropertyKey", "declarator": "WORKER_EVICTOR_CLASS =\n      new Builder(Name.WORKER_EVICTOR_CLASS)\n          .setDescription(\"The strategy that a worker uses to evict block files when a \"\n              + \"storage layer runs out of space. Valid options include \"\n              + \"`alluxio.worker.block.evictor.LRFUEvictor`, \"\n              + \"`alluxio.worker.block.evictor.GreedyEvictor`, \"\n              + \"`alluxio.worker.block.evictor.LRUEvictor`, \"\n              + \"`alluxio.worker.block.evictor.PartialLRUEvictor`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_EVICTOR_CLASS"}, {"original_string": "public static final PropertyKey WORKER_BLOCK_ANNOTATOR_CLASS =\n      new Builder(Name.WORKER_BLOCK_ANNOTATOR_CLASS)\n          .setDefaultValue(\"alluxio.worker.block.annotator.LRUAnnotator\")\n          .setDescription(\"The strategy that a worker uses to annotate blocks \"\n              + \"in order to have an ordered view of them during internal\"\n              + \"management tasks such as eviction and promotion/demotion. \"\n              + \" Valid options include: \"\n              + \"`alluxio.worker.block.annotator.LRFUAnnotator`, \"\n              + \"`alluxio.worker.block.annotator.LRUAnnotator`, \")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BLOCK_ANNOTATOR_CLASS =\n      new Builder(Name.WORKER_BLOCK_ANNOTATOR_CLASS)\n          .setDefaultValue(\"alluxio.worker.block.annotator.LRUAnnotator\")\n          .setDescription(\"The strategy that a worker uses to annotate blocks \"\n              + \"in order to have an ordered view of them during internal\"\n              + \"management tasks such as eviction and promotion/demotion. \"\n              + \" Valid options include: \"\n              + \"`alluxio.worker.block.annotator.LRFUAnnotator`, \"\n              + \"`alluxio.worker.block.annotator.LRUAnnotator`, \")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BLOCK_ANNOTATOR_CLASS"}, {"original_string": "public static final PropertyKey WORKER_BLOCK_ANNOTATOR_LRFU_ATTENUATION_FACTOR =\n      new Builder(Name.WORKER_BLOCK_ANNOTATOR_LRFU_ATTENUATION_FACTOR)\n          .setDefaultValue(2.0)\n          .setDescription(\n              \"A attenuation factor in [2, INF) to control the behavior of LRFU annotator.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BLOCK_ANNOTATOR_LRFU_ATTENUATION_FACTOR =\n      new Builder(Name.WORKER_BLOCK_ANNOTATOR_LRFU_ATTENUATION_FACTOR)\n          .setDefaultValue(2.0)\n          .setDescription(\n              \"A attenuation factor in [2, INF) to control the behavior of LRFU annotator.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BLOCK_ANNOTATOR_LRFU_ATTENUATION_FACTOR"}, {"original_string": "public static final PropertyKey WORKER_BLOCK_ANNOTATOR_LRFU_STEP_FACTOR =\n      new Builder(Name.WORKER_BLOCK_ANNOTATOR_LRFU_STEP_FACTOR)\n          .setDefaultValue(0.25)\n          .setDescription(\"A factor in [0, 1] to control the behavior of LRFU: smaller value \"\n              + \"makes LRFU more similar to LFU; and larger value makes LRFU closer to LRU.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BLOCK_ANNOTATOR_LRFU_STEP_FACTOR =\n      new Builder(Name.WORKER_BLOCK_ANNOTATOR_LRFU_STEP_FACTOR)\n          .setDefaultValue(0.25)\n          .setDescription(\"A factor in [0, 1] to control the behavior of LRFU: smaller value \"\n              + \"makes LRFU more similar to LFU; and larger value makes LRFU closer to LRU.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BLOCK_ANNOTATOR_LRFU_STEP_FACTOR"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_BACKOFF_STRATEGY =\n      new Builder(Name.WORKER_MANAGEMENT_BACKOFF_STRATEGY)\n          .setDefaultValue(\"ANY\")\n          .setDescription(\"Defines the backoff scope respected by background tasks. \"\n              + \"Supported values are ANY / DIRECTORY. \"\n              + \"ANY: Management tasks will backoff from worker when there is any user I/O.\"\n              + \"This mode will ensure low management task overhead in order to favor \"\n              + \"immediate user I/O performance. However, making progress on management tasks \"\n              + \"will require quite periods on the worker.\"\n              + \"DIRECTORY: Management tasks will backoff from directories with ongoing user I/O.\"\n              + \"This mode will give better chance of making progress on management tasks.\"\n              + \"However, immediate user I/O throughput might be reduced due to \"\n              + \"increased management task activity.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_BACKOFF_STRATEGY =\n      new Builder(Name.WORKER_MANAGEMENT_BACKOFF_STRATEGY)\n          .setDefaultValue(\"ANY\")\n          .setDescription(\"Defines the backoff scope respected by background tasks. \"\n              + \"Supported values are ANY / DIRECTORY. \"\n              + \"ANY: Management tasks will backoff from worker when there is any user I/O.\"\n              + \"This mode will ensure low management task overhead in order to favor \"\n              + \"immediate user I/O performance. However, making progress on management tasks \"\n              + \"will require quite periods on the worker.\"\n              + \"DIRECTORY: Management tasks will backoff from directories with ongoing user I/O.\"\n              + \"This mode will give better chance of making progress on management tasks.\"\n              + \"However, immediate user I/O throughput might be reduced due to \"\n              + \"increased management task activity.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_BACKOFF_STRATEGY"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_LOAD_DETECTION_COOL_DOWN_TIME =\n      new Builder(Name.WORKER_MANAGEMENT_LOAD_DETECTION_COOL_DOWN_TIME)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"Management tasks will not run for this long after load detected. \"\n              + \"Any user I/O will still register as a load for this period of time after \"\n              + \"it is finished. Short durations might cause interference between user I/O \"\n              + \"and background tier management tasks. Long durations might cause \"\n              + \"starvation for background tasks.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_LOAD_DETECTION_COOL_DOWN_TIME =\n      new Builder(Name.WORKER_MANAGEMENT_LOAD_DETECTION_COOL_DOWN_TIME)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"Management tasks will not run for this long after load detected. \"\n              + \"Any user I/O will still register as a load for this period of time after \"\n              + \"it is finished. Short durations might cause interference between user I/O \"\n              + \"and background tier management tasks. Long durations might cause \"\n              + \"starvation for background tasks.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_LOAD_DETECTION_COOL_DOWN_TIME"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_ALIGN_RESERVED_BYTES =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_ALIGN_RESERVED_BYTES)\n          .setDefaultValue(\"1GB\")\n          .setDescription(\"The amount of space that is reserved from each storage directory \"\n              + \"for internal management tasks.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_ALIGN_RESERVED_BYTES =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_ALIGN_RESERVED_BYTES)\n          .setDefaultValue(\"1GB\")\n          .setDescription(\"The amount of space that is reserved from each storage directory \"\n              + \"for internal management tasks.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_ALIGN_RESERVED_BYTES"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TASK_THREAD_COUNT =\n      new Builder(Name.WORKER_MANAGEMENT_TASK_THREAD_COUNT)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"Use {CPU core count} threads for all management tasks\")\n          .setDescription(\"The number of threads for management task executor\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TASK_THREAD_COUNT =\n      new Builder(Name.WORKER_MANAGEMENT_TASK_THREAD_COUNT)\n          .setDefaultSupplier(() -> Runtime.getRuntime().availableProcessors(),\n              \"Use {CPU core count} threads for all management tasks\")\n          .setDescription(\"The number of threads for management task executor\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TASK_THREAD_COUNT"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_BLOCK_TRANSFER_CONCURRENCY_LIMIT =\n      new Builder(Name.WORKER_MANAGEMENT_BLOCK_TRANSFER_CONCURRENCY_LIMIT)\n          .setDefaultSupplier(() -> Math.max(1, Runtime.getRuntime().availableProcessors() / 2),\n              \"Use {CPU core count}/2 threads block transfer\")\n          .setDescription(\"Puts a limit to how many block transfers are \"\n              + \"executed concurrently during management.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_BLOCK_TRANSFER_CONCURRENCY_LIMIT =\n      new Builder(Name.WORKER_MANAGEMENT_BLOCK_TRANSFER_CONCURRENCY_LIMIT)\n          .setDefaultSupplier(() -> Math.max(1, Runtime.getRuntime().availableProcessors() / 2),\n              \"Use {CPU core count}/2 threads block transfer\")\n          .setDescription(\"Puts a limit to how many block transfers are \"\n              + \"executed concurrently during management.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_BLOCK_TRANSFER_CONCURRENCY_LIMIT"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_ALIGN_ENABLED =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_ALIGN_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to align tiers based on access pattern.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_ALIGN_ENABLED =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_ALIGN_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to align tiers based on access pattern.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_ALIGN_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_PROMOTE_ENABLED =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_PROMOTE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to promote blocks to higher tiers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_PROMOTE_ENABLED =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_PROMOTE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to promote blocks to higher tiers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_PROMOTE_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_SWAP_RESTORE_ENABLED =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_SWAP_RESTORE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to run management swap-restore task when \"\n              + \"tier alignment cannot make progress.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_SWAP_RESTORE_ENABLED =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_SWAP_RESTORE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to run management swap-restore task when \"\n              + \"tier alignment cannot make progress.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_SWAP_RESTORE_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_ALIGN_RANGE =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_ALIGN_RANGE)\n          .setDefaultValue(100)\n          .setDescription(\n              \"Maximum number of blocks to consider from one tier for a single alignment task.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_ALIGN_RANGE =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_ALIGN_RANGE)\n          .setDefaultValue(100)\n          .setDescription(\n              \"Maximum number of blocks to consider from one tier for a single alignment task.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_ALIGN_RANGE"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_PROMOTE_RANGE =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_PROMOTE_RANGE)\n          .setDefaultValue(100)\n          .setDescription(\n              \"Maximum number of blocks to consider from one tier for a single promote task.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_PROMOTE_RANGE =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_PROMOTE_RANGE)\n          .setDefaultValue(100)\n          .setDescription(\n              \"Maximum number of blocks to consider from one tier for a single promote task.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_PROMOTE_RANGE"}, {"original_string": "public static final PropertyKey WORKER_MANAGEMENT_TIER_PROMOTE_QUOTA_PERCENT =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_PROMOTE_QUOTA_PERCENT)\n          .setDefaultValue(90)\n          .setDescription(\"Max percentage of each tier that could be used for promotions. \"\n              + \"Promotions will be stopped to a tier once its used space go over this value. \"\n              + \"(0 means never promote, and, 100 means always promote.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MANAGEMENT_TIER_PROMOTE_QUOTA_PERCENT =\n      new Builder(Name.WORKER_MANAGEMENT_TIER_PROMOTE_QUOTA_PERCENT)\n          .setDefaultValue(90)\n          .setDescription(\"Max percentage of each tier that could be used for promotions. \"\n              + \"Promotions will be stopped to a tier once its used space go over this value. \"\n              + \"(0 means never promote, and, 100 means always promote.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MANAGEMENT_TIER_PROMOTE_QUOTA_PERCENT"}, {"original_string": "public static final PropertyKey WORKER_FILE_BUFFER_SIZE =\n      new Builder(Name.WORKER_FILE_BUFFER_SIZE)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"The buffer size for worker to write data into the tiered storage.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_FILE_BUFFER_SIZE =\n      new Builder(Name.WORKER_FILE_BUFFER_SIZE)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"The buffer size for worker to write data into the tiered storage.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_FILE_BUFFER_SIZE"}, {"original_string": "public static final PropertyKey WORKER_FREE_SPACE_TIMEOUT =\n      new Builder(Name.WORKER_FREE_SPACE_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The duration for which a worker will wait for eviction to make space \"\n              + \"available for a client write request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_FREE_SPACE_TIMEOUT =\n      new Builder(Name.WORKER_FREE_SPACE_TIMEOUT)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The duration for which a worker will wait for eviction to make space \"\n              + \"available for a client write request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_FREE_SPACE_TIMEOUT"}, {"original_string": "public static final PropertyKey WORKER_HOSTNAME = new Builder(Name.WORKER_HOSTNAME)\n      .setDescription(\"The hostname of Alluxio worker.\")\n      .setScope(Scope.WORKER)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_HOSTNAME = new Builder(Name.WORKER_HOSTNAME)\n      .setDescription(\"The hostname of Alluxio worker.\")\n      .setScope(Scope.WORKER)\n      .build()", "var_name": "WORKER_HOSTNAME"}, {"original_string": "public static final PropertyKey WORKER_KEYTAB_FILE = new Builder(Name.WORKER_KEYTAB_FILE)\n      .setDescription(\"Kerberos keytab file for Alluxio worker.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.WORKER)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_KEYTAB_FILE = new Builder(Name.WORKER_KEYTAB_FILE)\n      .setDescription(\"Kerberos keytab file for Alluxio worker.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.WORKER)\n      .build()", "var_name": "WORKER_KEYTAB_FILE"}, {"original_string": "public static final PropertyKey WORKER_MASTER_CONNECT_RETRY_TIMEOUT =\n      new Builder(Name.WORKER_MASTER_CONNECT_RETRY_TIMEOUT)\n          .setDescription(\"Retry period before workers give up on connecting to master and exit.\")\n          .setDefaultValue(\"1hour\")\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MASTER_CONNECT_RETRY_TIMEOUT =\n      new Builder(Name.WORKER_MASTER_CONNECT_RETRY_TIMEOUT)\n          .setDescription(\"Retry period before workers give up on connecting to master and exit.\")\n          .setDefaultValue(\"1hour\")\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MASTER_CONNECT_RETRY_TIMEOUT"}, {"original_string": "public static final PropertyKey WORKER_MASTER_PERIODICAL_RPC_TIMEOUT =\n      new Builder(Name.WORKER_MASTER_PERIODICAL_RPC_TIMEOUT)\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Timeout for periodical RPC between workers \"\n              + \"and the leading master. This property is added to prevent workers \"\n              + \"from hanging in periodical RPCs with previous leading master \"\n              + \"during flaky network situations. If the timeout is too short, \"\n              + \"periodical RPCs may not have enough time to get response \"\n              + \"from the leading master during heavy cluster load \"\n              + \"and high network latency.\")\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_MASTER_PERIODICAL_RPC_TIMEOUT =\n      new Builder(Name.WORKER_MASTER_PERIODICAL_RPC_TIMEOUT)\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Timeout for periodical RPC between workers \"\n              + \"and the leading master. This property is added to prevent workers \"\n              + \"from hanging in periodical RPCs with previous leading master \"\n              + \"during flaky network situations. If the timeout is too short, \"\n              + \"periodical RPCs may not have enough time to get response \"\n              + \"from the leading master during heavy cluster load \"\n              + \"and high network latency.\")\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_MASTER_PERIODICAL_RPC_TIMEOUT"}, {"original_string": "public static final PropertyKey WORKER_RAMDISK_SIZE =\n      new Builder(Name.WORKER_RAMDISK_SIZE)\n          .setAlias(Name.WORKER_MEMORY_SIZE)\n          .setDefaultSupplier(() -> {\n            try {\n              OperatingSystemMXBean operatingSystemMXBean =\n                  (OperatingSystemMXBean) ManagementFactory.getOperatingSystemMXBean();\n              return operatingSystemMXBean.getTotalPhysicalMemorySize() * 2 / 3;\n            } catch (Exception e) {\n              // The package com.sun.management may not be available on every platform.\n              // fallback to a reasonable size.\n              return \"1GB\";\n            }\n          }, \"2/3 of total system memory, or 1GB if system memory size cannot be determined\")\n          .setDescription(\"Memory capacity of each worker node.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_RAMDISK_SIZE =\n      new Builder(Name.WORKER_RAMDISK_SIZE)\n          .setAlias(Name.WORKER_MEMORY_SIZE)\n          .setDefaultSupplier(() -> {\n            try {\n              OperatingSystemMXBean operatingSystemMXBean =\n                  (OperatingSystemMXBean) ManagementFactory.getOperatingSystemMXBean();\n              return operatingSystemMXBean.getTotalPhysicalMemorySize() * 2 / 3;\n            } catch (Exception e) {\n              // The package com.sun.management may not be available on every platform.\n              // fallback to a reasonable size.\n              return \"1GB\";\n            }\n          }, \"2/3 of total system memory, or 1GB if system memory size cannot be determined\")\n          .setDescription(\"Memory capacity of each worker node.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_RAMDISK_SIZE"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_ASYNC_CACHE_MANAGER_THREADS_MAX =\n      new Builder(Name.WORKER_NETWORK_ASYNC_CACHE_MANAGER_THREADS_MAX)\n          .setDefaultValue(8)\n          .setDescription(\"The maximum number of threads used to cache blocks asynchronously in \"\n              + \"the data server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_ASYNC_CACHE_MANAGER_THREADS_MAX =\n      new Builder(Name.WORKER_NETWORK_ASYNC_CACHE_MANAGER_THREADS_MAX)\n          .setDefaultValue(8)\n          .setDescription(\"The maximum number of threads used to cache blocks asynchronously in \"\n              + \"the data server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_ASYNC_CACHE_MANAGER_THREADS_MAX"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_BLOCK_READER_THREADS_MAX =\n      new Builder(Name.WORKER_NETWORK_BLOCK_READER_THREADS_MAX)\n          .setDefaultValue(2048)\n          .setDescription(\"The maximum number of threads used to read blocks in the data server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_BLOCK_READER_THREADS_MAX =\n      new Builder(Name.WORKER_NETWORK_BLOCK_READER_THREADS_MAX)\n          .setDefaultValue(2048)\n          .setDescription(\"The maximum number of threads used to read blocks in the data server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_BLOCK_READER_THREADS_MAX"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_BLOCK_WRITER_THREADS_MAX =\n      new Builder(Name.WORKER_NETWORK_BLOCK_WRITER_THREADS_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of threads used to write blocks in the data server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_BLOCK_WRITER_THREADS_MAX =\n      new Builder(Name.WORKER_NETWORK_BLOCK_WRITER_THREADS_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of threads used to write blocks in the data server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_BLOCK_WRITER_THREADS_MAX"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.WORKER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES)\n          .setDefaultValue(8)\n          .setDescription(\"When a client writes to a remote worker, the maximum number of \"\n              + \"data messages to buffer by the server for each request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.WORKER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES)\n          .setDefaultValue(8)\n          .setDescription(\"When a client writes to a remote worker, the maximum number of \"\n              + \"data messages to buffer by the server for each request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_FLOWCONTROL_WINDOW =\n      new Builder(Name.WORKER_NETWORK_FLOWCONTROL_WINDOW)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"The HTTP2 flow control window used by worker gRPC connections. Larger \"\n              + \"value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_FLOWCONTROL_WINDOW =\n      new Builder(Name.WORKER_NETWORK_FLOWCONTROL_WINDOW)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"The HTTP2 flow control window used by worker gRPC connections. Larger \"\n              + \"value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_FLOWCONTROL_WINDOW"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_KEEPALIVE_TIME_MS =\n      new Builder(Name.WORKER_NETWORK_KEEPALIVE_TIME_MS)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The amount of time for data server (for block reads and block writes) \"\n              + \"to wait for a response before pinging the client to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_KEEPALIVE_TIME_MS =\n      new Builder(Name.WORKER_NETWORK_KEEPALIVE_TIME_MS)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The amount of time for data server (for block reads and block writes) \"\n              + \"to wait for a response before pinging the client to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_KEEPALIVE_TIME_MS"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_KEEPALIVE_TIMEOUT_MS =\n      new Builder(Name.WORKER_NETWORK_KEEPALIVE_TIMEOUT_MS)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a data server (for block reads and block writes) \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_KEEPALIVE_TIMEOUT_MS =\n      new Builder(Name.WORKER_NETWORK_KEEPALIVE_TIMEOUT_MS)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a data server (for block reads and block writes) \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_KEEPALIVE_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.WORKER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"4MB\")\n          .setDescription(\"The max inbound message size used by worker gRPC connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.WORKER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"4MB\")\n          .setDescription(\"The max inbound message size used by worker gRPC connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_MAX_INBOUND_MESSAGE_SIZE"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_NETTY_BOSS_THREADS =\n      new Builder(Name.WORKER_NETWORK_NETTY_BOSS_THREADS)\n          .setDefaultValue(1)\n          .setDescription(\"How many threads to use for accepting new requests.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_NETTY_BOSS_THREADS =\n      new Builder(Name.WORKER_NETWORK_NETTY_BOSS_THREADS)\n          .setDefaultValue(1)\n          .setDescription(\"How many threads to use for accepting new requests.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_NETTY_BOSS_THREADS"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_NETTY_CHANNEL =\n      new Builder(Name.WORKER_NETWORK_NETTY_CHANNEL)\n          .setDescription(\"Netty channel type: NIO or EPOLL. If EPOLL is not available, this will \"\n              + \"automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .setDefaultValue(\"EPOLL\")\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_NETTY_CHANNEL =\n      new Builder(Name.WORKER_NETWORK_NETTY_CHANNEL)\n          .setDescription(\"Netty channel type: NIO or EPOLL. If EPOLL is not available, this will \"\n              + \"automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .setDefaultValue(\"EPOLL\")\n          .build()", "var_name": "WORKER_NETWORK_NETTY_CHANNEL"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_NETTY_SHUTDOWN_QUIET_PERIOD =\n      new Builder(Name.WORKER_NETWORK_NETTY_SHUTDOWN_QUIET_PERIOD)\n          .setDefaultValue(\"2sec\")\n          .setDescription(\"The quiet period. When the netty server is shutting \"\n              + \"down, it will ensure that no RPCs occur during the quiet period. If an RPC \"\n              + \"occurs, then the quiet period will restart before shutting down the netty \"\n              + \"server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_NETTY_SHUTDOWN_QUIET_PERIOD =\n      new Builder(Name.WORKER_NETWORK_NETTY_SHUTDOWN_QUIET_PERIOD)\n          .setDefaultValue(\"2sec\")\n          .setDescription(\"The quiet period. When the netty server is shutting \"\n              + \"down, it will ensure that no RPCs occur during the quiet period. If an RPC \"\n              + \"occurs, then the quiet period will restart before shutting down the netty \"\n              + \"server.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_NETTY_SHUTDOWN_QUIET_PERIOD"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_NETTY_WATERMARK_HIGH =\n      new Builder(Name.WORKER_NETWORK_NETTY_WATERMARK_HIGH)\n          .setDefaultValue(\"32KB\")\n          .setDescription(\"Determines how many bytes can be in the write queue before \"\n              + \"switching to non-writable.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_NETTY_WATERMARK_HIGH =\n      new Builder(Name.WORKER_NETWORK_NETTY_WATERMARK_HIGH)\n          .setDefaultValue(\"32KB\")\n          .setDescription(\"Determines how many bytes can be in the write queue before \"\n              + \"switching to non-writable.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_NETTY_WATERMARK_HIGH"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_NETTY_WATERMARK_LOW =\n      new Builder(Name.WORKER_NETWORK_NETTY_WATERMARK_LOW)\n          .setDefaultValue(\"8KB\")\n          .setDescription(\"Once the high watermark limit is reached, the queue must be \"\n              + \"flushed down to the low watermark before switching back to writable.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_NETTY_WATERMARK_LOW =\n      new Builder(Name.WORKER_NETWORK_NETTY_WATERMARK_LOW)\n          .setDefaultValue(\"8KB\")\n          .setDescription(\"Once the high watermark limit is reached, the queue must be \"\n              + \"flushed down to the low watermark before switching back to writable.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_NETTY_WATERMARK_LOW"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_NETTY_WORKER_THREADS =\n      new Builder(Name.WORKER_NETWORK_NETTY_WORKER_THREADS)\n          .setDefaultValue(0)\n          .setDescription(\"How many threads to use for processing requests. Zero defaults to \"\n              + \"#cpuCores * 2.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_NETTY_WORKER_THREADS =\n      new Builder(Name.WORKER_NETWORK_NETTY_WORKER_THREADS)\n          .setDefaultValue(0)\n          .setDescription(\"How many threads to use for processing requests. Zero defaults to \"\n              + \"#cpuCores * 2.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_NETTY_WORKER_THREADS"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_READER_BUFFER_SIZE_BYTES =\n      new Builder(Name.WORKER_NETWORK_READER_BUFFER_SIZE_BYTES)\n          .setDefaultValue(\"4MB\")\n          .setDescription(\"When a client reads from a remote worker, the maximum amount of data\"\n              + \" not received by client allowed before the worker pauses sending more data.\"\n              + \" If this value is lower than read chunk size, read performance may be impacted\"\n              + \" as worker waits more often for buffer to free up. Higher value will increase\"\n              + \" the memory consumed by each read request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_READER_BUFFER_SIZE_BYTES =\n      new Builder(Name.WORKER_NETWORK_READER_BUFFER_SIZE_BYTES)\n          .setDefaultValue(\"4MB\")\n          .setDescription(\"When a client reads from a remote worker, the maximum amount of data\"\n              + \" not received by client allowed before the worker pauses sending more data.\"\n              + \" If this value is lower than read chunk size, read performance may be impacted\"\n              + \" as worker waits more often for buffer to free up. Higher value will increase\"\n              + \" the memory consumed by each read request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_READER_BUFFER_SIZE_BYTES"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_READER_MAX_CHUNK_SIZE_BYTES =\n      new Builder(Name.WORKER_NETWORK_READER_MAX_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"When a client read from a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_READER_MAX_CHUNK_SIZE_BYTES =\n      new Builder(Name.WORKER_NETWORK_READER_MAX_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"When a client read from a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_READER_MAX_CHUNK_SIZE_BYTES"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_SHUTDOWN_TIMEOUT =\n      new Builder(Name.WORKER_NETWORK_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"15sec\")\n          .setDescription(\"Maximum amount of time to wait until the worker gRPC server \"\n              + \"is shutdown (regardless of the quiet period).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_SHUTDOWN_TIMEOUT =\n      new Builder(Name.WORKER_NETWORK_SHUTDOWN_TIMEOUT)\n          .setDefaultValue(\"15sec\")\n          .setDescription(\"Maximum amount of time to wait until the worker gRPC server \"\n              + \"is shutdown (regardless of the quiet period).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_SHUTDOWN_TIMEOUT"}, {"original_string": "public static final PropertyKey WORKER_NETWORK_ZEROCOPY_ENABLED =\n      new Builder(Name.WORKER_NETWORK_ZEROCOPY_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether zero copy is enabled on worker when processing data streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_NETWORK_ZEROCOPY_ENABLED =\n      new Builder(Name.WORKER_NETWORK_ZEROCOPY_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether zero copy is enabled on worker when processing data streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_NETWORK_ZEROCOPY_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_BLOCK_MASTER_CLIENT_POOL_SIZE =\n      new Builder(Name.WORKER_BLOCK_MASTER_CLIENT_POOL_SIZE)\n          .setDefaultValue(11)\n          .setDescription(\"The block master client pool size on the Alluxio workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_BLOCK_MASTER_CLIENT_POOL_SIZE =\n      new Builder(Name.WORKER_BLOCK_MASTER_CLIENT_POOL_SIZE)\n          .setDefaultValue(11)\n          .setDescription(\"The block master client pool size on the Alluxio workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_BLOCK_MASTER_CLIENT_POOL_SIZE"}, {"original_string": "public static final PropertyKey WORKER_PRINCIPAL = new Builder(Name.WORKER_PRINCIPAL)\n      .setDescription(\"Kerberos principal for Alluxio worker.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.WORKER)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_PRINCIPAL = new Builder(Name.WORKER_PRINCIPAL)\n      .setDescription(\"Kerberos principal for Alluxio worker.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n      .setScope(Scope.WORKER)\n      .build()", "var_name": "WORKER_PRINCIPAL"}, {"original_string": "public static final PropertyKey WORKER_RPC_PORT =\n      new Builder(Name.WORKER_RPC_PORT)\n          .setAlias(\"alluxio.worker.port\")\n          .setDefaultValue(29999)\n          .setDescription(\"The port for Alluxio worker's RPC service.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_RPC_PORT =\n      new Builder(Name.WORKER_RPC_PORT)\n          .setAlias(\"alluxio.worker.port\")\n          .setDefaultValue(29999)\n          .setDescription(\"The port for Alluxio worker's RPC service.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "WORKER_RPC_PORT"}, {"original_string": "public static final PropertyKey WORKER_SESSION_TIMEOUT_MS =\n      new Builder(Name.WORKER_SESSION_TIMEOUT_MS)\n          .setAlias(\"alluxio.worker.session.timeout.ms\")\n          .setDefaultValue(\"1min\")\n          .setDescription(\"Timeout between worker and client connection \"\n              + \"indicating a lost session connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_SESSION_TIMEOUT_MS =\n      new Builder(Name.WORKER_SESSION_TIMEOUT_MS)\n          .setAlias(\"alluxio.worker.session.timeout.ms\")\n          .setDefaultValue(\"1min\")\n          .setDescription(\"Timeout between worker and client connection \"\n              + \"indicating a lost session connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_SESSION_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey WORKER_STORAGE_CHECKER_ENABLED =\n      new Builder(Name.WORKER_STORAGE_CHECKER_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether periodic storage health checker is enabled on Alluxio workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_STORAGE_CHECKER_ENABLED =\n      new Builder(Name.WORKER_STORAGE_CHECKER_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether periodic storage health checker is enabled on Alluxio workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_STORAGE_CHECKER_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_BLOCK_LOCK_READERS =\n      new Builder(Name.WORKER_TIERED_STORE_BLOCK_LOCK_READERS)\n          .setDefaultValue(1000)\n          .setDescription(\"The max number of concurrent readers for a block lock.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_BLOCK_LOCK_READERS =\n      new Builder(Name.WORKER_TIERED_STORE_BLOCK_LOCK_READERS)\n          .setDefaultValue(1000)\n          .setDescription(\"The max number of concurrent readers for a block lock.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_BLOCK_LOCK_READERS"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_BLOCK_LOCKS =\n      new Builder(Name.WORKER_TIERED_STORE_BLOCK_LOCKS)\n          .setDefaultValue(1000)\n          .setDescription(\"Total number of block locks for an Alluxio block worker. Larger \"\n              + \"value leads to finer locking granularity, but uses more space.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_BLOCK_LOCKS =\n      new Builder(Name.WORKER_TIERED_STORE_BLOCK_LOCKS)\n          .setDefaultValue(1000)\n          .setDescription(\"Total number of block locks for an Alluxio block worker. Larger \"\n              + \"value leads to finer locking granularity, but uses more space.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_BLOCK_LOCKS"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_FREE_AHEAD_BYTES =\n      new Builder(Name.WORKER_TIERED_STORE_FREE_AHEAD_BYTES)\n          .setDefaultValue(0)\n          .setDescription(\"Amount to free ahead when worker storage is full. \"\n              + \"Higher values will help decrease CPU utilization under peak storage. \"\n              + \"Lower values will increase storage utilization.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_FREE_AHEAD_BYTES =\n      new Builder(Name.WORKER_TIERED_STORE_FREE_AHEAD_BYTES)\n          .setDefaultValue(0)\n          .setDescription(\"Amount to free ahead when worker storage is full. \"\n              + \"Higher values will help decrease CPU utilization under peak storage. \"\n              + \"Lower values will increase storage utilization.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_FREE_AHEAD_BYTES"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL0_ALIAS =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_ALIAS, 0)\n          .setDefaultValue(\"MEM\")\n          .setDescription(\"The alias of the top storage tier on this worker. It must \"\n              + \"match one of the global storage tiers from the master configuration. We \"\n              + \"disable placing an alias lower in the global hierarchy before an alias with \"\n              + \"a higher position on the worker hierarchy. So by default, SSD cannot come \"\n              + \"before MEM on any worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL0_ALIAS =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_ALIAS, 0)\n          .setDefaultValue(\"MEM\")\n          .setDescription(\"The alias of the top storage tier on this worker. It must \"\n              + \"match one of the global storage tiers from the master configuration. We \"\n              + \"disable placing an alias lower in the global hierarchy before an alias with \"\n              + \"a higher position on the worker hierarchy. So by default, SSD cannot come \"\n              + \"before MEM on any worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL0_ALIAS"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL0_DIRS_PATH =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_PATH, 0)\n          .setDefaultSupplier(() -> OSUtils.isLinux() ? \"/mnt/ramdisk\" : \"/Volumes/ramdisk\",\n              \"/mnt/ramdisk on Linux, /Volumes/ramdisk on OSX\")\n          .setDescription(\"The path of storage directory for the top storage tier. Note \"\n              + \"for MacOS the value should be `/Volumes/`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL0_DIRS_PATH =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_PATH, 0)\n          .setDefaultSupplier(() -> OSUtils.isLinux() ? \"/mnt/ramdisk\" : \"/Volumes/ramdisk\",\n              \"/mnt/ramdisk on Linux, /Volumes/ramdisk on OSX\")\n          .setDescription(\"The path of storage directory for the top storage tier. Note \"\n              + \"for MacOS the value should be `/Volumes/`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL0_DIRS_PATH"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL0_DIRS_MEDIUMTYPE =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_MEDIUMTYPE, 0)\n          .setDefaultValue(\n              String.format(\"${%s}\", Template.WORKER_TIERED_STORE_LEVEL_ALIAS.format(0)))\n          .setDescription(String.format(\n              \"A list of media types (e.g., \\\"MEM,SSD,SSD\\\") for each storage \"\n                  + \"directory on the top storage tier specified by %s.\",\n              PropertyKey.WORKER_TIERED_STORE_LEVEL0_DIRS_PATH.mName))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL0_DIRS_MEDIUMTYPE =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_MEDIUMTYPE, 0)\n          .setDefaultValue(\n              String.format(\"${%s}\", Template.WORKER_TIERED_STORE_LEVEL_ALIAS.format(0)))\n          .setDescription(String.format(\n              \"A list of media types (e.g., \\\"MEM,SSD,SSD\\\") for each storage \"\n                  + \"directory on the top storage tier specified by %s.\",\n              PropertyKey.WORKER_TIERED_STORE_LEVEL0_DIRS_PATH.mName))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL0_DIRS_MEDIUMTYPE"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL0_DIRS_QUOTA =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_QUOTA, 0)\n          .setDefaultValue(String.format(\"${%s}\", Name.WORKER_RAMDISK_SIZE))\n          .setDescription(\"The capacity of the top storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL0_DIRS_QUOTA =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_QUOTA, 0)\n          .setDefaultValue(String.format(\"${%s}\", Name.WORKER_RAMDISK_SIZE))\n          .setDescription(\"The capacity of the top storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL0_DIRS_QUOTA"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL0_HIGH_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_HIGH_WATERMARK_RATIO, 0)\n          .setDefaultValue(0.95)\n          .setDescription(\"The high watermark of the space in the top storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL0_HIGH_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_HIGH_WATERMARK_RATIO, 0)\n          .setDefaultValue(0.95)\n          .setDescription(\"The high watermark of the space in the top storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL0_HIGH_WATERMARK_RATIO"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL0_LOW_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_LOW_WATERMARK_RATIO, 0)\n          .setDefaultValue(0.7)\n          .setDescription(\"The low watermark of the space in the top storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL0_LOW_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_LOW_WATERMARK_RATIO, 0)\n          .setDefaultValue(0.7)\n          .setDescription(\"The low watermark of the space in the top storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL0_LOW_WATERMARK_RATIO"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL1_ALIAS =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_ALIAS, 1)\n          .setDescription(\"The alias of the second storage tier on this worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL1_ALIAS =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_ALIAS, 1)\n          .setDescription(\"The alias of the second storage tier on this worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL1_ALIAS"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL1_DIRS_PATH =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_PATH, 1)\n          .setDescription(\"The path of storage directory for the second storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL1_DIRS_PATH =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_PATH, 1)\n          .setDescription(\"The path of storage directory for the second storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL1_DIRS_PATH"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL1_DIRS_MEDIUMTYPE =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_MEDIUMTYPE, 1)\n          .setDefaultValue(\n              String.format(\"${%s}\", Template.WORKER_TIERED_STORE_LEVEL_ALIAS.format(1)))\n          .setDescription(String.format(\n              \"A list of media types (e.g., \\\"MEM,SSD,SSD\\\") for each storage \"\n                  + \"directory on the second storage tier specified by %s.\",\n              PropertyKey.WORKER_TIERED_STORE_LEVEL1_DIRS_PATH.mName))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL1_DIRS_MEDIUMTYPE =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_MEDIUMTYPE, 1)\n          .setDefaultValue(\n              String.format(\"${%s}\", Template.WORKER_TIERED_STORE_LEVEL_ALIAS.format(1)))\n          .setDescription(String.format(\n              \"A list of media types (e.g., \\\"MEM,SSD,SSD\\\") for each storage \"\n                  + \"directory on the second storage tier specified by %s.\",\n              PropertyKey.WORKER_TIERED_STORE_LEVEL1_DIRS_PATH.mName))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL1_DIRS_MEDIUMTYPE"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL1_DIRS_QUOTA =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_QUOTA, 1)\n          .setDescription(\"The capacity of the second storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL1_DIRS_QUOTA =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_QUOTA, 1)\n          .setDescription(\"The capacity of the second storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL1_DIRS_QUOTA"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL1_HIGH_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_HIGH_WATERMARK_RATIO, 1)\n          .setDescription(\"The high watermark of the space in the second storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setDefaultValue(0.95)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL1_HIGH_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_HIGH_WATERMARK_RATIO, 1)\n          .setDescription(\"The high watermark of the space in the second storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setDefaultValue(0.95)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL1_HIGH_WATERMARK_RATIO"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL1_LOW_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_LOW_WATERMARK_RATIO, 1)\n          .setDefaultValue(0.7)\n          .setDescription(\"The low watermark of the space in the second storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL1_LOW_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_LOW_WATERMARK_RATIO, 1)\n          .setDefaultValue(0.7)\n          .setDescription(\"The low watermark of the space in the second storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL1_LOW_WATERMARK_RATIO"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL2_ALIAS =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_ALIAS, 2)\n          .setDescription(\"The alias of the third storage tier on this worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL2_ALIAS =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_ALIAS, 2)\n          .setDescription(\"The alias of the third storage tier on this worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL2_ALIAS"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL2_DIRS_PATH =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_PATH, 2)\n          .setDescription(\"The path of storage directory for the third storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL2_DIRS_PATH =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_PATH, 2)\n          .setDescription(\"The path of storage directory for the third storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL2_DIRS_PATH"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL2_DIRS_MEDIUMTYPE =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_MEDIUMTYPE, 2)\n          .setDefaultValue(\n              String.format(\"${%s}\", Template.WORKER_TIERED_STORE_LEVEL_ALIAS.format(2)))\n          .setDescription(String.format(\n              \"A list of media types (e.g., \\\"MEM,SSD,SSD\\\") for each storage \"\n                  + \"directory on the third storage tier specified by %s.\",\n              PropertyKey.WORKER_TIERED_STORE_LEVEL2_DIRS_PATH.mName))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL2_DIRS_MEDIUMTYPE =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_MEDIUMTYPE, 2)\n          .setDefaultValue(\n              String.format(\"${%s}\", Template.WORKER_TIERED_STORE_LEVEL_ALIAS.format(2)))\n          .setDescription(String.format(\n              \"A list of media types (e.g., \\\"MEM,SSD,SSD\\\") for each storage \"\n                  + \"directory on the third storage tier specified by %s.\",\n              PropertyKey.WORKER_TIERED_STORE_LEVEL2_DIRS_PATH.mName))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL2_DIRS_MEDIUMTYPE"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL2_DIRS_QUOTA =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_QUOTA, 2)\n          .setDescription(\"The capacity of the third storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL2_DIRS_QUOTA =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_DIRS_QUOTA, 2)\n          .setDescription(\"The capacity of the third storage tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL2_DIRS_QUOTA"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL2_HIGH_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_HIGH_WATERMARK_RATIO, 2)\n          .setDefaultValue(0.95)\n          .setDescription(\"The high watermark of the space in the third storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL2_HIGH_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_HIGH_WATERMARK_RATIO, 2)\n          .setDefaultValue(0.95)\n          .setDescription(\"The high watermark of the space in the third storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL2_HIGH_WATERMARK_RATIO"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVEL2_LOW_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_LOW_WATERMARK_RATIO, 2)\n          .setDefaultValue(0.7)\n          .setDescription(\"The low watermark of the space in the third storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVEL2_LOW_WATERMARK_RATIO =\n      new Builder(Template.WORKER_TIERED_STORE_LEVEL_LOW_WATERMARK_RATIO, 2)\n          .setDefaultValue(0.7)\n          .setDescription(\"The low watermark of the space in the third storage tier (a value \"\n              + \"between 0 and 1).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVEL2_LOW_WATERMARK_RATIO"}, {"original_string": "public static final PropertyKey WORKER_TIERED_STORE_LEVELS =\n      new Builder(Name.WORKER_TIERED_STORE_LEVELS)\n          .setDefaultValue(1)\n          .setDescription(\"The number of storage tiers on the worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_TIERED_STORE_LEVELS =\n      new Builder(Name.WORKER_TIERED_STORE_LEVELS)\n          .setDefaultValue(1)\n          .setDescription(\"The number of storage tiers on the worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_TIERED_STORE_LEVELS"}, {"original_string": "public static final PropertyKey WORKER_WEB_BIND_HOST =\n      new Builder(Name.WORKER_WEB_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname Alluxio worker's web server binds to.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_WEB_BIND_HOST =\n      new Builder(Name.WORKER_WEB_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname Alluxio worker's web server binds to.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_WEB_BIND_HOST"}, {"original_string": "public static final PropertyKey WORKER_WEB_HOSTNAME =\n      new Builder(Name.WORKER_WEB_HOSTNAME)\n          .setDescription(\"The hostname Alluxio worker's web UI binds to.\")\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_WEB_HOSTNAME =\n      new Builder(Name.WORKER_WEB_HOSTNAME)\n          .setDescription(\"The hostname Alluxio worker's web UI binds to.\")\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_WEB_HOSTNAME"}, {"original_string": "public static final PropertyKey WORKER_WEB_PORT =\n      new Builder(Name.WORKER_WEB_PORT)\n          .setDefaultValue(30000)\n          .setDescription(\"The port Alluxio worker's web UI runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_WEB_PORT =\n      new Builder(Name.WORKER_WEB_PORT)\n          .setDefaultValue(30000)\n          .setDescription(\"The port Alluxio worker's web UI runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_WEB_PORT"}, {"original_string": "public static final PropertyKey WORKER_UFS_BLOCK_OPEN_TIMEOUT_MS =\n      new Builder(Name.WORKER_UFS_BLOCK_OPEN_TIMEOUT_MS)\n          .setAlias(\"alluxio.worker.ufs.block.open.timeout.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Timeout to open a block from UFS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_UFS_BLOCK_OPEN_TIMEOUT_MS =\n      new Builder(Name.WORKER_UFS_BLOCK_OPEN_TIMEOUT_MS)\n          .setAlias(\"alluxio.worker.ufs.block.open.timeout.ms\")\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Timeout to open a block from UFS.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_UFS_BLOCK_OPEN_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey WORKER_UFS_INSTREAM_CACHE_ENABLED =\n      new Builder(Name.WORKER_UFS_INSTREAM_CACHE_ENABLED)\n          .setDefaultValue(\"true\")\n          .setDescription(\"Enable caching for seekable under storage input stream, \"\n              + \"so that subsequent seek operations on the same file will reuse \"\n              + \"the cached input stream. This will improve position read performance \"\n              + \"as the open operations of some under file system would be expensive. \"\n              + \"The cached input stream would be stale, when the UFS file is modified \"\n              + \"without notifying alluxio. \")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_UFS_INSTREAM_CACHE_ENABLED =\n      new Builder(Name.WORKER_UFS_INSTREAM_CACHE_ENABLED)\n          .setDefaultValue(\"true\")\n          .setDescription(\"Enable caching for seekable under storage input stream, \"\n              + \"so that subsequent seek operations on the same file will reuse \"\n              + \"the cached input stream. This will improve position read performance \"\n              + \"as the open operations of some under file system would be expensive. \"\n              + \"The cached input stream would be stale, when the UFS file is modified \"\n              + \"without notifying alluxio. \")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_UFS_INSTREAM_CACHE_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_UFS_INSTREAM_CACHE_EXPIRARTION_TIME =\n      new Builder(Name.WORKER_UFS_INSTREAM_CACHE_EXPIRATION_TIME)\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Cached UFS instream expiration time.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_UFS_INSTREAM_CACHE_EXPIRARTION_TIME =\n      new Builder(Name.WORKER_UFS_INSTREAM_CACHE_EXPIRATION_TIME)\n          .setDefaultValue(\"5min\")\n          .setDescription(\"Cached UFS instream expiration time.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_UFS_INSTREAM_CACHE_EXPIRARTION_TIME"}, {"original_string": "public static final PropertyKey WORKER_UFS_INSTREAM_CACHE_MAX_SIZE =\n      new Builder(Name.WORKER_UFS_INSTREAM_CACHE_MAX_SIZE)\n          .setDefaultValue(\"5000\")\n          .setDescription(\"The max entries in the UFS instream cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_UFS_INSTREAM_CACHE_MAX_SIZE =\n      new Builder(Name.WORKER_UFS_INSTREAM_CACHE_MAX_SIZE)\n          .setDefaultValue(\"5000\")\n          .setDescription(\"The max entries in the UFS instream cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_UFS_INSTREAM_CACHE_MAX_SIZE"}, {"original_string": "public static final PropertyKey PROXY_S3_WRITE_TYPE =\n      new Builder(Name.PROXY_S3_WRITE_TYPE)\n          .setDefaultValue(\"CACHE_THROUGH\")\n          .setDescription(\"Write type when creating buckets and objects through S3 API. \"\n              + \"Valid options are \"\n              + \"`MUST_CACHE` (write will only go to Alluxio and must be stored in Alluxio), \"\n              + \"`CACHE_THROUGH` (try to cache, write to UnderFS synchronously), \"\n              + \"`ASYNC_THROUGH` (try to cache, write to UnderFS asynchronously), \"\n              + \"`THROUGH` (no cache, write to UnderFS synchronously).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_S3_WRITE_TYPE =\n      new Builder(Name.PROXY_S3_WRITE_TYPE)\n          .setDefaultValue(\"CACHE_THROUGH\")\n          .setDescription(\"Write type when creating buckets and objects through S3 API. \"\n              + \"Valid options are \"\n              + \"`MUST_CACHE` (write will only go to Alluxio and must be stored in Alluxio), \"\n              + \"`CACHE_THROUGH` (try to cache, write to UnderFS synchronously), \"\n              + \"`ASYNC_THROUGH` (try to cache, write to UnderFS asynchronously), \"\n              + \"`THROUGH` (no cache, write to UnderFS synchronously).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "PROXY_S3_WRITE_TYPE"}, {"original_string": "public static final PropertyKey PROXY_S3_DELETE_TYPE =\n      new Builder(Name.PROXY_S3_DELETE_TYPE)\n          .setDefaultValue(Constants.S3_DELETE_IN_ALLUXIO_AND_UFS)\n          .setDescription(String.format(\n              \"Delete type when deleting buckets and objects through S3 API. Valid options are \"\n                  + \"`%s` (delete both in Alluxio and UFS), \"\n                  + \"`%s` (delete only the buckets or objects in Alluxio namespace).\",\n              Constants.S3_DELETE_IN_ALLUXIO_AND_UFS, Constants.S3_DELETE_IN_ALLUXIO_ONLY))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_S3_DELETE_TYPE =\n      new Builder(Name.PROXY_S3_DELETE_TYPE)\n          .setDefaultValue(Constants.S3_DELETE_IN_ALLUXIO_AND_UFS)\n          .setDescription(String.format(\n              \"Delete type when deleting buckets and objects through S3 API. Valid options are \"\n                  + \"`%s` (delete both in Alluxio and UFS), \"\n                  + \"`%s` (delete only the buckets or objects in Alluxio namespace).\",\n              Constants.S3_DELETE_IN_ALLUXIO_AND_UFS, Constants.S3_DELETE_IN_ALLUXIO_ONLY))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "PROXY_S3_DELETE_TYPE"}, {"original_string": "public static final PropertyKey PROXY_S3_MULTIPART_TEMPORARY_DIR_SUFFIX =\n      new Builder(Name.PROXY_S3_MULTIPART_TEMPORARY_DIR_SUFFIX)\n          .setDefaultValue(Constants.S3_MULTIPART_TEMPORARY_DIR_SUFFIX)\n          .setDescription(\"Suffix for the directory which holds parts during a multipart upload.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_S3_MULTIPART_TEMPORARY_DIR_SUFFIX =\n      new Builder(Name.PROXY_S3_MULTIPART_TEMPORARY_DIR_SUFFIX)\n          .setDefaultValue(Constants.S3_MULTIPART_TEMPORARY_DIR_SUFFIX)\n          .setDescription(\"Suffix for the directory which holds parts during a multipart upload.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "PROXY_S3_MULTIPART_TEMPORARY_DIR_SUFFIX"}, {"original_string": "public static final PropertyKey PROXY_STREAM_CACHE_TIMEOUT_MS =\n      new Builder(Name.PROXY_STREAM_CACHE_TIMEOUT_MS)\n          .setAlias(\"alluxio.proxy.stream.cache.timeout.ms\")\n          .setDefaultValue(\"1hour\")\n          .setDescription(\"The timeout for the input and output streams cache eviction in the \"\n              + \"proxy.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_STREAM_CACHE_TIMEOUT_MS =\n      new Builder(Name.PROXY_STREAM_CACHE_TIMEOUT_MS)\n          .setAlias(\"alluxio.proxy.stream.cache.timeout.ms\")\n          .setDefaultValue(\"1hour\")\n          .setDescription(\"The timeout for the input and output streams cache eviction in the \"\n              + \"proxy.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "PROXY_STREAM_CACHE_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey PROXY_WEB_BIND_HOST =\n      new Builder(Name.PROXY_WEB_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname that the Alluxio proxy's web server runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_WEB_BIND_HOST =\n      new Builder(Name.PROXY_WEB_BIND_HOST)\n          .setDefaultValue(\"0.0.0.0\")\n          .setDescription(\"The hostname that the Alluxio proxy's web server runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "PROXY_WEB_BIND_HOST"}, {"original_string": "public static final PropertyKey PROXY_WEB_HOSTNAME =\n      new Builder(Name.PROXY_WEB_HOSTNAME)\n          .setDescription(\"The hostname Alluxio proxy's web UI binds to.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_WEB_HOSTNAME =\n      new Builder(Name.PROXY_WEB_HOSTNAME)\n          .setDescription(\"The hostname Alluxio proxy's web UI binds to.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "PROXY_WEB_HOSTNAME"}, {"original_string": "public static final PropertyKey PROXY_WEB_PORT =\n      new Builder(Name.PROXY_WEB_PORT)\n          .setDefaultValue(39999)\n          .setDescription(\"The port Alluxio proxy's web UI runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "PROXY_WEB_PORT =\n      new Builder(Name.PROXY_WEB_PORT)\n          .setDefaultValue(39999)\n          .setDescription(\"The port Alluxio proxy's web UI runs on.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "PROXY_WEB_PORT"}, {"original_string": "public static final PropertyKey LOCALITY_ORDER =\n      new Builder(Name.LOCALITY_ORDER)\n          .setDefaultValue(String.format(\"%s,%s\", Constants.LOCALITY_NODE, Constants.LOCALITY_RACK))\n          .setDescription(\"Ordering of locality tiers\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOCALITY_ORDER =\n      new Builder(Name.LOCALITY_ORDER)\n          .setDefaultValue(String.format(\"%s,%s\", Constants.LOCALITY_NODE, Constants.LOCALITY_RACK))\n          .setDescription(\"Ordering of locality tiers\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOCALITY_ORDER"}, {"original_string": "public static final PropertyKey LOCALITY_SCRIPT =\n      new Builder(Name.LOCALITY_SCRIPT)\n          .setDefaultValue(Constants.ALLUXIO_LOCALITY_SCRIPT)\n          .setDescription(\"A script to determine tiered identity for locality checking\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOCALITY_SCRIPT =\n      new Builder(Name.LOCALITY_SCRIPT)\n          .setDefaultValue(Constants.ALLUXIO_LOCALITY_SCRIPT)\n          .setDescription(\"A script to determine tiered identity for locality checking\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOCALITY_SCRIPT"}, {"original_string": "public static final PropertyKey LOCALITY_TIER_NODE =\n      new Builder(Template.LOCALITY_TIER, Constants.LOCALITY_NODE)\n          .setDescription(\"Value to use for determining node locality\")\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOCALITY_TIER_NODE =\n      new Builder(Template.LOCALITY_TIER, Constants.LOCALITY_NODE)\n          .setDescription(\"Value to use for determining node locality\")\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOCALITY_TIER_NODE"}, {"original_string": "public static final PropertyKey LOCALITY_TIER_RACK =\n      new Builder(Template.LOCALITY_TIER, Constants.LOCALITY_RACK)\n          .setDescription(\"Value to use for determining rack locality\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOCALITY_TIER_RACK =\n      new Builder(Template.LOCALITY_TIER, Constants.LOCALITY_RACK)\n          .setDescription(\"Value to use for determining rack locality\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOCALITY_TIER_RACK"}, {"original_string": "public static final PropertyKey LOCALITY_COMPARE_NODE_IP =\n          new Builder(Name.LOCALITY_COMPARE_NODE_IP)\n          .setDefaultValue(false)\n          .setDescription(\"Whether try to resolve the node IP address for locality checking\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOCALITY_COMPARE_NODE_IP =\n          new Builder(Name.LOCALITY_COMPARE_NODE_IP)\n          .setDefaultValue(false)\n          .setDescription(\"Whether try to resolve the node IP address for locality checking\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "LOCALITY_COMPARE_NODE_IP"}, {"original_string": "public static final PropertyKey LOGSERVER_LOGS_DIR =\n      new Builder(Name.LOGSERVER_LOGS_DIR)\n          .setDefaultValue(String.format(\"${%s}/logs\", Name.WORK_DIR))\n          .setDescription(\"Default location for remote log files.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGSERVER_LOGS_DIR =\n      new Builder(Name.LOGSERVER_LOGS_DIR)\n          .setDefaultValue(String.format(\"${%s}/logs\", Name.WORK_DIR))\n          .setDescription(\"Default location for remote log files.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "LOGSERVER_LOGS_DIR"}, {"original_string": "public static final PropertyKey LOGSERVER_HOSTNAME =\n      new Builder(Name.LOGSERVER_HOSTNAME)\n          .setDescription(\"The hostname of Alluxio logserver.\")\n          .setIgnoredSiteProperty(true)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGSERVER_HOSTNAME =\n      new Builder(Name.LOGSERVER_HOSTNAME)\n          .setDescription(\"The hostname of Alluxio logserver.\")\n          .setIgnoredSiteProperty(true)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "LOGSERVER_HOSTNAME"}, {"original_string": "public static final PropertyKey LOGSERVER_PORT =\n      new Builder(Name.LOGSERVER_PORT)\n          .setDefaultValue(45600)\n          .setDescription(\"Default port of logserver to receive logs from alluxio servers.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGSERVER_PORT =\n      new Builder(Name.LOGSERVER_PORT)\n          .setDefaultValue(45600)\n          .setDescription(\"Default port of logserver to receive logs from alluxio servers.\")\n          .setIgnoredSiteProperty(true)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "LOGSERVER_PORT"}, {"original_string": "public static final PropertyKey LOGSERVER_THREADS_MAX =\n      new Builder(Name.LOGSERVER_THREADS_MAX)\n          .setDefaultValue(2048)\n          .setDescription(\"The maximum number of threads used by logserver to service\"\n              + \" logging requests.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGSERVER_THREADS_MAX =\n      new Builder(Name.LOGSERVER_THREADS_MAX)\n          .setDefaultValue(2048)\n          .setDescription(\"The maximum number of threads used by logserver to service\"\n              + \" logging requests.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "LOGSERVER_THREADS_MAX"}, {"original_string": "public static final PropertyKey LOGSERVER_THREADS_MIN =\n      new Builder(Name.LOGSERVER_THREADS_MIN)\n          .setDefaultValue(512)\n          .setDescription(\"The minimum number of threads used by logserver to service\"\n              + \" logging requests.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "LOGSERVER_THREADS_MIN =\n      new Builder(Name.LOGSERVER_THREADS_MIN)\n          .setDefaultValue(512)\n          .setDescription(\"The minimum number of threads used by logserver to service\"\n              + \" logging requests.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "LOGSERVER_THREADS_MIN"}, {"original_string": "public static final PropertyKey USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MIN =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The minimum number of block master clients cached in the block master \"\n              + \"client pool. For long running processes, this should be set to zero.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MIN =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The minimum number of block master clients cached in the block master \"\n              + \"client pool. For long running processes, this should be set to zero.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MIN"}, {"original_string": "public static final PropertyKey USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MAX =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MAX)\n          .setDefaultValue(10)\n          .setDescription(\"The maximum number of block master clients cached in the block master \"\n              + \"client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setAlias(new String[] {\"alluxio.user.block.master.client.threads\"})\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MAX =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MAX)\n          .setDefaultValue(10)\n          .setDescription(\"The maximum number of block master clients cached in the block master \"\n              + \"client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setAlias(new String[] {\"alluxio.user.block.master.client.threads\"})\n          .build()", "var_name": "USER_BLOCK_MASTER_CLIENT_POOL_SIZE_MAX"}, {"original_string": "public static final PropertyKey USER_BLOCK_MASTER_CLIENT_POOL_GC_INTERVAL_MS =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_GC_INTERVAL_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"The interval at which block master client GC checks occur.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_MASTER_CLIENT_POOL_GC_INTERVAL_MS =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_GC_INTERVAL_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"The interval at which block master client GC checks occur.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_MASTER_CLIENT_POOL_GC_INTERVAL_MS"}, {"original_string": "public static final PropertyKey USER_BLOCK_MASTER_CLIENT_POOL_GC_THRESHOLD_MS =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_GC_THRESHOLD_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"A block master client is closed if it has been idle for more than this \"\n              + \"threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_MASTER_CLIENT_POOL_GC_THRESHOLD_MS =\n      new Builder(Name.USER_BLOCK_MASTER_CLIENT_POOL_GC_THRESHOLD_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"A block master client is closed if it has been idle for more than this \"\n              + \"threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_MASTER_CLIENT_POOL_GC_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey USER_BLOCK_WORKER_CLIENT_POOL_MIN =\n      new Builder(Name.USER_BLOCK_WORKER_CLIENT_POOL_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The minimum number of block worker clients cached in the block \"\n              + \"worker client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setIsHidden(true)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_WORKER_CLIENT_POOL_MIN =\n      new Builder(Name.USER_BLOCK_WORKER_CLIENT_POOL_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The minimum number of block worker clients cached in the block \"\n              + \"worker client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setIsHidden(true)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_WORKER_CLIENT_POOL_MIN"}, {"original_string": "public static final PropertyKey USER_BLOCK_WORKER_CLIENT_POOL_MAX =\n      new Builder(Name.USER_BLOCK_WORKER_CLIENT_POOL_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of block worker clients cached in the block \"\n              + \"worker client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setAlias(new String[] {\"alluxio.user.block.worker.client.pool.size\"})\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_WORKER_CLIENT_POOL_MAX =\n      new Builder(Name.USER_BLOCK_WORKER_CLIENT_POOL_MAX)\n          .setDefaultValue(1024)\n          .setDescription(\"The maximum number of block worker clients cached in the block \"\n              + \"worker client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setAlias(new String[] {\"alluxio.user.block.worker.client.pool.size\"})\n          .build()", "var_name": "USER_BLOCK_WORKER_CLIENT_POOL_MAX"}, {"original_string": "public static final PropertyKey USER_BLOCK_WORKER_CLIENT_POOL_GC_THRESHOLD_MS =\n      new Builder(Name.USER_BLOCK_WORKER_CLIENT_POOL_GC_THRESHOLD_MS)\n          .setDefaultValue(\"300sec\")\n          .setDescription(\"A block worker client is closed if it has been idle for more than this \"\n              + \"threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_WORKER_CLIENT_POOL_GC_THRESHOLD_MS =\n      new Builder(Name.USER_BLOCK_WORKER_CLIENT_POOL_GC_THRESHOLD_MS)\n          .setDefaultValue(\"300sec\")\n          .setDescription(\"A block worker client is closed if it has been idle for more than this \"\n              + \"threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_WORKER_CLIENT_POOL_GC_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey USER_BLOCK_REMOTE_READ_BUFFER_SIZE_BYTES =\n      new Builder(Name.USER_BLOCK_REMOTE_READ_BUFFER_SIZE_BYTES)\n          .setDefaultValue(\"8MB\")\n          .setDescription(\"The size of the file buffer to read data from remote Alluxio \"\n              + \"worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_REMOTE_READ_BUFFER_SIZE_BYTES =\n      new Builder(Name.USER_BLOCK_REMOTE_READ_BUFFER_SIZE_BYTES)\n          .setDefaultValue(\"8MB\")\n          .setDescription(\"The size of the file buffer to read data from remote Alluxio \"\n              + \"worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_REMOTE_READ_BUFFER_SIZE_BYTES"}, {"original_string": "public static final PropertyKey USER_CONF_SYNC_INTERVAL =\n      new Builder(Name.USER_CONF_SYNC_INTERVAL)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"The time period of client master heartbeat to \"\n              + \"update the configuration if necessary from meta master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CONF_SYNC_INTERVAL =\n      new Builder(Name.USER_CONF_SYNC_INTERVAL)\n          .setDefaultValue(\"1min\")\n          .setDescription(\"The time period of client master heartbeat to \"\n              + \"update the configuration if necessary from meta master.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CONF_SYNC_INTERVAL"}, {"original_string": "public static final PropertyKey USER_FILE_REPLICATION_MAX =\n      new Builder(Name.USER_FILE_REPLICATION_MAX)\n          .setDefaultValue(-1)\n          .setDescription(\"The target max replication level of a file in Alluxio space. Setting \"\n              + \"this property to a negative value means no upper limit.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_REPLICATION_MAX =\n      new Builder(Name.USER_FILE_REPLICATION_MAX)\n          .setDefaultValue(-1)\n          .setDescription(\"The target max replication level of a file in Alluxio space. Setting \"\n              + \"this property to a negative value means no upper limit.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_REPLICATION_MAX"}, {"original_string": "public static final PropertyKey USER_FILE_REPLICATION_MIN =\n      new Builder(Name.USER_FILE_REPLICATION_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The target min replication level of a file in Alluxio space.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_REPLICATION_MIN =\n      new Builder(Name.USER_FILE_REPLICATION_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The target min replication level of a file in Alluxio space.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_REPLICATION_MIN"}, {"original_string": "public static final PropertyKey USER_FILE_REPLICATION_DURABLE =\n      new Builder(Name.USER_FILE_REPLICATION_DURABLE)\n          .setDefaultValue(1)\n          .setDescription(\"The target replication level of a file created by ASYNC_THROUGH writes\"\n              + \"before this file is persisted.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_REPLICATION_DURABLE =\n      new Builder(Name.USER_FILE_REPLICATION_DURABLE)\n          .setDefaultValue(1)\n          .setDescription(\"The target replication level of a file created by ASYNC_THROUGH writes\"\n              + \"before this file is persisted.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_REPLICATION_DURABLE"}, {"original_string": "public static final PropertyKey USER_FILE_SEQUENTIAL_PREAD_THRESHOLD =\n      new Builder(Name.USER_FILE_SEQUENTIAL_PREAD_THRESHOLD)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"An upper bound on the client buffer size for positioned read to hint \"\n              + \"at the sequential nature of reads. For reads with a buffer size greater than this \"\n              + \"threshold, the read op is treated to be sequential and the worker may handle the \"\n              + \"read differently. For instance, cold reads from the HDFS ufs may use a different \"\n              + \"HDFS client API.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_SEQUENTIAL_PREAD_THRESHOLD =\n      new Builder(Name.USER_FILE_SEQUENTIAL_PREAD_THRESHOLD)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"An upper bound on the client buffer size for positioned read to hint \"\n              + \"at the sequential nature of reads. For reads with a buffer size greater than this \"\n              + \"threshold, the read op is treated to be sequential and the worker may handle the \"\n              + \"read differently. For instance, cold reads from the HDFS ufs may use a different \"\n              + \"HDFS client API.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_SEQUENTIAL_PREAD_THRESHOLD"}, {"original_string": "public static final PropertyKey USER_FILE_TARGET_MEDIA =\n      new Builder(Name.USER_FILE_TARGET_MEDIA)\n          .setDescription(\"Preferred media type while storing file's blocks.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_TARGET_MEDIA =\n      new Builder(Name.USER_FILE_TARGET_MEDIA)\n          .setDescription(\"Preferred media type while storing file's blocks.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_TARGET_MEDIA"}, {"original_string": "public static final PropertyKey USER_BLOCK_SIZE_BYTES_DEFAULT =\n      new Builder(Name.USER_BLOCK_SIZE_BYTES_DEFAULT)\n          .setDefaultValue(\"64MB\")\n          .setDescription(\"Default block size for Alluxio files.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_SIZE_BYTES_DEFAULT =\n      new Builder(Name.USER_BLOCK_SIZE_BYTES_DEFAULT)\n          .setDefaultValue(\"64MB\")\n          .setDescription(\"Default block size for Alluxio files.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_SIZE_BYTES_DEFAULT"}, {"original_string": "public static final PropertyKey USER_BLOCK_READ_RETRY_SLEEP_MIN =\n          new Builder(Name.USER_BLOCK_READ_RETRY_SLEEP_MIN)\n          .setDefaultValue(\"250ms\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_READ_RETRY_SLEEP_MIN =\n          new Builder(Name.USER_BLOCK_READ_RETRY_SLEEP_MIN)\n          .setDefaultValue(\"250ms\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_READ_RETRY_SLEEP_MIN"}, {"original_string": "public static final PropertyKey USER_BLOCK_READ_RETRY_SLEEP_MAX =\n          new Builder(Name.USER_BLOCK_READ_RETRY_SLEEP_MAX)\n          .setDefaultValue(\"2sec\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_READ_RETRY_SLEEP_MAX =\n          new Builder(Name.USER_BLOCK_READ_RETRY_SLEEP_MAX)\n          .setDefaultValue(\"2sec\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_READ_RETRY_SLEEP_MAX"}, {"original_string": "public static final PropertyKey USER_BLOCK_READ_RETRY_MAX_DURATION =\n      new Builder(Name.USER_BLOCK_READ_RETRY_MAX_DURATION)\n          .setDefaultValue(\"2min\")\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_READ_RETRY_MAX_DURATION =\n      new Builder(Name.USER_BLOCK_READ_RETRY_MAX_DURATION)\n          .setDefaultValue(\"2min\")\n          .build()", "var_name": "USER_BLOCK_READ_RETRY_MAX_DURATION"}, {"original_string": "public static final PropertyKey USER_CONF_CLUSTER_DEFAULT_ENABLED =\n      new Builder(Name.USER_CONF_CLUSTER_DEFAULT_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"When this property is true, an Alluxio client will load the default \"\n              + \"values of configuration properties set by Alluxio master.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CONF_CLUSTER_DEFAULT_ENABLED =\n      new Builder(Name.USER_CONF_CLUSTER_DEFAULT_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"When this property is true, an Alluxio client will load the default \"\n              + \"values of configuration properties set by Alluxio master.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CONF_CLUSTER_DEFAULT_ENABLED"}, {"original_string": "public static final PropertyKey USER_DATE_FORMAT_PATTERN =\n      new Builder(Name.USER_DATE_FORMAT_PATTERN)\n          .setDefaultValue(\"MM-dd-yyyy HH:mm:ss:SSS\")\n          .setDescription(\"Display formatted date in cli command and web UI by given date \"\n              + \"format pattern.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_DATE_FORMAT_PATTERN =\n      new Builder(Name.USER_DATE_FORMAT_PATTERN)\n          .setDefaultValue(\"MM-dd-yyyy HH:mm:ss:SSS\")\n          .setDescription(\"Display formatted date in cli command and web UI by given date \"\n              + \"format pattern.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_DATE_FORMAT_PATTERN"}, {"original_string": "public static final PropertyKey USER_FILE_BUFFER_BYTES =\n      new Builder(Name.USER_FILE_BUFFER_BYTES)\n          .setDefaultValue(\"8MB\")\n          .setDescription(\"The size of the file buffer to use for file system reads/writes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_BUFFER_BYTES =\n      new Builder(Name.USER_FILE_BUFFER_BYTES)\n          .setDefaultValue(\"8MB\")\n          .setDescription(\"The size of the file buffer to use for file system reads/writes.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_BUFFER_BYTES"}, {"original_string": "public static final PropertyKey USER_FILE_RESERVED_BYTES =\n      new Builder(Name.USER_FILE_RESERVED_BYTES)\n          .setDefaultValue(String.format(\"${%s}\", Name.USER_BLOCK_SIZE_BYTES_DEFAULT))\n          .setDescription(\"The size to reserve on workers for file system writes.\"\n              + \"Using smaller value will improve concurrency for writes smaller than block size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_RESERVED_BYTES =\n      new Builder(Name.USER_FILE_RESERVED_BYTES)\n          .setDefaultValue(String.format(\"${%s}\", Name.USER_BLOCK_SIZE_BYTES_DEFAULT))\n          .setDescription(\"The size to reserve on workers for file system writes.\"\n              + \"Using smaller value will improve concurrency for writes smaller than block size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_RESERVED_BYTES"}, {"original_string": "public static final PropertyKey USER_FILE_COPYFROMLOCAL_BLOCK_LOCATION_POLICY =\n      new Builder(Name.USER_FILE_COPYFROMLOCAL_BLOCK_LOCATION_POLICY)\n          .setDefaultValue(\"alluxio.client.block.policy.RoundRobinPolicy\")\n          .setDescription(\"The default location policy for choosing workers for writing a \"\n              + \"file's blocks using copyFromLocal command.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_COPYFROMLOCAL_BLOCK_LOCATION_POLICY =\n      new Builder(Name.USER_FILE_COPYFROMLOCAL_BLOCK_LOCATION_POLICY)\n          .setDefaultValue(\"alluxio.client.block.policy.RoundRobinPolicy\")\n          .setDescription(\"The default location policy for choosing workers for writing a \"\n              + \"file's blocks using copyFromLocal command.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_COPYFROMLOCAL_BLOCK_LOCATION_POLICY"}, {"original_string": "public static final PropertyKey USER_FILE_DELETE_UNCHECKED =\n      new Builder(Name.USER_FILE_DELETE_UNCHECKED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to check if the UFS contents are in sync with Alluxio \"\n              + \"before attempting to delete persisted directories recursively.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_DELETE_UNCHECKED =\n      new Builder(Name.USER_FILE_DELETE_UNCHECKED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to check if the UFS contents are in sync with Alluxio \"\n              + \"before attempting to delete persisted directories recursively.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_DELETE_UNCHECKED"}, {"original_string": "public static final PropertyKey USER_FILE_MASTER_CLIENT_POOL_SIZE_MIN =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_SIZE_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The minimum number of fs master clients cached in the fs master \"\n              + \"client pool. For long running processes, this should be set to zero.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_MASTER_CLIENT_POOL_SIZE_MIN =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_SIZE_MIN)\n          .setDefaultValue(0)\n          .setDescription(\"The minimum number of fs master clients cached in the fs master \"\n              + \"client pool. For long running processes, this should be set to zero.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_MASTER_CLIENT_POOL_SIZE_MIN"}, {"original_string": "public static final PropertyKey USER_FILE_MASTER_CLIENT_POOL_SIZE_MAX =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_SIZE_MAX)\n          .setDefaultValue(10)\n          .setDescription(\"The maximum number of fs master clients cached in the fs master \"\n              + \"client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setAlias(new String[] {\"alluxio.user.file.master.client.threads\"})\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_MASTER_CLIENT_POOL_SIZE_MAX =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_SIZE_MAX)\n          .setDefaultValue(10)\n          .setDescription(\"The maximum number of fs master clients cached in the fs master \"\n              + \"client pool.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setAlias(new String[] {\"alluxio.user.file.master.client.threads\"})\n          .build()", "var_name": "USER_FILE_MASTER_CLIENT_POOL_SIZE_MAX"}, {"original_string": "public static final PropertyKey USER_FILE_MASTER_CLIENT_POOL_GC_INTERVAL_MS =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_GC_INTERVAL_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"The interval at which file system master client GC checks occur.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_MASTER_CLIENT_POOL_GC_INTERVAL_MS =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_GC_INTERVAL_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"The interval at which file system master client GC checks occur.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_MASTER_CLIENT_POOL_GC_INTERVAL_MS"}, {"original_string": "public static final PropertyKey USER_FILE_MASTER_CLIENT_POOL_GC_THRESHOLD_MS =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_GC_THRESHOLD_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"A fs master client is closed if it has been idle for more than this \"\n              + \"threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_MASTER_CLIENT_POOL_GC_THRESHOLD_MS =\n      new Builder(Name.USER_FILE_MASTER_CLIENT_POOL_GC_THRESHOLD_MS)\n          .setDefaultValue(\"120sec\")\n          .setDescription(\"A fs master client is closed if it has been idle for more than this \"\n              + \"threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_MASTER_CLIENT_POOL_GC_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey USER_FILE_METADATA_LOAD_TYPE =\n      new Builder(Name.USER_FILE_METADATA_LOAD_TYPE)\n          .setDefaultValue(\"ONCE\")\n          .setDescription(\"The behavior of loading metadata from UFS. When information about \"\n              + \"a path is requested and the path does not exist in Alluxio, metadata can be \"\n              + \"loaded from the UFS. Valid options are `ALWAYS`, `NEVER`, and `ONCE`. \"\n              + \"`ALWAYS` will always access UFS to see if the path exists in the UFS. \"\n              + \"`NEVER` will never consult the UFS. `ONCE` will access the UFS the \\\"first\\\" \"\n              + \"time (according to a cache), but not after that. This parameter is ignored if a \"\n              + \"metadata sync is performed, via the parameter \"\n              + \"\\\"alluxio.user.file.metadata.sync.interval\\\"\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_METADATA_LOAD_TYPE =\n      new Builder(Name.USER_FILE_METADATA_LOAD_TYPE)\n          .setDefaultValue(\"ONCE\")\n          .setDescription(\"The behavior of loading metadata from UFS. When information about \"\n              + \"a path is requested and the path does not exist in Alluxio, metadata can be \"\n              + \"loaded from the UFS. Valid options are `ALWAYS`, `NEVER`, and `ONCE`. \"\n              + \"`ALWAYS` will always access UFS to see if the path exists in the UFS. \"\n              + \"`NEVER` will never consult the UFS. `ONCE` will access the UFS the \\\"first\\\" \"\n              + \"time (according to a cache), but not after that. This parameter is ignored if a \"\n              + \"metadata sync is performed, via the parameter \"\n              + \"\\\"alluxio.user.file.metadata.sync.interval\\\"\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_METADATA_LOAD_TYPE"}, {"original_string": "public static final PropertyKey USER_FILE_METADATA_SYNC_INTERVAL =\n      new Builder(Name.USER_FILE_METADATA_SYNC_INTERVAL)\n          .setDefaultValue(\"-1\")\n          .setDescription(\"The interval for syncing UFS metadata before invoking an \"\n              + \"operation on a path. -1 means no sync will occur. 0 means Alluxio will \"\n              + \"always sync the metadata of the path before an operation. If you specify a time \"\n              + \"interval, Alluxio will (best effort) not re-sync a path within that time \"\n              + \"interval. Syncing the metadata for a path must interact with the UFS, so it is \"\n              + \"an expensive operation. If a sync is performed for an operation, the \"\n              + \"configuration of \\\"alluxio.user.file.metadata.load.type\\\" will be ignored.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_METADATA_SYNC_INTERVAL =\n      new Builder(Name.USER_FILE_METADATA_SYNC_INTERVAL)\n          .setDefaultValue(\"-1\")\n          .setDescription(\"The interval for syncing UFS metadata before invoking an \"\n              + \"operation on a path. -1 means no sync will occur. 0 means Alluxio will \"\n              + \"always sync the metadata of the path before an operation. If you specify a time \"\n              + \"interval, Alluxio will (best effort) not re-sync a path within that time \"\n              + \"interval. Syncing the metadata for a path must interact with the UFS, so it is \"\n              + \"an expensive operation. If a sync is performed for an operation, the \"\n              + \"configuration of \\\"alluxio.user.file.metadata.load.type\\\" will be ignored.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_METADATA_SYNC_INTERVAL"}, {"original_string": "public static final PropertyKey USER_FILE_PASSIVE_CACHE_ENABLED =\n      new Builder(Name.USER_FILE_PASSIVE_CACHE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to cache files to local Alluxio workers when the files are read \"\n              + \"from remote workers (not UFS).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_PASSIVE_CACHE_ENABLED =\n      new Builder(Name.USER_FILE_PASSIVE_CACHE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to cache files to local Alluxio workers when the files are read \"\n              + \"from remote workers (not UFS).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_PASSIVE_CACHE_ENABLED"}, {"original_string": "public static final PropertyKey USER_FILE_READ_TYPE_DEFAULT =\n      new Builder(Name.USER_FILE_READ_TYPE_DEFAULT)\n          .setDefaultValue(\"CACHE\")\n          .setDescription(\"Default read type when creating Alluxio files. Valid options are \"\n              + \"`CACHE_PROMOTE` (move data to highest tier if already in Alluxio storage, \"\n              + \"write data into highest tier of local Alluxio if data needs to be read from \"\n              + \"under storage), `CACHE` (write data into highest tier of local Alluxio if \"\n              + \"data needs to be read from under storage), `NO_CACHE` (no data interaction \"\n              + \"with Alluxio, if the read is from Alluxio data migration or eviction will \"\n              + \"not occur).\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_READ_TYPE_DEFAULT =\n      new Builder(Name.USER_FILE_READ_TYPE_DEFAULT)\n          .setDefaultValue(\"CACHE\")\n          .setDescription(\"Default read type when creating Alluxio files. Valid options are \"\n              + \"`CACHE_PROMOTE` (move data to highest tier if already in Alluxio storage, \"\n              + \"write data into highest tier of local Alluxio if data needs to be read from \"\n              + \"under storage), `CACHE` (write data into highest tier of local Alluxio if \"\n              + \"data needs to be read from under storage), `NO_CACHE` (no data interaction \"\n              + \"with Alluxio, if the read is from Alluxio data migration or eviction will \"\n              + \"not occur).\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_READ_TYPE_DEFAULT"}, {"original_string": "public static final PropertyKey USER_FILE_PERSIST_ON_RENAME =\n      new Builder(Name.USER_FILE_PERSIST_ON_RENAME)\n          .setDefaultValue(\"false\")\n          .setDescription(\"Whether or not to asynchronously persist any files which have been \"\n              + \"renamed. This is helpful when working with compute frameworks which use rename \"\n              + \"to commit results.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_PERSIST_ON_RENAME =\n      new Builder(Name.USER_FILE_PERSIST_ON_RENAME)\n          .setDefaultValue(\"false\")\n          .setDescription(\"Whether or not to asynchronously persist any files which have been \"\n              + \"renamed. This is helpful when working with compute frameworks which use rename \"\n              + \"to commit results.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_PERSIST_ON_RENAME"}, {"original_string": "public static final PropertyKey USER_FILE_PERSISTENCE_INITIAL_WAIT_TIME =\n      new Builder(Name.USER_FILE_PERSISTENCE_INITIAL_WAIT_TIME)\n          .setDefaultValue(\"0\")\n          .setDescription(String.format(\"Time to wait before starting the persistence job. \"\n              + \"When the value is set to -1, the file will be persisted by rename operation \"\n              + \"or persist CLI but will not be automatically persisted in other cases. \"\n              + \"This is to avoid the heavy object copy in rename operation when %s is set to %s. \"\n              + \"This value should be smaller than the value of %s\",\n              Name.USER_FILE_WRITE_TYPE_DEFAULT, WritePType.ASYNC_THROUGH,\n              Name.MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS))\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_PERSISTENCE_INITIAL_WAIT_TIME =\n      new Builder(Name.USER_FILE_PERSISTENCE_INITIAL_WAIT_TIME)\n          .setDefaultValue(\"0\")\n          .setDescription(String.format(\"Time to wait before starting the persistence job. \"\n              + \"When the value is set to -1, the file will be persisted by rename operation \"\n              + \"or persist CLI but will not be automatically persisted in other cases. \"\n              + \"This is to avoid the heavy object copy in rename operation when %s is set to %s. \"\n              + \"This value should be smaller than the value of %s\",\n              Name.USER_FILE_WRITE_TYPE_DEFAULT, WritePType.ASYNC_THROUGH,\n              Name.MASTER_PERSISTENCE_MAX_TOTAL_WAIT_TIME_MS))\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_PERSISTENCE_INITIAL_WAIT_TIME"}, {"original_string": "public static final PropertyKey USER_FILE_WAITCOMPLETED_POLL_MS =\n      new Builder(Name.USER_FILE_WAITCOMPLETED_POLL_MS)\n          .setAlias(\"alluxio.user.file.waitcompleted.poll.ms\")\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The time interval to poll a file for its completion status when \"\n              + \"using waitCompleted.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_WAITCOMPLETED_POLL_MS =\n      new Builder(Name.USER_FILE_WAITCOMPLETED_POLL_MS)\n          .setAlias(\"alluxio.user.file.waitcompleted.poll.ms\")\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The time interval to poll a file for its completion status when \"\n              + \"using waitCompleted.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_WAITCOMPLETED_POLL_MS"}, {"original_string": "public static final PropertyKey USER_FILE_CREATE_TTL =\n      new Builder(Name.USER_FILE_CREATE_TTL)\n          .setDefaultValue(Constants.NO_TTL)\n          .setDescription(\"Time to live for files created by a user, no ttl by default.\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_CREATE_TTL =\n      new Builder(Name.USER_FILE_CREATE_TTL)\n          .setDefaultValue(Constants.NO_TTL)\n          .setDescription(\"Time to live for files created by a user, no ttl by default.\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_CREATE_TTL"}, {"original_string": "public static final PropertyKey USER_FILE_CREATE_TTL_ACTION =\n      new Builder(Name.USER_FILE_CREATE_TTL_ACTION)\n          .setDefaultValue(\"DELETE\")\n          .setDescription(\"When file's ttl is expired, the action performs on it. Options: \"\n              + \"DELETE (default) or FREE\")\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_CREATE_TTL_ACTION =\n      new Builder(Name.USER_FILE_CREATE_TTL_ACTION)\n          .setDefaultValue(\"DELETE\")\n          .setDescription(\"When file's ttl is expired, the action performs on it. Options: \"\n              + \"DELETE (default) or FREE\")\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_CREATE_TTL_ACTION"}, {"original_string": "public static final PropertyKey USER_FILE_UFS_TIER_ENABLED =\n      new Builder(Name.USER_FILE_UFS_TIER_ENABLED)\n          .setDescription(\"When workers run out of available memory, whether the client can skip \"\n              + \"writing data to Alluxio but fallback to write to UFS without stopping the \"\n              + \"application. This property only works when the write type is ASYNC_THROUGH.\")\n          .setDefaultValue(false)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_UFS_TIER_ENABLED =\n      new Builder(Name.USER_FILE_UFS_TIER_ENABLED)\n          .setDescription(\"When workers run out of available memory, whether the client can skip \"\n              + \"writing data to Alluxio but fallback to write to UFS without stopping the \"\n              + \"application. This property only works when the write type is ASYNC_THROUGH.\")\n          .setDefaultValue(false)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_UFS_TIER_ENABLED"}, {"original_string": "public static final PropertyKey USER_BLOCK_WRITE_LOCATION_POLICY =\n      new Builder(Name.USER_BLOCK_WRITE_LOCATION_POLICY)\n          .setDefaultValue(\"alluxio.client.block.policy.LocalFirstPolicy\")\n          .setDescription(\"The default location policy for choosing workers for writing a \"\n              + \"file's blocks.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_WRITE_LOCATION_POLICY =\n      new Builder(Name.USER_BLOCK_WRITE_LOCATION_POLICY)\n          .setDefaultValue(\"alluxio.client.block.policy.LocalFirstPolicy\")\n          .setDescription(\"The default location policy for choosing workers for writing a \"\n              + \"file's blocks.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_WRITE_LOCATION_POLICY"}, {"original_string": "public static final PropertyKey USER_BLOCK_AVOID_EVICTION_POLICY_RESERVED_BYTES =\n      new Builder(Name.USER_BLOCK_AVOID_EVICTION_POLICY_RESERVED_BYTES)\n          .setDefaultValue(\"0MB\")\n          .setDescription(\"The portion of space reserved in a worker when using the \"\n              + \"LocalFirstAvoidEvictionPolicy class as block location policy.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_BLOCK_AVOID_EVICTION_POLICY_RESERVED_BYTES =\n      new Builder(Name.USER_BLOCK_AVOID_EVICTION_POLICY_RESERVED_BYTES)\n          .setDefaultValue(\"0MB\")\n          .setDescription(\"The portion of space reserved in a worker when using the \"\n              + \"LocalFirstAvoidEvictionPolicy class as block location policy.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_BLOCK_AVOID_EVICTION_POLICY_RESERVED_BYTES"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_ASYNC_RESTORE_ENABLED =\n      new Builder(Name.USER_CLIENT_CACHE_ASYNC_RESTORE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"If this is enabled, cache restore state asynchronously.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_ASYNC_RESTORE_ENABLED =\n      new Builder(Name.USER_CLIENT_CACHE_ASYNC_RESTORE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"If this is enabled, cache restore state asynchronously.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_ASYNC_RESTORE_ENABLED"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_ASYNC_WRITE_ENABLED =\n      new Builder(Name.USER_CLIENT_CACHE_ASYNC_WRITE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"If this is enabled, cache data asynchronously.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_ASYNC_WRITE_ENABLED =\n      new Builder(Name.USER_CLIENT_CACHE_ASYNC_WRITE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"If this is enabled, cache data asynchronously.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_ASYNC_WRITE_ENABLED"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_ASYNC_WRITE_THREADS =\n      new Builder(Name.USER_CLIENT_CACHE_ASYNC_WRITE_THREADS)\n          .setDefaultValue(16)\n          .setDescription(\"Number of threads to asynchronously cache data.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_ASYNC_WRITE_THREADS =\n      new Builder(Name.USER_CLIENT_CACHE_ASYNC_WRITE_THREADS)\n          .setDefaultValue(16)\n          .setDescription(\"Number of threads to asynchronously cache data.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_ASYNC_WRITE_THREADS"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_ENABLED =\n      new Builder(Name.USER_CLIENT_CACHE_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"If this is enabled, data will be cached on Alluxio client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_ENABLED =\n      new Builder(Name.USER_CLIENT_CACHE_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"If this is enabled, data will be cached on Alluxio client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_ENABLED"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_EVICTOR_CLASS =\n      new Builder(Name.USER_CLIENT_CACHE_EVICTOR_CLASS)\n          .setDefaultValue(\"alluxio.client.file.cache.evictor.LRUCacheEvictor\")\n          .setDescription(\"The strategy that client uses to evict local cached pages when running \"\n              + \"out of space. Currently the only valid option provided is \"\n              + \"`alluxio.client.file.cache.evictor.LRUCacheEvictor`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_EVICTOR_CLASS =\n      new Builder(Name.USER_CLIENT_CACHE_EVICTOR_CLASS)\n          .setDefaultValue(\"alluxio.client.file.cache.evictor.LRUCacheEvictor\")\n          .setDescription(\"The strategy that client uses to evict local cached pages when running \"\n              + \"out of space. Currently the only valid option provided is \"\n              + \"`alluxio.client.file.cache.evictor.LRUCacheEvictor`.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_EVICTOR_CLASS"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_EVICTOR_LFU_LOGBASE =\n      new Builder(Name.USER_CLIENT_CACHE_EVICTOR_LFU_LOGBASE)\n          .setDefaultValue(2.0)\n          .setDescription(\"The log base for client cache LFU evictor bucket index.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_EVICTOR_LFU_LOGBASE =\n      new Builder(Name.USER_CLIENT_CACHE_EVICTOR_LFU_LOGBASE)\n          .setDefaultValue(2.0)\n          .setDescription(\"The log base for client cache LFU evictor bucket index.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_EVICTOR_LFU_LOGBASE"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_DIR =\n      new Builder(Name.USER_CLIENT_CACHE_DIR)\n          .setDefaultValue(\"/tmp/alluxio_cache\")\n          .setDescription(\"The directory where client-side cache is stored.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_DIR =\n      new Builder(Name.USER_CLIENT_CACHE_DIR)\n          .setDefaultValue(\"/tmp/alluxio_cache\")\n          .setDescription(\"The directory where client-side cache is stored.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_DIR"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_STORE_TYPE =\n      new Builder(Name.USER_CLIENT_CACHE_STORE_TYPE)\n          .setDefaultValue(\"LOCAL\")\n          .setDescription(\"The type of page store to use for client-side cache. Can be either \"\n              + \"`LOCAL` or `ROCKS`. The `LOCAL` page store stores all pages in a directory, \"\n              + \"the `ROCKS` page store utilizes rocksDB to persist the data.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_STORE_TYPE =\n      new Builder(Name.USER_CLIENT_CACHE_STORE_TYPE)\n          .setDefaultValue(\"LOCAL\")\n          .setDescription(\"The type of page store to use for client-side cache. Can be either \"\n              + \"`LOCAL` or `ROCKS`. The `LOCAL` page store stores all pages in a directory, \"\n              + \"the `ROCKS` page store utilizes rocksDB to persist the data.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_STORE_TYPE"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_LOCAL_STORE_FILE_BUCKETS =\n      new Builder(Name.USER_CLIENT_CACHE_LOCAL_STORE_FILE_BUCKETS)\n          .setDefaultValue(\"1000\")\n          .setDescription(\"The number of file buckets for the local page store of the client-side \"\n              + \"cache. It is recommended to set this to a high value if the number of unique \"\n              + \"files is expected to be high (# files / file buckets <= 100,000).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_LOCAL_STORE_FILE_BUCKETS =\n      new Builder(Name.USER_CLIENT_CACHE_LOCAL_STORE_FILE_BUCKETS)\n          .setDefaultValue(\"1000\")\n          .setDescription(\"The number of file buckets for the local page store of the client-side \"\n              + \"cache. It is recommended to set this to a high value if the number of unique \"\n              + \"files is expected to be high (# files / file buckets <= 100,000).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_LOCAL_STORE_FILE_BUCKETS"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_SIZE =\n      new Builder(Name.USER_CLIENT_CACHE_SIZE)\n          .setDefaultValue(\"512MB\")\n          .setDescription(\"The maximum size of the client-side cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_SIZE =\n      new Builder(Name.USER_CLIENT_CACHE_SIZE)\n          .setDefaultValue(\"512MB\")\n          .setDescription(\"The maximum size of the client-side cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_SIZE"}, {"original_string": "public static final PropertyKey USER_CLIENT_CACHE_PAGE_SIZE =\n      new Builder(Name.USER_CLIENT_CACHE_PAGE_SIZE)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"Size of each page in client-side cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_CLIENT_CACHE_PAGE_SIZE =\n      new Builder(Name.USER_CLIENT_CACHE_PAGE_SIZE)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"Size of each page in client-side cache.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_CLIENT_CACHE_PAGE_SIZE"}, {"original_string": "public static final PropertyKey USER_FILE_WRITE_TYPE_DEFAULT =\n      new Builder(Name.USER_FILE_WRITE_TYPE_DEFAULT)\n          .setDefaultValue(\"ASYNC_THROUGH\")\n      .setDescription(\n          String.format(\"Default write type when creating Alluxio files. Valid \" + \"options are \"\n              + \"`MUST_CACHE` (write will only go to Alluxio and must be stored in Alluxio), \"\n              + \"`CACHE_THROUGH` (try to cache, write to UnderFS synchronously), `THROUGH` \"\n              + \"(no cache, write to UnderFS synchronously), `ASYNC_THROUGH` (write to cache, \"\n              + \"write to UnderFS asynchronously, replicated %s times in Alluxio before data is \"\n              + \"persisted.\", USER_FILE_REPLICATION_DURABLE))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_WRITE_TYPE_DEFAULT =\n      new Builder(Name.USER_FILE_WRITE_TYPE_DEFAULT)\n          .setDefaultValue(\"ASYNC_THROUGH\")\n      .setDescription(\n          String.format(\"Default write type when creating Alluxio files. Valid \" + \"options are \"\n              + \"`MUST_CACHE` (write will only go to Alluxio and must be stored in Alluxio), \"\n              + \"`CACHE_THROUGH` (try to cache, write to UnderFS synchronously), `THROUGH` \"\n              + \"(no cache, write to UnderFS synchronously), `ASYNC_THROUGH` (write to cache, \"\n              + \"write to UnderFS asynchronously, replicated %s times in Alluxio before data is \"\n              + \"persisted.\", USER_FILE_REPLICATION_DURABLE))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_WRITE_TYPE_DEFAULT"}, {"original_string": "public static final PropertyKey USER_HOSTNAME = new Builder(Name.USER_HOSTNAME)\n      .setDescription(\"The hostname to use for an Alluxio client.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n      .setScope(Scope.CLIENT)\n      .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_HOSTNAME = new Builder(Name.USER_HOSTNAME)\n      .setDescription(\"The hostname to use for an Alluxio client.\")\n      .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n      .setScope(Scope.CLIENT)\n      .build()", "var_name": "USER_HOSTNAME"}, {"original_string": "public static final PropertyKey USER_FILE_WRITE_TIER_DEFAULT =\n      new Builder(Name.USER_FILE_WRITE_TIER_DEFAULT)\n          .setDefaultValue(Constants.FIRST_TIER)\n          .setDescription(\"The default tier for choosing a where to write a block. Valid \"\n              + \"option is any integer. Non-negative values identify tiers starting from top \"\n              + \"going down (0 identifies the first tier, 1 identifies the second tier, and \"\n              + \"so on). If the provided value is greater than the number of tiers, it \"\n              + \"identifies the last tier. Negative values identify tiers starting from the \"\n              + \"bottom going up (-1 identifies the last tier, -2 identifies the second to \"\n              + \"last tier, and so on). If the absolute value of the provided value is \"\n              + \"greater than the number of tiers, it identifies the first tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_FILE_WRITE_TIER_DEFAULT =\n      new Builder(Name.USER_FILE_WRITE_TIER_DEFAULT)\n          .setDefaultValue(Constants.FIRST_TIER)\n          .setDescription(\"The default tier for choosing a where to write a block. Valid \"\n              + \"option is any integer. Non-negative values identify tiers starting from top \"\n              + \"going down (0 identifies the first tier, 1 identifies the second tier, and \"\n              + \"so on). If the provided value is greater than the number of tiers, it \"\n              + \"identifies the last tier. Negative values identify tiers starting from the \"\n              + \"bottom going up (-1 identifies the last tier, -2 identifies the second to \"\n              + \"last tier, and so on). If the absolute value of the provided value is \"\n              + \"greater than the number of tiers, it identifies the first tier.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_FILE_WRITE_TIER_DEFAULT"}, {"original_string": "public static final PropertyKey USER_LOCAL_READER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_LOCAL_READER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"8MB\")\n          .setDescription(\"When a client reads from a local worker, the maximum data chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_LOCAL_READER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_LOCAL_READER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"8MB\")\n          .setDescription(\"When a client reads from a local worker, the maximum data chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_LOCAL_READER_CHUNK_SIZE_BYTES"}, {"original_string": "public static final PropertyKey USER_LOCAL_WRITER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_LOCAL_WRITER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"64KB\")\n          .setDescription(\"When a client writes to a local worker, the maximum data chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_LOCAL_WRITER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_LOCAL_WRITER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"64KB\")\n          .setDescription(\"When a client writes to a local worker, the maximum data chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_LOCAL_WRITER_CHUNK_SIZE_BYTES"}, {"original_string": "public static final PropertyKey USER_LOGGING_THRESHOLD =\n      new Builder(Name.USER_LOGGING_THRESHOLD)\n          .setDefaultValue(\"10s\")\n          .setDescription(\"Logging a client RPC when it takes more time than the threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_LOGGING_THRESHOLD =\n      new Builder(Name.USER_LOGGING_THRESHOLD)\n          .setDefaultValue(\"10s\")\n          .setDescription(\"Logging a client RPC when it takes more time than the threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_LOGGING_THRESHOLD"}, {"original_string": "public static final PropertyKey USER_MASTER_POLLING_TIMEOUT =\n      new Builder(Name.USER_MASTER_POLLING_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a rpc client to wait for master to respond.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_MASTER_POLLING_TIMEOUT =\n      new Builder(Name.USER_MASTER_POLLING_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a rpc client to wait for master to respond.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_MASTER_POLLING_TIMEOUT"}, {"original_string": "public static final PropertyKey USER_METADATA_CACHE_ENABLED =\n      new Builder(Name.USER_METADATA_CACHE_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"If this is enabled, metadata of paths will be cached. \"\n              + \"The cached metadata will be evicted when it expires after \"\n              + Name.USER_METADATA_CACHE_EXPIRATION_TIME\n              + \" or the cache size is over the limit of \"\n              + Name.USER_METADATA_CACHE_MAX_SIZE + \".\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_METADATA_CACHE_ENABLED =\n      new Builder(Name.USER_METADATA_CACHE_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"If this is enabled, metadata of paths will be cached. \"\n              + \"The cached metadata will be evicted when it expires after \"\n              + Name.USER_METADATA_CACHE_EXPIRATION_TIME\n              + \" or the cache size is over the limit of \"\n              + Name.USER_METADATA_CACHE_MAX_SIZE + \".\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_METADATA_CACHE_ENABLED"}, {"original_string": "public static final PropertyKey USER_METADATA_CACHE_MAX_SIZE =\n      new Builder(Name.USER_METADATA_CACHE_MAX_SIZE)\n          .setDefaultValue(100000)\n          .setDescription(\"Maximum number of paths with cached metadata. Only valid if the \"\n              + \"filesystem is alluxio.client.file.MetadataCachingBaseFileSystem.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_METADATA_CACHE_MAX_SIZE =\n      new Builder(Name.USER_METADATA_CACHE_MAX_SIZE)\n          .setDefaultValue(100000)\n          .setDescription(\"Maximum number of paths with cached metadata. Only valid if the \"\n              + \"filesystem is alluxio.client.file.MetadataCachingBaseFileSystem.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_METADATA_CACHE_MAX_SIZE"}, {"original_string": "public static final PropertyKey USER_METADATA_CACHE_EXPIRATION_TIME =\n      new Builder(Name.USER_METADATA_CACHE_EXPIRATION_TIME)\n          .setDefaultValue(\"10min\")\n          .setDescription(\"Metadata will expire and be evicted after being cached for this time \"\n              + \"period. Only valid if the filesystem is \"\n              + \"alluxio.client.file.MetadataCachingBaseFileSystem.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_METADATA_CACHE_EXPIRATION_TIME =\n      new Builder(Name.USER_METADATA_CACHE_EXPIRATION_TIME)\n          .setDefaultValue(\"10min\")\n          .setDescription(\"Metadata will expire and be evicted after being cached for this time \"\n              + \"period. Only valid if the filesystem is \"\n              + \"alluxio.client.file.MetadataCachingBaseFileSystem.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_METADATA_CACHE_EXPIRATION_TIME"}, {"original_string": "public static final PropertyKey USER_METRICS_COLLECTION_ENABLED =\n      new Builder(Name.USER_METRICS_COLLECTION_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Enable collecting the client-side metrics and heartbeat them to master\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_METRICS_COLLECTION_ENABLED =\n      new Builder(Name.USER_METRICS_COLLECTION_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Enable collecting the client-side metrics and heartbeat them to master\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_METRICS_COLLECTION_ENABLED"}, {"original_string": "public static final PropertyKey USER_METRICS_HEARTBEAT_INTERVAL_MS =\n      new Builder(Name.USER_METRICS_HEARTBEAT_INTERVAL_MS)\n          .setAlias(\"alluxio.user.metrics.heartbeat.interval.ms\")\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The time period of client master heartbeat to \"\n              + \"send the client-side metrics.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_METRICS_HEARTBEAT_INTERVAL_MS =\n      new Builder(Name.USER_METRICS_HEARTBEAT_INTERVAL_MS)\n          .setAlias(\"alluxio.user.metrics.heartbeat.interval.ms\")\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"The time period of client master heartbeat to \"\n              + \"send the client-side metrics.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_METRICS_HEARTBEAT_INTERVAL_MS"}, {"original_string": "public static final PropertyKey USER_APP_ID =\n      new Builder(Name.USER_APP_ID)\n          .setScope(Scope.CLIENT)\n          .setDescription(\"The custom id to use for labeling this client's info, such as metrics. \"\n              + \"If unset, a random long will be used. This value is displayed in the client logs \"\n              + \"on initialization. Note that using the same app id will cause client info to be \"\n              + \"aggregated, so different applications must set their own ids or leave this value \"\n              + \"unset to use a randomly generated id.\")\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_APP_ID =\n      new Builder(Name.USER_APP_ID)\n          .setScope(Scope.CLIENT)\n          .setDescription(\"The custom id to use for labeling this client's info, such as metrics. \"\n              + \"If unset, a random long will be used. This value is displayed in the client logs \"\n              + \"on initialization. Note that using the same app id will cause client info to be \"\n              + \"aggregated, so different applications must set their own ids or leave this value \"\n              + \"unset to use a randomly generated id.\")\n          .build()", "var_name": "USER_APP_ID"}, {"original_string": "public static final PropertyKey USER_STREAMING_DATA_TIMEOUT =\n      new Builder(Name.USER_STREAMING_DATA_TIMEOUT)\n          .setAlias(\"alluxio.user.network.data.timeout.ms\", Name.USER_NETWORK_DATA_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for an Alluxio client to wait for a data response \"\n              + \"(e.g. block reads and block writes) from Alluxio worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_DATA_TIMEOUT =\n      new Builder(Name.USER_STREAMING_DATA_TIMEOUT)\n          .setAlias(\"alluxio.user.network.data.timeout.ms\", Name.USER_NETWORK_DATA_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for an Alluxio client to wait for a data response \"\n              + \"(e.g. block reads and block writes) from Alluxio worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_DATA_TIMEOUT"}, {"original_string": "public static final PropertyKey USER_STREAMING_READER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_STREAMING_READER_BUFFER_SIZE_MESSAGES)\n          .setAlias(Name.USER_NETWORK_READER_BUFFER_SIZE_MESSAGES)\n          .setDefaultValue(16)\n          .setDescription(\"When a client reads from a remote worker, the maximum number of \"\n              + \"messages to buffer by the client. A message can be either a command response, \"\n              + \"a data chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_READER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_STREAMING_READER_BUFFER_SIZE_MESSAGES)\n          .setAlias(Name.USER_NETWORK_READER_BUFFER_SIZE_MESSAGES)\n          .setDefaultValue(16)\n          .setDescription(\"When a client reads from a remote worker, the maximum number of \"\n              + \"messages to buffer by the client. A message can be either a command response, \"\n              + \"a data chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_READER_BUFFER_SIZE_MESSAGES"}, {"original_string": "public static final PropertyKey USER_STREAMING_READER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_STREAMING_READER_CHUNK_SIZE_BYTES)\n          .setAlias(Name.USER_NETWORK_READER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"When a client reads from a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_READER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_STREAMING_READER_CHUNK_SIZE_BYTES)\n          .setAlias(Name.USER_NETWORK_READER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"When a client reads from a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_READER_CHUNK_SIZE_BYTES"}, {"original_string": "public static final PropertyKey USER_STREAMING_WRITER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_STREAMING_WRITER_BUFFER_SIZE_MESSAGES)\n          .setAlias(Name.USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES)\n          .setDefaultValue(16)\n          .setDescription(\"When a client writes to a remote worker, the maximum number of messages \"\n              + \"to buffer by the client. A message can be either a command response, a data \"\n              + \"chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_WRITER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_STREAMING_WRITER_BUFFER_SIZE_MESSAGES)\n          .setAlias(Name.USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES)\n          .setDefaultValue(16)\n          .setDescription(\"When a client writes to a remote worker, the maximum number of messages \"\n              + \"to buffer by the client. A message can be either a command response, a data \"\n              + \"chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_WRITER_BUFFER_SIZE_MESSAGES"}, {"original_string": "public static final PropertyKey USER_STREAMING_WRITER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_STREAMING_WRITER_CHUNK_SIZE_BYTES)\n          .setAlias(Name.USER_NETWORK_WRITER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"When a client writes to a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_WRITER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_STREAMING_WRITER_CHUNK_SIZE_BYTES)\n          .setAlias(Name.USER_NETWORK_WRITER_CHUNK_SIZE_BYTES)\n          .setDefaultValue(\"1MB\")\n          .setDescription(\"When a client writes to a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_WRITER_CHUNK_SIZE_BYTES"}, {"original_string": "public static final PropertyKey USER_STREAMING_WRITER_CLOSE_TIMEOUT =\n      new Builder(Name.USER_STREAMING_WRITER_CLOSE_TIMEOUT)\n          .setAlias(\"alluxio.user.network.writer.close.timeout.ms\",\n              Name.USER_NETWORK_WRITER_CLOSE_TIMEOUT)\n          .setDefaultValue(\"30min\")\n          .setDescription(\"The timeout to close a writer client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_WRITER_CLOSE_TIMEOUT =\n      new Builder(Name.USER_STREAMING_WRITER_CLOSE_TIMEOUT)\n          .setAlias(\"alluxio.user.network.writer.close.timeout.ms\",\n              Name.USER_NETWORK_WRITER_CLOSE_TIMEOUT)\n          .setDefaultValue(\"30min\")\n          .setDescription(\"The timeout to close a writer client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_WRITER_CLOSE_TIMEOUT"}, {"original_string": "public static final PropertyKey USER_STREAMING_WRITER_FLUSH_TIMEOUT =\n      new Builder(Name.USER_STREAMING_WRITER_FLUSH_TIMEOUT)\n          .setAlias(Name.USER_NETWORK_WRITER_FLUSH_TIMEOUT)\n          .setDefaultValue(\"30min\")\n          .setDescription(\"The timeout to wait for flush to finish in a data writer.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_WRITER_FLUSH_TIMEOUT =\n      new Builder(Name.USER_STREAMING_WRITER_FLUSH_TIMEOUT)\n          .setAlias(Name.USER_NETWORK_WRITER_FLUSH_TIMEOUT)\n          .setDefaultValue(\"30min\")\n          .setDescription(\"The timeout to wait for flush to finish in a data writer.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_WRITER_FLUSH_TIMEOUT"}, {"original_string": "public static final PropertyKey USER_STREAMING_ZEROCOPY_ENABLED =\n      new Builder(Name.USER_STREAMING_ZEROCOPY_ENABLED)\n          .setAlias(Name.USER_NETWORK_ZEROCOPY_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether zero copy is enabled on client when processing data streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_STREAMING_ZEROCOPY_ENABLED =\n      new Builder(Name.USER_STREAMING_ZEROCOPY_ENABLED)\n          .setAlias(Name.USER_NETWORK_ZEROCOPY_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether zero copy is enabled on client when processing data streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_STREAMING_ZEROCOPY_ENABLED"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_DATA_TIMEOUT_MS =\n      new Builder(Name.USER_NETWORK_DATA_TIMEOUT)\n          .setAlias(\"alluxio.user.network.data.timeout.ms\")\n          .setDescription(\"The maximum time for an Alluxio client to wait for a data response \"\n              + \"(e.g. block reads and block writes) from Alluxio worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_DATA_TIMEOUT_MS =\n      new Builder(Name.USER_NETWORK_DATA_TIMEOUT)\n          .setAlias(\"alluxio.user.network.data.timeout.ms\")\n          .setDescription(\"The maximum time for an Alluxio client to wait for a data response \"\n              + \"(e.g. block reads and block writes) from Alluxio worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_DATA_TIMEOUT_MS"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_READER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_NETWORK_READER_BUFFER_SIZE_MESSAGES)\n          .setDescription(\"When a client reads from a remote worker, the maximum number of \"\n              + \"messages to buffer by the client. A message can be either a command response, \"\n              + \"a data chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_READER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_NETWORK_READER_BUFFER_SIZE_MESSAGES)\n          .setDescription(\"When a client reads from a remote worker, the maximum number of \"\n              + \"messages to buffer by the client. A message can be either a command response, \"\n              + \"a data chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_READER_BUFFER_SIZE_MESSAGES"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_READER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_NETWORK_READER_CHUNK_SIZE_BYTES)\n          .setDescription(\"When a client reads from a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_READER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_NETWORK_READER_CHUNK_SIZE_BYTES)\n          .setDescription(\"When a client reads from a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_READER_CHUNK_SIZE_BYTES"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES)\n          .setDescription(\"When a client writes to a remote worker, the maximum number of messages \"\n              + \"to buffer by the client. A message can be either a command response, a data \"\n              + \"chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES =\n      new Builder(Name.USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES)\n          .setDescription(\"When a client writes to a remote worker, the maximum number of messages \"\n              + \"to buffer by the client. A message can be either a command response, a data \"\n              + \"chunk, or a gRPC stream event such as complete or error.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_WRITER_BUFFER_SIZE_MESSAGES"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_WRITER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_NETWORK_WRITER_CHUNK_SIZE_BYTES)\n          .setDescription(\"When a client writes to a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_WRITER_CHUNK_SIZE_BYTES =\n      new Builder(Name.USER_NETWORK_WRITER_CHUNK_SIZE_BYTES)\n          .setDescription(\"When a client writes to a remote worker, the maximum chunk size.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_WRITER_CHUNK_SIZE_BYTES"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_WRITER_CLOSE_TIMEOUT_MS =\n      new Builder(Name.USER_NETWORK_WRITER_CLOSE_TIMEOUT)\n          .setAlias(\"alluxio.user.network.writer.close.timeout.ms\")\n          .setDescription(\"The timeout to close a writer client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_WRITER_CLOSE_TIMEOUT_MS =\n      new Builder(Name.USER_NETWORK_WRITER_CLOSE_TIMEOUT)\n          .setAlias(\"alluxio.user.network.writer.close.timeout.ms\")\n          .setDescription(\"The timeout to close a writer client.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_WRITER_CLOSE_TIMEOUT_MS"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_WRITER_FLUSH_TIMEOUT =\n      new Builder(Name.USER_NETWORK_WRITER_FLUSH_TIMEOUT)\n          .setDescription(\"The timeout to wait for flush to finish in a data writer.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_WRITER_FLUSH_TIMEOUT =\n      new Builder(Name.USER_NETWORK_WRITER_FLUSH_TIMEOUT)\n          .setDescription(\"The timeout to wait for flush to finish in a data writer.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_WRITER_FLUSH_TIMEOUT"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_ZEROCOPY_ENABLED =\n      new Builder(Name.USER_NETWORK_ZEROCOPY_ENABLED)\n          .setDescription(\"Whether zero copy is enabled on client when processing data streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_ZEROCOPY_ENABLED =\n      new Builder(Name.USER_NETWORK_ZEROCOPY_ENABLED)\n          .setDescription(\"Whether zero copy is enabled on client when processing data streams.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_ZEROCOPY_ENABLED"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_FLOWCONTROL_WINDOW =\n      new Builder(Name.USER_NETWORK_FLOWCONTROL_WINDOW)\n          .setDescription(\"The HTTP2 flow control window used by user gRPC connections. Larger \"\n              + \"value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_FLOWCONTROL_WINDOW =\n      new Builder(Name.USER_NETWORK_FLOWCONTROL_WINDOW)\n          .setDescription(\"The HTTP2 flow control window used by user gRPC connections. Larger \"\n              + \"value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_FLOWCONTROL_WINDOW"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_KEEPALIVE_TIME =\n      new Builder(Name.USER_NETWORK_KEEPALIVE_TIME)\n          .setDescription(\"The amount of time for a gRPC client (for block reads and block writes) \"\n              + \"to wait for a response before pinging the server to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_KEEPALIVE_TIME =\n      new Builder(Name.USER_NETWORK_KEEPALIVE_TIME)\n          .setDescription(\"The amount of time for a gRPC client (for block reads and block writes) \"\n              + \"to wait for a response before pinging the server to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_KEEPALIVE_TIME"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_KEEPALIVE_TIMEOUT =\n      new Builder(Name.USER_NETWORK_KEEPALIVE_TIMEOUT)\n          .setDescription(\"The maximum time for a gRPC client (for block reads and block writes) \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_KEEPALIVE_TIMEOUT =\n      new Builder(Name.USER_NETWORK_KEEPALIVE_TIMEOUT)\n          .setDescription(\"The maximum time for a gRPC client (for block reads and block writes) \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_KEEPALIVE_TIMEOUT"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDescription(\"The max inbound message size used by user gRPC connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDescription(\"The max inbound message size used by user gRPC connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_NETTY_CHANNEL =\n      new Builder(Name.USER_NETWORK_NETTY_CHANNEL)\n          .setDescription(\"Type of netty channels. If EPOLL is not available, this will \"\n              + \"automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_NETTY_CHANNEL =\n      new Builder(Name.USER_NETWORK_NETTY_CHANNEL)\n          .setDescription(\"Type of netty channels. If EPOLL is not available, this will \"\n              + \"automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_NETTY_CHANNEL"}, {"original_string": "@Deprecated\n  public static final PropertyKey USER_NETWORK_NETTY_WORKER_THREADS =\n      new Builder(Name.USER_NETWORK_NETTY_WORKER_THREADS)\n          .setDescription(\"How many threads to use for remote block worker client to read \"\n              + \"from remote block workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "@Deprecated\n  public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_NETTY_WORKER_THREADS =\n      new Builder(Name.USER_NETWORK_NETTY_WORKER_THREADS)\n          .setDescription(\"How many threads to use for remote block worker client to read \"\n              + \"from remote block workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_NETTY_WORKER_THREADS"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_FLOWCONTROL_WINDOW =\n      new Builder(Name.USER_NETWORK_RPC_FLOWCONTROL_WINDOW)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"The HTTP2 flow control window used by user rpc connections. \"\n              + \"Larger value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_FLOWCONTROL_WINDOW =\n      new Builder(Name.USER_NETWORK_RPC_FLOWCONTROL_WINDOW)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"The HTTP2 flow control window used by user rpc connections. \"\n              + \"Larger value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_RPC_FLOWCONTROL_WINDOW"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_KEEPALIVE_TIME =\n      new Builder(Name.USER_NETWORK_RPC_KEEPALIVE_TIME)\n          .setDefaultValue(Long.MAX_VALUE)\n          .setDescription(\"The amount of time for a rpc client \"\n              + \"to wait for a response before pinging the server to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_KEEPALIVE_TIME =\n      new Builder(Name.USER_NETWORK_RPC_KEEPALIVE_TIME)\n          .setDefaultValue(Long.MAX_VALUE)\n          .setDescription(\"The amount of time for a rpc client \"\n              + \"to wait for a response before pinging the server to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_RPC_KEEPALIVE_TIME"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_KEEPALIVE_TIMEOUT =\n      new Builder(Name.USER_NETWORK_RPC_KEEPALIVE_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a rpc client \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_KEEPALIVE_TIMEOUT =\n      new Builder(Name.USER_NETWORK_RPC_KEEPALIVE_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a rpc client \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_RPC_KEEPALIVE_TIMEOUT"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.USER_NETWORK_RPC_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The max inbound message size used by user rpc connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.USER_NETWORK_RPC_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The max inbound message size used by user rpc connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_RPC_MAX_INBOUND_MESSAGE_SIZE"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_NETTY_CHANNEL =\n      new Builder(Name.USER_NETWORK_RPC_NETTY_CHANNEL)\n          .setDescription(\"Type of netty channels used by rpc connections. \"\n              + \"If EPOLL is not available, this will automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setDefaultValue(\"EPOLL\")\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_NETTY_CHANNEL =\n      new Builder(Name.USER_NETWORK_RPC_NETTY_CHANNEL)\n          .setDescription(\"Type of netty channels used by rpc connections. \"\n              + \"If EPOLL is not available, this will automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setDefaultValue(\"EPOLL\")\n          .build()", "var_name": "USER_NETWORK_RPC_NETTY_CHANNEL"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_NETTY_WORKER_THREADS =\n      new Builder(Name.USER_NETWORK_RPC_NETTY_WORKER_THREADS)\n          .setDefaultValue(0)\n          .setDescription(\"How many threads to use for rpc client to read \"\n              + \"from remote workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_NETTY_WORKER_THREADS =\n      new Builder(Name.USER_NETWORK_RPC_NETTY_WORKER_THREADS)\n          .setDefaultValue(0)\n          .setDescription(\"How many threads to use for rpc client to read \"\n              + \"from remote workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_RPC_NETTY_WORKER_THREADS"}, {"original_string": "public static final PropertyKey USER_NETWORK_RPC_MAX_CONNECTIONS =\n      new Builder(Name.USER_NETWORK_RPC_MAX_CONNECTIONS)\n          .setDefaultValue(1)\n          .setDescription(\n              \"The maximum number of physical connections to be \"\n              + \"used per target host.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_RPC_MAX_CONNECTIONS =\n      new Builder(Name.USER_NETWORK_RPC_MAX_CONNECTIONS)\n          .setDefaultValue(1)\n          .setDescription(\n              \"The maximum number of physical connections to be \"\n              + \"used per target host.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_RPC_MAX_CONNECTIONS"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_FLOWCONTROL_WINDOW =\n      new Builder(Name.USER_NETWORK_STREAMING_FLOWCONTROL_WINDOW)\n          .setAlias(Name.USER_NETWORK_FLOWCONTROL_WINDOW)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"The HTTP2 flow control window used by user streaming connections. \"\n              + \"Larger value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_FLOWCONTROL_WINDOW =\n      new Builder(Name.USER_NETWORK_STREAMING_FLOWCONTROL_WINDOW)\n          .setAlias(Name.USER_NETWORK_FLOWCONTROL_WINDOW)\n          .setDefaultValue(\"2MB\")\n          .setDescription(\"The HTTP2 flow control window used by user streaming connections. \"\n              + \"Larger value will allow more data to be buffered but will use more memory.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_STREAMING_FLOWCONTROL_WINDOW"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_KEEPALIVE_TIME =\n      new Builder(Name.USER_NETWORK_STREAMING_KEEPALIVE_TIME)\n          .setAlias(Name.USER_NETWORK_KEEPALIVE_TIME)\n          .setDefaultValue(Long.MAX_VALUE)\n          .setDescription(\"The amount of time for a streaming client \"\n              + \"to wait for a response before pinging the server to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_KEEPALIVE_TIME =\n      new Builder(Name.USER_NETWORK_STREAMING_KEEPALIVE_TIME)\n          .setAlias(Name.USER_NETWORK_KEEPALIVE_TIME)\n          .setDefaultValue(Long.MAX_VALUE)\n          .setDescription(\"The amount of time for a streaming client \"\n              + \"to wait for a response before pinging the server to see if it is still alive.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_STREAMING_KEEPALIVE_TIME"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_KEEPALIVE_TIMEOUT =\n      new Builder(Name.USER_NETWORK_STREAMING_KEEPALIVE_TIMEOUT)\n          .setAlias(Name.USER_NETWORK_KEEPALIVE_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a streaming client \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_KEEPALIVE_TIMEOUT =\n      new Builder(Name.USER_NETWORK_STREAMING_KEEPALIVE_TIMEOUT)\n          .setAlias(Name.USER_NETWORK_KEEPALIVE_TIMEOUT)\n          .setDefaultValue(\"30sec\")\n          .setDescription(\"The maximum time for a streaming client \"\n              + \"to wait for a keepalive response before closing the connection.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_STREAMING_KEEPALIVE_TIMEOUT"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.USER_NETWORK_STREAMING_MAX_INBOUND_MESSAGE_SIZE)\n          .setAlias(Name.USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The max inbound message size used by user streaming connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_MAX_INBOUND_MESSAGE_SIZE =\n      new Builder(Name.USER_NETWORK_STREAMING_MAX_INBOUND_MESSAGE_SIZE)\n          .setAlias(Name.USER_NETWORK_MAX_INBOUND_MESSAGE_SIZE)\n          .setDefaultValue(\"100MB\")\n          .setDescription(\"The max inbound message size used by user streaming connections.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_STREAMING_MAX_INBOUND_MESSAGE_SIZE"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_NETTY_CHANNEL =\n      new Builder(Name.USER_NETWORK_STREAMING_NETTY_CHANNEL)\n          .setAlias(Name.USER_NETWORK_NETTY_CHANNEL)\n          .setDescription(\"Type of netty channels used by streaming connections. \"\n              + \"If EPOLL is not available, this will automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setDefaultValue(\"EPOLL\")\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_NETTY_CHANNEL =\n      new Builder(Name.USER_NETWORK_STREAMING_NETTY_CHANNEL)\n          .setAlias(Name.USER_NETWORK_NETTY_CHANNEL)\n          .setDescription(\"Type of netty channels used by streaming connections. \"\n              + \"If EPOLL is not available, this will automatically fall back to NIO.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .setDefaultValue(\"EPOLL\")\n          .build()", "var_name": "USER_NETWORK_STREAMING_NETTY_CHANNEL"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_NETTY_WORKER_THREADS =\n      new Builder(Name.USER_NETWORK_STREAMING_NETTY_WORKER_THREADS)\n          .setAlias(Name.USER_NETWORK_NETTY_WORKER_THREADS)\n          .setDefaultValue(0)\n          .setDescription(\"How many threads to use for streaming client to read \"\n              + \"from remote workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_NETTY_WORKER_THREADS =\n      new Builder(Name.USER_NETWORK_STREAMING_NETTY_WORKER_THREADS)\n          .setAlias(Name.USER_NETWORK_NETTY_WORKER_THREADS)\n          .setDefaultValue(0)\n          .setDescription(\"How many threads to use for streaming client to read \"\n              + \"from remote workers.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_STREAMING_NETTY_WORKER_THREADS"}, {"original_string": "public static final PropertyKey USER_NETWORK_STREAMING_MAX_CONNECTIONS =\n      new Builder(Name.USER_NETWORK_STREAMING_MAX_CONNECTIONS)\n          .setDefaultValue(64)\n          .setDescription(\n              \"The maximum number of physical connections to be \"\n              + \"used per target host.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_NETWORK_STREAMING_MAX_CONNECTIONS =\n      new Builder(Name.USER_NETWORK_STREAMING_MAX_CONNECTIONS)\n          .setDefaultValue(64)\n          .setDescription(\n              \"The maximum number of physical connections to be \"\n              + \"used per target host.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_NETWORK_STREAMING_MAX_CONNECTIONS"}, {"original_string": "public static final PropertyKey USER_RPC_RETRY_BASE_SLEEP_MS =\n      new Builder(Name.USER_RPC_RETRY_BASE_SLEEP_MS)\n          .setAlias(\"alluxio.user.rpc.retry.base.sleep.ms\")\n          .setDefaultValue(\"50ms\")\n          .setDescription(\"Alluxio client RPCs automatically retry for transient errors with \"\n              + \"an exponential backoff. This property determines the base time \"\n              + \"in the exponential backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_RPC_RETRY_BASE_SLEEP_MS =\n      new Builder(Name.USER_RPC_RETRY_BASE_SLEEP_MS)\n          .setAlias(\"alluxio.user.rpc.retry.base.sleep.ms\")\n          .setDefaultValue(\"50ms\")\n          .setDescription(\"Alluxio client RPCs automatically retry for transient errors with \"\n              + \"an exponential backoff. This property determines the base time \"\n              + \"in the exponential backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_RPC_RETRY_BASE_SLEEP_MS"}, {"original_string": "public static final PropertyKey USER_RPC_RETRY_MAX_DURATION =\n      new Builder(Name.USER_RPC_RETRY_MAX_DURATION)\n          .setDefaultValue(\"2min\")\n          .setDescription(\"Alluxio client RPCs automatically retry for transient errors with \"\n              + \"an exponential backoff. This property determines the maximum duration to retry for\"\n              + \" before giving up. Note that, this value is set to 5s for fs and fsadmin CLIs.\")\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_RPC_RETRY_MAX_DURATION =\n      new Builder(Name.USER_RPC_RETRY_MAX_DURATION)\n          .setDefaultValue(\"2min\")\n          .setDescription(\"Alluxio client RPCs automatically retry for transient errors with \"\n              + \"an exponential backoff. This property determines the maximum duration to retry for\"\n              + \" before giving up. Note that, this value is set to 5s for fs and fsadmin CLIs.\")\n          .build()", "var_name": "USER_RPC_RETRY_MAX_DURATION"}, {"original_string": "public static final PropertyKey USER_WORKER_LIST_REFRESH_INTERVAL =\n      new Builder(Name.USER_WORKER_LIST_REFRESH_INTERVAL)\n          .setDefaultValue(\"2min\")\n          .setDescription(\"The interval used to refresh the live worker list on the client\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_WORKER_LIST_REFRESH_INTERVAL =\n      new Builder(Name.USER_WORKER_LIST_REFRESH_INTERVAL)\n          .setDefaultValue(\"2min\")\n          .setDescription(\"The interval used to refresh the live worker list on the client\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_WORKER_LIST_REFRESH_INTERVAL"}, {"original_string": "public static final PropertyKey USER_RPC_RETRY_MAX_SLEEP_MS =\n      new Builder(Name.USER_RPC_RETRY_MAX_SLEEP_MS)\n          .setAlias(\"alluxio.user.rpc.retry.max.sleep.ms\")\n          .setDefaultValue(\"3sec\")\n          .setDescription(\"Alluxio client RPCs automatically retry for transient errors with \"\n              + \"an exponential backoff. This property determines the maximum wait time \"\n              + \"in the backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_RPC_RETRY_MAX_SLEEP_MS =\n      new Builder(Name.USER_RPC_RETRY_MAX_SLEEP_MS)\n          .setAlias(\"alluxio.user.rpc.retry.max.sleep.ms\")\n          .setDefaultValue(\"3sec\")\n          .setDescription(\"Alluxio client RPCs automatically retry for transient errors with \"\n              + \"an exponential backoff. This property determines the maximum wait time \"\n              + \"in the backoff.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_RPC_RETRY_MAX_SLEEP_MS"}, {"original_string": "public static final PropertyKey USER_UFS_BLOCK_LOCATION_ALL_FALLBACK_ENABLED =\n      new Builder(Name.USER_UFS_BLOCK_LOCATION_ALL_FALLBACK_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to return all workers as block location if ufs block locations \"\n              + \"are not co-located with any Alluxio workers or is empty.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_UFS_BLOCK_LOCATION_ALL_FALLBACK_ENABLED =\n      new Builder(Name.USER_UFS_BLOCK_LOCATION_ALL_FALLBACK_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to return all workers as block location if ufs block locations \"\n              + \"are not co-located with any Alluxio workers or is empty.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_UFS_BLOCK_LOCATION_ALL_FALLBACK_ENABLED"}, {"original_string": "public static final PropertyKey USER_UFS_BLOCK_READ_LOCATION_POLICY =\n      new Builder(Name.USER_UFS_BLOCK_READ_LOCATION_POLICY)\n          .setDefaultValue(\"alluxio.client.block.policy.LocalFirstPolicy\")\n          .setDescription(String.format(\"When an Alluxio client reads a file from the UFS, it \"\n              + \"delegates the read to an Alluxio worker. The client uses this policy to choose \"\n              + \"which worker to read through. Built-in choices: %s.\", Arrays.asList(\n              javadocLink(\"alluxio.client.block.policy.DeterministicHashPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.LocalFirstAvoidEvictionPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.LocalFirstPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.MostAvailableFirstPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.RoundRobinPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.SpecificHostPolicy\"))))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_UFS_BLOCK_READ_LOCATION_POLICY =\n      new Builder(Name.USER_UFS_BLOCK_READ_LOCATION_POLICY)\n          .setDefaultValue(\"alluxio.client.block.policy.LocalFirstPolicy\")\n          .setDescription(String.format(\"When an Alluxio client reads a file from the UFS, it \"\n              + \"delegates the read to an Alluxio worker. The client uses this policy to choose \"\n              + \"which worker to read through. Built-in choices: %s.\", Arrays.asList(\n              javadocLink(\"alluxio.client.block.policy.DeterministicHashPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.LocalFirstAvoidEvictionPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.LocalFirstPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.MostAvailableFirstPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.RoundRobinPolicy\"),\n              javadocLink(\"alluxio.client.block.policy.SpecificHostPolicy\"))))\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_UFS_BLOCK_READ_LOCATION_POLICY"}, {"original_string": "public static final PropertyKey USER_UFS_BLOCK_READ_LOCATION_POLICY_DETERMINISTIC_HASH_SHARDS =\n      new Builder(Name.USER_UFS_BLOCK_READ_LOCATION_POLICY_DETERMINISTIC_HASH_SHARDS)\n          .setDefaultValue(1)\n          .setDescription(\"When alluxio.user.ufs.block.read.location.policy is set to \"\n              + \"alluxio.client.block.policy.DeterministicHashPolicy, this specifies the number of \"\n              + \"hash shards.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_UFS_BLOCK_READ_LOCATION_POLICY_DETERMINISTIC_HASH_SHARDS =\n      new Builder(Name.USER_UFS_BLOCK_READ_LOCATION_POLICY_DETERMINISTIC_HASH_SHARDS)\n          .setDefaultValue(1)\n          .setDescription(\"When alluxio.user.ufs.block.read.location.policy is set to \"\n              + \"alluxio.client.block.policy.DeterministicHashPolicy, this specifies the number of \"\n              + \"hash shards.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_UFS_BLOCK_READ_LOCATION_POLICY_DETERMINISTIC_HASH_SHARDS"}, {"original_string": "public static final PropertyKey USER_UFS_BLOCK_READ_CONCURRENCY_MAX =\n      new Builder(Name.USER_UFS_BLOCK_READ_CONCURRENCY_MAX)\n          .setDefaultValue(Integer.MAX_VALUE)\n          .setDescription(\"The maximum concurrent readers for one UFS block on one Block Worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_UFS_BLOCK_READ_CONCURRENCY_MAX =\n      new Builder(Name.USER_UFS_BLOCK_READ_CONCURRENCY_MAX)\n          .setDefaultValue(Integer.MAX_VALUE)\n          .setDescription(\"The maximum concurrent readers for one UFS block on one Block Worker.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_UFS_BLOCK_READ_CONCURRENCY_MAX"}, {"original_string": "public static final PropertyKey USER_SHORT_CIRCUIT_ENABLED =\n      new Builder(Name.USER_SHORT_CIRCUIT_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"The short circuit read/write which allows the clients to \"\n              + \"read/write data without going through Alluxio workers if the data is local \"\n              + \"is enabled if set to true.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_SHORT_CIRCUIT_ENABLED =\n      new Builder(Name.USER_SHORT_CIRCUIT_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"The short circuit read/write which allows the clients to \"\n              + \"read/write data without going through Alluxio workers if the data is local \"\n              + \"is enabled if set to true.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_SHORT_CIRCUIT_ENABLED"}, {"original_string": "public static final PropertyKey USER_SHORT_CIRCUIT_PREFERRED =\n      new Builder(Name.USER_SHORT_CIRCUIT_PREFERRED)\n          .setDefaultValue(false)\n          .setDescription(\"When short circuit and domain socket both enabled, \"\n              + \"prefer to use short circuit.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "USER_SHORT_CIRCUIT_PREFERRED =\n      new Builder(Name.USER_SHORT_CIRCUIT_PREFERRED)\n          .setDefaultValue(false)\n          .setDescription(\"When short circuit and domain socket both enabled, \"\n              + \"prefer to use short circuit.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "USER_SHORT_CIRCUIT_PREFERRED"}, {"original_string": "public static final PropertyKey FUSE_CACHED_PATHS_MAX =\n      new Builder(Name.FUSE_CACHED_PATHS_MAX)\n          .setDefaultValue(500)\n          .setDescription(\"Maximum number of Alluxio paths to cache for FUSE conversion.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "FUSE_CACHED_PATHS_MAX =\n      new Builder(Name.FUSE_CACHED_PATHS_MAX)\n          .setDefaultValue(500)\n          .setDescription(\"Maximum number of Alluxio paths to cache for FUSE conversion.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "FUSE_CACHED_PATHS_MAX"}, {"original_string": "public static final PropertyKey FUSE_DEBUG_ENABLED =\n      new Builder(Name.FUSE_DEBUG_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Run FUSE in debug mode, and have the fuse process log every FS request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "FUSE_DEBUG_ENABLED =\n      new Builder(Name.FUSE_DEBUG_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Run FUSE in debug mode, and have the fuse process log every FS request.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "FUSE_DEBUG_ENABLED"}, {"original_string": "public static final PropertyKey FUSE_FS_NAME =\n      new Builder(Name.FUSE_FS_NAME)\n          .setDefaultValue(\"alluxio-fuse\")\n          .setDescription(\"The FUSE file system name.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "FUSE_FS_NAME =\n      new Builder(Name.FUSE_FS_NAME)\n          .setDefaultValue(\"alluxio-fuse\")\n          .setDescription(\"The FUSE file system name.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "FUSE_FS_NAME"}, {"original_string": "public static final PropertyKey FUSE_LOGGING_THRESHOLD =\n      new Builder(Name.FUSE_LOGGING_THRESHOLD)\n          .setDefaultValue(\"10s\")\n          .setDescription(\"Logging a FUSE API call when it takes more time than the threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "FUSE_LOGGING_THRESHOLD =\n      new Builder(Name.FUSE_LOGGING_THRESHOLD)\n          .setDefaultValue(\"10s\")\n          .setDescription(\"Logging a FUSE API call when it takes more time than the threshold.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "FUSE_LOGGING_THRESHOLD"}, {"original_string": "public static final PropertyKey FUSE_MAXWRITE_BYTES =\n      new Builder(Name.FUSE_MAXWRITE_BYTES)\n          .setDefaultValue(\"128KB\")\n          .setDescription(\"Maximum granularity of write operations, capped by the kernel to 128KB \"\n              + \"max (as of Linux 3.16.0).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "FUSE_MAXWRITE_BYTES =\n      new Builder(Name.FUSE_MAXWRITE_BYTES)\n          .setDefaultValue(\"128KB\")\n          .setDescription(\"Maximum granularity of write operations, capped by the kernel to 128KB \"\n              + \"max (as of Linux 3.16.0).\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "FUSE_MAXWRITE_BYTES"}, {"original_string": "public static final PropertyKey FUSE_USER_GROUP_TRANSLATION_ENABLED =\n      new Builder(Name.FUSE_USER_GROUP_TRANSLATION_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to translate Alluxio users and groups \"\n              + \"into Unix users and groups when exposing Alluxio files through the FUSE API. \"\n              + \"When this property is set to false, the user and group for all FUSE files \"\n              + \"will match the user who started the alluxio-fuse process.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "FUSE_USER_GROUP_TRANSLATION_ENABLED =\n      new Builder(Name.FUSE_USER_GROUP_TRANSLATION_ENABLED)\n          .setDefaultValue(false)\n          .setDescription(\"Whether to translate Alluxio users and groups \"\n              + \"into Unix users and groups when exposing Alluxio files through the FUSE API. \"\n              + \"When this property is set to false, the user and group for all FUSE files \"\n              + \"will match the user who started the alluxio-fuse process.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "FUSE_USER_GROUP_TRANSLATION_ENABLED"}, {"original_string": "public static final PropertyKey SECURITY_AUTHENTICATION_CUSTOM_PROVIDER_CLASS =\n      new Builder(Name.SECURITY_AUTHENTICATION_CUSTOM_PROVIDER_CLASS)\n          .setDescription(\"The class to provide customized authentication implementation, \"\n              + \"when alluxio.security.authentication.type is set to CUSTOM. It must \"\n              + \"implement the interface \"\n              + \"'alluxio.security.authentication.AuthenticationProvider'.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_AUTHENTICATION_CUSTOM_PROVIDER_CLASS =\n      new Builder(Name.SECURITY_AUTHENTICATION_CUSTOM_PROVIDER_CLASS)\n          .setDescription(\"The class to provide customized authentication implementation, \"\n              + \"when alluxio.security.authentication.type is set to CUSTOM. It must \"\n              + \"implement the interface \"\n              + \"'alluxio.security.authentication.AuthenticationProvider'.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SECURITY_AUTHENTICATION_CUSTOM_PROVIDER_CLASS"}, {"original_string": "public static final PropertyKey SECURITY_AUTHENTICATION_TYPE =\n      new Builder(Name.SECURITY_AUTHENTICATION_TYPE)\n          .setDefaultValue(\"SIMPLE\")\n          .setDescription(\"The authentication mode. Currently three modes are supported: \"\n              + \"NOSASL, SIMPLE, CUSTOM. The default value SIMPLE indicates that a simple \"\n              + \"authentication is enabled. Server trusts whoever the client claims to be.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_AUTHENTICATION_TYPE =\n      new Builder(Name.SECURITY_AUTHENTICATION_TYPE)\n          .setDefaultValue(\"SIMPLE\")\n          .setDescription(\"The authentication mode. Currently three modes are supported: \"\n              + \"NOSASL, SIMPLE, CUSTOM. The default value SIMPLE indicates that a simple \"\n              + \"authentication is enabled. Server trusts whoever the client claims to be.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SECURITY_AUTHENTICATION_TYPE"}, {"original_string": "public static final PropertyKey SECURITY_AUTHORIZATION_PERMISSION_ENABLED =\n      new Builder(Name.SECURITY_AUTHORIZATION_PERMISSION_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to enable access control based on file permission.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_AUTHORIZATION_PERMISSION_ENABLED =\n      new Builder(Name.SECURITY_AUTHORIZATION_PERMISSION_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to enable access control based on file permission.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SECURITY_AUTHORIZATION_PERMISSION_ENABLED"}, {"original_string": "public static final PropertyKey SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP =\n      new Builder(Name.SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP)\n          .setDefaultValue(\"supergroup\")\n          .setDescription(\"The super group of Alluxio file system. All users in this group \"\n              + \"have super permission.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP =\n      new Builder(Name.SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP)\n          .setDefaultValue(\"supergroup\")\n          .setDescription(\"The super group of Alluxio file system. All users in this group \"\n              + \"have super permission.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP"}, {"original_string": "public static final PropertyKey SECURITY_AUTHORIZATION_PERMISSION_UMASK =\n      new Builder(Name.SECURITY_AUTHORIZATION_PERMISSION_UMASK)\n          .setDefaultValue(\"022\")\n          .setDescription(\"The umask of creating file and directory. The initial creation \"\n              + \"permission is 777, and the difference between directory and file is 111. So \"\n              + \"for default umask value 022, the created directory has permission 755 and \"\n              + \"file has permission 644.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_AUTHORIZATION_PERMISSION_UMASK =\n      new Builder(Name.SECURITY_AUTHORIZATION_PERMISSION_UMASK)\n          .setDefaultValue(\"022\")\n          .setDescription(\"The umask of creating file and directory. The initial creation \"\n              + \"permission is 777, and the difference between directory and file is 111. So \"\n              + \"for default umask value 022, the created directory has permission 755 and \"\n              + \"file has permission 644.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SECURITY_AUTHORIZATION_PERMISSION_UMASK"}, {"original_string": "public static final PropertyKey SECURITY_GROUP_MAPPING_CACHE_TIMEOUT_MS =\n      new Builder(Name.SECURITY_GROUP_MAPPING_CACHE_TIMEOUT_MS)\n          .setAlias(\"alluxio.security.group.mapping.cache.timeout.ms\")\n          .setDefaultValue(\"1min\")\n          .setDescription(\"Time for cached group mapping to expire.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_GROUP_MAPPING_CACHE_TIMEOUT_MS =\n      new Builder(Name.SECURITY_GROUP_MAPPING_CACHE_TIMEOUT_MS)\n          .setAlias(\"alluxio.security.group.mapping.cache.timeout.ms\")\n          .setDefaultValue(\"1min\")\n          .setDescription(\"Time for cached group mapping to expire.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SECURITY_GROUP_MAPPING_CACHE_TIMEOUT_MS"}, {"original_string": "public static final PropertyKey SECURITY_GROUP_MAPPING_CLASS =\n      new Builder(Name.SECURITY_GROUP_MAPPING_CLASS)\n          .setDefaultValue(\"alluxio.security.group.provider.ShellBasedUnixGroupsMapping\")\n          .setDescription(\"The class to provide user-to-groups mapping service. Master could \"\n              + \"get the various group memberships of a given user.  It must implement the \"\n              + \"interface 'alluxio.security.group.GroupMappingService'. The default \"\n              + \"implementation execute the 'groups' shell command to fetch the group \"\n              + \"memberships of a given user.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_GROUP_MAPPING_CLASS =\n      new Builder(Name.SECURITY_GROUP_MAPPING_CLASS)\n          .setDefaultValue(\"alluxio.security.group.provider.ShellBasedUnixGroupsMapping\")\n          .setDescription(\"The class to provide user-to-groups mapping service. Master could \"\n              + \"get the various group memberships of a given user.  It must implement the \"\n              + \"interface 'alluxio.security.group.GroupMappingService'. The default \"\n              + \"implementation execute the 'groups' shell command to fetch the group \"\n              + \"memberships of a given user.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "SECURITY_GROUP_MAPPING_CLASS"}, {"original_string": "public static final PropertyKey SECURITY_LOGIN_IMPERSONATION_USERNAME =\n      new Builder(Name.SECURITY_LOGIN_IMPERSONATION_USERNAME).setDescription(String.format(\n          \"When %s is set to SIMPLE or CUSTOM, user application uses this property to indicate \"\n              + \"the IMPERSONATED user requesting Alluxio service. If it is not set explicitly, \"\n              + \"or set to %s, impersonation will not be used. A special value of '%s' can be \"\n              + \"specified to impersonate the hadoop client user.\", SECURITY_AUTHENTICATION_TYPE,\n          Constants.IMPERSONATION_NONE, Constants.IMPERSONATION_HDFS_USER))\n          .setDefaultValue(Constants.IMPERSONATION_HDFS_USER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_LOGIN_IMPERSONATION_USERNAME =\n      new Builder(Name.SECURITY_LOGIN_IMPERSONATION_USERNAME).setDescription(String.format(\n          \"When %s is set to SIMPLE or CUSTOM, user application uses this property to indicate \"\n              + \"the IMPERSONATED user requesting Alluxio service. If it is not set explicitly, \"\n              + \"or set to %s, impersonation will not be used. A special value of '%s' can be \"\n              + \"specified to impersonate the hadoop client user.\", SECURITY_AUTHENTICATION_TYPE,\n          Constants.IMPERSONATION_NONE, Constants.IMPERSONATION_HDFS_USER))\n          .setDefaultValue(Constants.IMPERSONATION_HDFS_USER)\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.IGNORE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "SECURITY_LOGIN_IMPERSONATION_USERNAME"}, {"original_string": "public static final PropertyKey SECURITY_LOGIN_USERNAME =\n      new Builder(Name.SECURITY_LOGIN_USERNAME)\n          .setDescription(\"When alluxio.security.authentication.type is set to SIMPLE or \"\n              + \"CUSTOM, user application uses this property to indicate the user requesting \"\n              + \"Alluxio service. If it is not set explicitly, the OS login user will be used.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.CLIENT)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "SECURITY_LOGIN_USERNAME =\n      new Builder(Name.SECURITY_LOGIN_USERNAME)\n          .setDescription(\"When alluxio.security.authentication.type is set to SIMPLE or \"\n              + \"CUSTOM, user application uses this property to indicate the user requesting \"\n              + \"Alluxio service. If it is not set explicitly, the OS login user will be used.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.ENFORCE)\n          .setScope(Scope.CLIENT)\n          .build()", "var_name": "SECURITY_LOGIN_USERNAME"}, {"original_string": "public static final PropertyKey AUTHENTICATION_INACTIVE_CHANNEL_REAUTHENTICATE_PERIOD =\n      new Builder(Name.AUTHENTICATION_INACTIVE_CHANNEL_REAUTHENTICATE_PERIOD)\n          .setDefaultValue(\"3day\")\n          .setDescription(\"Interval for which client channels that have been inactive \"\n                  + \"will be regarded as unauthenticated. Such channels will reauthenticate with \"\n                  + \"their target master upon being used for new RPCs.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "AUTHENTICATION_INACTIVE_CHANNEL_REAUTHENTICATE_PERIOD =\n      new Builder(Name.AUTHENTICATION_INACTIVE_CHANNEL_REAUTHENTICATE_PERIOD)\n          .setDefaultValue(\"3day\")\n          .setDescription(\"Interval for which client channels that have been inactive \"\n                  + \"will be regarded as unauthenticated. Such channels will reauthenticate with \"\n                  + \"their target master upon being used for new RPCs.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "AUTHENTICATION_INACTIVE_CHANNEL_REAUTHENTICATE_PERIOD"}, {"original_string": "public static final PropertyKey INTEGRATION_MASTER_RESOURCE_CPU =\n      new Builder(Name.INTEGRATION_MASTER_RESOURCE_CPU)\n          .setDefaultValue(1)\n          .setDescription(\"The number of CPUs to run an Alluxio master for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "INTEGRATION_MASTER_RESOURCE_CPU =\n      new Builder(Name.INTEGRATION_MASTER_RESOURCE_CPU)\n          .setDefaultValue(1)\n          .setDescription(\"The number of CPUs to run an Alluxio master for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "INTEGRATION_MASTER_RESOURCE_CPU"}, {"original_string": "public static final PropertyKey INTEGRATION_MASTER_RESOURCE_MEM =\n      new Builder(Name.INTEGRATION_MASTER_RESOURCE_MEM)\n          .setDefaultValue(\"1024MB\")\n          .setDescription(\"The amount of memory to run an Alluxio master for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "INTEGRATION_MASTER_RESOURCE_MEM =\n      new Builder(Name.INTEGRATION_MASTER_RESOURCE_MEM)\n          .setDefaultValue(\"1024MB\")\n          .setDescription(\"The amount of memory to run an Alluxio master for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "INTEGRATION_MASTER_RESOURCE_MEM"}, {"original_string": "public static final PropertyKey INTEGRATION_WORKER_RESOURCE_CPU =\n      new Builder(Name.INTEGRATION_WORKER_RESOURCE_CPU)\n          .setDefaultValue(1)\n          .setDescription(\"The number of CPUs to run an Alluxio worker for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "INTEGRATION_WORKER_RESOURCE_CPU =\n      new Builder(Name.INTEGRATION_WORKER_RESOURCE_CPU)\n          .setDefaultValue(1)\n          .setDescription(\"The number of CPUs to run an Alluxio worker for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "INTEGRATION_WORKER_RESOURCE_CPU"}, {"original_string": "public static final PropertyKey INTEGRATION_WORKER_RESOURCE_MEM =\n      new Builder(Name.INTEGRATION_WORKER_RESOURCE_MEM)\n          .setDefaultValue(\"1024MB\")\n          .setDescription(\"The amount of memory to run an Alluxio worker for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "INTEGRATION_WORKER_RESOURCE_MEM =\n      new Builder(Name.INTEGRATION_WORKER_RESOURCE_MEM)\n          .setDefaultValue(\"1024MB\")\n          .setDescription(\"The amount of memory to run an Alluxio worker for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "INTEGRATION_WORKER_RESOURCE_MEM"}, {"original_string": "public static final PropertyKey INTEGRATION_YARN_WORKERS_PER_HOST_MAX =\n      new Builder(Name.INTEGRATION_YARN_WORKERS_PER_HOST_MAX)\n          .setDefaultValue(1)\n          .setDescription(\"The number of workers to run on an Alluxio host for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "INTEGRATION_YARN_WORKERS_PER_HOST_MAX =\n      new Builder(Name.INTEGRATION_YARN_WORKERS_PER_HOST_MAX)\n          .setDefaultValue(1)\n          .setDescription(\"The number of workers to run on an Alluxio host for YARN framework.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.NONE)\n          .build()", "var_name": "INTEGRATION_YARN_WORKERS_PER_HOST_MAX"}, {"original_string": "public static final PropertyKey UNDERFS_VERSION =\n      new Builder(Name.UNDERFS_VERSION)\n          .setDefaultValue(\"3.3.0\")\n          .setIsHidden(true)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "UNDERFS_VERSION =\n      new Builder(Name.UNDERFS_VERSION)\n          .setDefaultValue(\"3.3.0\")\n          .setIsHidden(true)\n          .build()", "var_name": "UNDERFS_VERSION"}, {"original_string": "public static final PropertyKey JOB_MASTER_CLIENT_THREADS =\n      new Builder(Name.JOB_MASTER_CLIENT_THREADS)\n          .setDescription(\"The number of threads the Alluxio master uses to make requests to the \"\n              + \"job master.\")\n          .setDefaultValue(1024)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_CLIENT_THREADS =\n      new Builder(Name.JOB_MASTER_CLIENT_THREADS)\n          .setDescription(\"The number of threads the Alluxio master uses to make requests to the \"\n              + \"job master.\")\n          .setDefaultValue(1024)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_CLIENT_THREADS"}, {"original_string": "public static final PropertyKey JOB_MASTER_FINISHED_JOB_PURGE_COUNT =\n      new Builder(Name.JOB_MASTER_FINISHED_JOB_PURGE_COUNT)\n          .setDescription(\"The maximum amount of jobs to purge at any single time when the job \"\n              + \"master reaches its maximum capacity. It is recommended to set this value when \"\n              + \"setting the capacity of the job master to a large ( > 10M) value. Default is -1 \"\n              + \"denoting an unlimited value\")\n          .setDefaultValue(\"-1\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_FINISHED_JOB_PURGE_COUNT =\n      new Builder(Name.JOB_MASTER_FINISHED_JOB_PURGE_COUNT)\n          .setDescription(\"The maximum amount of jobs to purge at any single time when the job \"\n              + \"master reaches its maximum capacity. It is recommended to set this value when \"\n              + \"setting the capacity of the job master to a large ( > 10M) value. Default is -1 \"\n              + \"denoting an unlimited value\")\n          .setDefaultValue(\"-1\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_FINISHED_JOB_PURGE_COUNT"}, {"original_string": "public static final PropertyKey JOB_MASTER_FINISHED_JOB_RETENTION_TIME =\n      new Builder(Name.JOB_MASTER_FINISHED_JOB_RETENTION_TIME)\n          .setDescription(\"The length of time the Alluxio Job Master should save information about \"\n              + \"completed jobs before they are discarded.\")\n          .setDefaultValue(\"300sec\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_FINISHED_JOB_RETENTION_TIME =\n      new Builder(Name.JOB_MASTER_FINISHED_JOB_RETENTION_TIME)\n          .setDescription(\"The length of time the Alluxio Job Master should save information about \"\n              + \"completed jobs before they are discarded.\")\n          .setDefaultValue(\"300sec\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_FINISHED_JOB_RETENTION_TIME"}, {"original_string": "public static final PropertyKey JOB_MASTER_JOB_CAPACITY =\n      new Builder(Name.JOB_MASTER_JOB_CAPACITY)\n          .setDescription(\"The total possible number of available job statuses in the job master. \"\n              + \"This value includes running and finished jobs which are have completed within \"\n              + Name.JOB_MASTER_FINISHED_JOB_RETENTION_TIME + \".\")\n          .setDefaultValue(100000)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_JOB_CAPACITY =\n      new Builder(Name.JOB_MASTER_JOB_CAPACITY)\n          .setDescription(\"The total possible number of available job statuses in the job master. \"\n              + \"This value includes running and finished jobs which are have completed within \"\n              + Name.JOB_MASTER_FINISHED_JOB_RETENTION_TIME + \".\")\n          .setDefaultValue(100000)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_JOB_CAPACITY"}, {"original_string": "public static final PropertyKey JOB_MASTER_WORKER_HEARTBEAT_INTERVAL =\n      new Builder(Name.JOB_MASTER_WORKER_HEARTBEAT_INTERVAL)\n          .setDescription(\"The amount of time that the Alluxio job worker should wait in between \"\n              + \"heartbeats to the Job Master.\")\n          .setDefaultValue(\"1sec\")\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_WORKER_HEARTBEAT_INTERVAL =\n      new Builder(Name.JOB_MASTER_WORKER_HEARTBEAT_INTERVAL)\n          .setDescription(\"The amount of time that the Alluxio job worker should wait in between \"\n              + \"heartbeats to the Job Master.\")\n          .setDefaultValue(\"1sec\")\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_MASTER_WORKER_HEARTBEAT_INTERVAL"}, {"original_string": "public static final PropertyKey JOB_MASTER_WORKER_TIMEOUT =\n      new Builder(Name.JOB_MASTER_WORKER_TIMEOUT)\n          .setDescription(\"The time period after which the job master will mark a worker as lost \"\n              + \"without a subsequent heartbeat.\")\n          .setDefaultValue(\"60sec\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_WORKER_TIMEOUT =\n      new Builder(Name.JOB_MASTER_WORKER_TIMEOUT)\n          .setDescription(\"The time period after which the job master will mark a worker as lost \"\n              + \"without a subsequent heartbeat.\")\n          .setDefaultValue(\"60sec\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_WORKER_TIMEOUT"}, {"original_string": "public static final PropertyKey JOB_MASTER_BIND_HOST =\n      new Builder(Name.JOB_MASTER_BIND_HOST)\n          .setDescription(\"The host that the Alluxio job master will bind to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_BIND_HOST =\n      new Builder(Name.JOB_MASTER_BIND_HOST)\n          .setDescription(\"The host that the Alluxio job master will bind to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.ALL)\n          .build()", "var_name": "JOB_MASTER_BIND_HOST"}, {"original_string": "public static final PropertyKey JOB_MASTER_HOSTNAME =\n      new Builder(Name.JOB_MASTER_HOSTNAME)\n          .setDescription(\"The hostname of the Alluxio job master.\")\n          .setDefaultValue(String.format(\"${%s}\", Name.MASTER_HOSTNAME))\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_HOSTNAME =\n      new Builder(Name.JOB_MASTER_HOSTNAME)\n          .setDescription(\"The hostname of the Alluxio job master.\")\n          .setDefaultValue(String.format(\"${%s}\", Name.MASTER_HOSTNAME))\n          .setScope(Scope.ALL)\n          .build()", "var_name": "JOB_MASTER_HOSTNAME"}, {"original_string": "public static final PropertyKey JOB_MASTER_LOST_WORKER_INTERVAL =\n      new Builder(Name.JOB_MASTER_LOST_WORKER_INTERVAL)\n          .setDescription(\"The time interval the job master waits between checks for lost workers.\")\n          .setDefaultValue(\"1sec\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_LOST_WORKER_INTERVAL =\n      new Builder(Name.JOB_MASTER_LOST_WORKER_INTERVAL)\n          .setDescription(\"The time interval the job master waits between checks for lost workers.\")\n          .setDefaultValue(\"1sec\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_LOST_WORKER_INTERVAL"}, {"original_string": "public static final PropertyKey JOB_MASTER_RPC_PORT =\n      new Builder(Name.JOB_MASTER_RPC_PORT)\n          .setDescription(\"The port for Alluxio job master's RPC service.\")\n          .setDefaultValue(20001)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_RPC_PORT =\n      new Builder(Name.JOB_MASTER_RPC_PORT)\n          .setDescription(\"The port for Alluxio job master's RPC service.\")\n          .setDefaultValue(20001)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "JOB_MASTER_RPC_PORT"}, {"original_string": "public static final PropertyKey JOB_MASTER_WEB_BIND_HOST =\n      new Builder(Name.JOB_MASTER_WEB_BIND_HOST)\n          .setDescription(\"The host that the job master web server binds to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_WEB_BIND_HOST =\n      new Builder(Name.JOB_MASTER_WEB_BIND_HOST)\n          .setDescription(\"The host that the job master web server binds to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_WEB_BIND_HOST"}, {"original_string": "public static final PropertyKey JOB_MASTER_WEB_HOSTNAME =\n      new Builder(Name.JOB_MASTER_WEB_HOSTNAME)\n          .setDescription(\"The hostname of the job master web server.\")\n          .setDefaultValue(\"${alluxio.job.master.hostname}\")\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_WEB_HOSTNAME =\n      new Builder(Name.JOB_MASTER_WEB_HOSTNAME)\n          .setDescription(\"The hostname of the job master web server.\")\n          .setDefaultValue(\"${alluxio.job.master.hostname}\")\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_WEB_HOSTNAME"}, {"original_string": "public static final PropertyKey JOB_MASTER_WEB_PORT =\n      new Builder(Name.JOB_MASTER_WEB_PORT)\n          .setDescription(\"The port the job master web server uses.\")\n          .setDefaultValue(20002)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_WEB_PORT =\n      new Builder(Name.JOB_MASTER_WEB_PORT)\n          .setDescription(\"The port the job master web server uses.\")\n          .setDefaultValue(20002)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "JOB_MASTER_WEB_PORT"}, {"original_string": "public static final PropertyKey JOB_WORKER_BIND_HOST =\n      new Builder(Name.JOB_WORKER_BIND_HOST)\n          .setDescription(\"The host that the Alluxio job worker will bind to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_BIND_HOST =\n      new Builder(Name.JOB_WORKER_BIND_HOST)\n          .setDescription(\"The host that the Alluxio job worker will bind to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_BIND_HOST"}, {"original_string": "public static final PropertyKey JOB_WORKER_DATA_PORT =\n      new Builder(Name.JOB_WORKER_DATA_PORT)\n          .setDescription(\"The port the Alluxio Job worker uses to send data.\")\n          .setDefaultValue(30002)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_DATA_PORT =\n      new Builder(Name.JOB_WORKER_DATA_PORT)\n          .setDescription(\"The port the Alluxio Job worker uses to send data.\")\n          .setDefaultValue(30002)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_DATA_PORT"}, {"original_string": "public static final PropertyKey JOB_WORKER_HOSTNAME =\n      new Builder(Name.JOB_WORKER_HOSTNAME)\n          .setDescription(\"The hostname of the Alluxio job worker.\")\n          .setDefaultValue(String.format(\"${%s}\", Name.WORKER_HOSTNAME))\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_HOSTNAME =\n      new Builder(Name.JOB_WORKER_HOSTNAME)\n          .setDescription(\"The hostname of the Alluxio job worker.\")\n          .setDefaultValue(String.format(\"${%s}\", Name.WORKER_HOSTNAME))\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_HOSTNAME"}, {"original_string": "public static final PropertyKey JOB_WORKER_RPC_PORT =\n      new Builder(Name.JOB_WORKER_RPC_PORT)\n          .setDescription(\"The port for Alluxio job worker's RPC service.\")\n          .setDefaultValue(30001)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_RPC_PORT =\n      new Builder(Name.JOB_WORKER_RPC_PORT)\n          .setDescription(\"The port for Alluxio job worker's RPC service.\")\n          .setDefaultValue(30001)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_RPC_PORT"}, {"original_string": "public static final PropertyKey JOB_WORKER_THREADPOOL_SIZE =\n      new Builder(Name.JOB_WORKER_THREADPOOL_SIZE)\n          .setDescription(\"Number of threads in the thread pool for job worker. \"\n              + \"This may be adjusted to a lower value to alleviate resource \"\n              + \"saturation on the job worker nodes (CPU + IO).\")\n          .setDefaultValue(10)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_THREADPOOL_SIZE =\n      new Builder(Name.JOB_WORKER_THREADPOOL_SIZE)\n          .setDescription(\"Number of threads in the thread pool for job worker. \"\n              + \"This may be adjusted to a lower value to alleviate resource \"\n              + \"saturation on the job worker nodes (CPU + IO).\")\n          .setDefaultValue(10)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_THREADPOOL_SIZE"}, {"original_string": "public static final PropertyKey JOB_WORKER_THROTTLING =\n      new Builder(Name.JOB_WORKER_THROTTLING)\n          .setDescription(\"Whether the job worker should throttle itself based on whether the\"\n              + \"resources are saturated.\")\n          .setScope(Scope.WORKER)\n          .setDefaultValue(false)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_THROTTLING =\n      new Builder(Name.JOB_WORKER_THROTTLING)\n          .setDescription(\"Whether the job worker should throttle itself based on whether the\"\n              + \"resources are saturated.\")\n          .setScope(Scope.WORKER)\n          .setDefaultValue(false)\n          .build()", "var_name": "JOB_WORKER_THROTTLING"}, {"original_string": "public static final PropertyKey JOB_WORKER_WEB_BIND_HOST =\n      new Builder(Name.JOB_WORKER_WEB_BIND_HOST)\n          .setDescription(\"The host the job worker web server binds to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_WEB_BIND_HOST =\n      new Builder(Name.JOB_WORKER_WEB_BIND_HOST)\n          .setDescription(\"The host the job worker web server binds to.\")\n          .setDefaultValue(\"0.0.0.0\")\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_WEB_BIND_HOST"}, {"original_string": "public static final PropertyKey JOB_WORKER_WEB_PORT =\n      new Builder(Name.JOB_WORKER_WEB_PORT)\n          .setDescription(\"The port the Alluxio job worker web server uses.\")\n          .setDefaultValue(30003)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_WORKER_WEB_PORT =\n      new Builder(Name.JOB_WORKER_WEB_PORT)\n          .setDescription(\"The port the Alluxio job worker web server uses.\")\n          .setDefaultValue(30003)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "JOB_WORKER_WEB_PORT"}, {"original_string": "public static final PropertyKey JOB_MASTER_RPC_ADDRESSES =\n      new Builder(Name.JOB_MASTER_RPC_ADDRESSES)\n          .setDescription(String.format(\"The list of RPC addresses to use for the job service \"\n                  + \"configured in non-zookeeper HA mode. If this property is not specifically \"\n                  + \"defined, it will first fall back to using %s, replacing those address \"\n                  + \"ports with the port defined by %s. Otherwise the addresses are inherited from \"\n                  + \"%s using the port defined in %s\",\n              Name.MASTER_RPC_ADDRESSES, Name.JOB_MASTER_RPC_PORT,\n              Name.JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES, Name.JOB_MASTER_RPC_PORT))\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_RPC_ADDRESSES =\n      new Builder(Name.JOB_MASTER_RPC_ADDRESSES)\n          .setDescription(String.format(\"The list of RPC addresses to use for the job service \"\n                  + \"configured in non-zookeeper HA mode. If this property is not specifically \"\n                  + \"defined, it will first fall back to using %s, replacing those address \"\n                  + \"ports with the port defined by %s. Otherwise the addresses are inherited from \"\n                  + \"%s using the port defined in %s\",\n              Name.MASTER_RPC_ADDRESSES, Name.JOB_MASTER_RPC_PORT,\n              Name.JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES, Name.JOB_MASTER_RPC_PORT))\n          .setScope(Scope.ALL)\n          .build()", "var_name": "JOB_MASTER_RPC_ADDRESSES"}, {"original_string": "public static final PropertyKey JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES =\n      new Builder(Name.JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES)\n          .setDescription(String.format(\"A comma-separated list of journal addresses for all job \"\n              + \"masters in the cluster. The format is 'hostname1:port1,hostname2:port2,...'. \"\n              + \"Defaults to the journal addresses set for the Alluxio masters (%s), but with the \"\n              + \"job master embedded journal port.\", Name.MASTER_EMBEDDED_JOURNAL_ADDRESSES))\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES =\n      new Builder(Name.JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES)\n          .setDescription(String.format(\"A comma-separated list of journal addresses for all job \"\n              + \"masters in the cluster. The format is 'hostname1:port1,hostname2:port2,...'. \"\n              + \"Defaults to the journal addresses set for the Alluxio masters (%s), but with the \"\n              + \"job master embedded journal port.\", Name.MASTER_EMBEDDED_JOURNAL_ADDRESSES))\n          .setScope(Scope.ALL)\n          .build()", "var_name": "JOB_MASTER_EMBEDDED_JOURNAL_ADDRESSES"}, {"original_string": "public static final PropertyKey JOB_MASTER_EMBEDDED_JOURNAL_PORT =\n      new Builder(Name.JOB_MASTER_EMBEDDED_JOURNAL_PORT)\n          .setDescription(\n              \"The port to use for embedded journal communication with other job masters.\")\n          .setDefaultValue(20003)\n          .setScope(Scope.ALL)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JOB_MASTER_EMBEDDED_JOURNAL_PORT =\n      new Builder(Name.JOB_MASTER_EMBEDDED_JOURNAL_PORT)\n          .setDescription(\n              \"The port to use for embedded journal communication with other job masters.\")\n          .setDefaultValue(20003)\n          .setScope(Scope.ALL)\n          .build()", "var_name": "JOB_MASTER_EMBEDDED_JOURNAL_PORT"}, {"original_string": "public static final PropertyKey ZOOKEEPER_JOB_ELECTION_PATH =\n      new Builder(Name.ZOOKEEPER_JOB_ELECTION_PATH).setDefaultValue(\"/job_election\").build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_JOB_ELECTION_PATH =\n      new Builder(Name.ZOOKEEPER_JOB_ELECTION_PATH).setDefaultValue(\"/job_election\").build()", "var_name": "ZOOKEEPER_JOB_ELECTION_PATH"}, {"original_string": "public static final PropertyKey ZOOKEEPER_JOB_LEADER_PATH =\n      new Builder(Name.ZOOKEEPER_JOB_LEADER_PATH).setDefaultValue(\"/job_leader\").build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "ZOOKEEPER_JOB_LEADER_PATH =\n      new Builder(Name.ZOOKEEPER_JOB_LEADER_PATH).setDefaultValue(\"/job_leader\").build()", "var_name": "ZOOKEEPER_JOB_LEADER_PATH"}, {"original_string": "public static final PropertyKey JVM_MONITOR_WARN_THRESHOLD_MS =\n      new Builder(Name.JVM_MONITOR_WARN_THRESHOLD_MS)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"When the JVM pauses for anything longer than this, log a WARN message.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JVM_MONITOR_WARN_THRESHOLD_MS =\n      new Builder(Name.JVM_MONITOR_WARN_THRESHOLD_MS)\n          .setDefaultValue(\"10sec\")\n          .setDescription(\"When the JVM pauses for anything longer than this, log a WARN message.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "JVM_MONITOR_WARN_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey JVM_MONITOR_INFO_THRESHOLD_MS =\n      new Builder(Name.JVM_MONITOR_INFO_THRESHOLD_MS)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"When the JVM pauses for anything longer than this, log an INFO message.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JVM_MONITOR_INFO_THRESHOLD_MS =\n      new Builder(Name.JVM_MONITOR_INFO_THRESHOLD_MS)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"When the JVM pauses for anything longer than this, log an INFO message.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "JVM_MONITOR_INFO_THRESHOLD_MS"}, {"original_string": "public static final PropertyKey JVM_MONITOR_SLEEP_INTERVAL_MS =\n      new Builder(Name.JVM_MONITOR_SLEEP_INTERVAL_MS)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The time for the JVM monitor thread to sleep.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "JVM_MONITOR_SLEEP_INTERVAL_MS =\n      new Builder(Name.JVM_MONITOR_SLEEP_INTERVAL_MS)\n          .setDefaultValue(\"1sec\")\n          .setDescription(\"The time for the JVM monitor thread to sleep.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.SERVER)\n          .build()", "var_name": "JVM_MONITOR_SLEEP_INTERVAL_MS"}, {"original_string": "public static final PropertyKey MASTER_JVM_MONITOR_ENABLED =\n      new Builder(Name.MASTER_JVM_MONITOR_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to enable start JVM monitor thread on the master. This will \"\n              + \"start a thread to detect JVM-wide pauses induced by GC or other reasons.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "MASTER_JVM_MONITOR_ENABLED =\n      new Builder(Name.MASTER_JVM_MONITOR_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to enable start JVM monitor thread on the master. This will \"\n              + \"start a thread to detect JVM-wide pauses induced by GC or other reasons.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "MASTER_JVM_MONITOR_ENABLED"}, {"original_string": "public static final PropertyKey WORKER_JVM_MONITOR_ENABLED =\n      new Builder(Name.WORKER_JVM_MONITOR_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to enable start JVM monitor thread on the worker. This will \"\n              + \"start a thread to detect JVM-wide pauses induced by GC or other reasons.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "WORKER_JVM_MONITOR_ENABLED =\n      new Builder(Name.WORKER_JVM_MONITOR_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"Whether to enable start JVM monitor thread on the worker. This will \"\n              + \"start a thread to detect JVM-wide pauses induced by GC or other reasons.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.WORKER)\n          .build()", "var_name": "WORKER_JVM_MONITOR_ENABLED"}, {"original_string": "public static final PropertyKey TABLE_ENABLED =\n      new Builder(Name.TABLE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"(Experimental) Enables the table service.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TABLE_ENABLED =\n      new Builder(Name.TABLE_ENABLED)\n          .setDefaultValue(true)\n          .setDescription(\"(Experimental) Enables the table service.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "TABLE_ENABLED"}, {"original_string": "public static final PropertyKey TABLE_CATALOG_PATH =\n      new Builder(Name.TABLE_CATALOG_PATH)\n          .setDefaultValue(\"/catalog\")\n          .setDescription(\"The Alluxio file path for the table catalog metadata.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TABLE_CATALOG_PATH =\n      new Builder(Name.TABLE_CATALOG_PATH)\n          .setDefaultValue(\"/catalog\")\n          .setDescription(\"The Alluxio file path for the table catalog metadata.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "TABLE_CATALOG_PATH"}, {"original_string": "public static final PropertyKey TABLE_CATALOG_UDB_SYNC_TIMEOUT =\n      new Builder(Name.TABLE_CATALOG_UDB_SYNC_TIMEOUT)\n          .setDefaultValue(\"1h\")\n          .setDescription(\"The timeout period for a db sync to finish in the catalog. If a sync\"\n              + \"takes longer than this timeout, the sync will be terminated.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TABLE_CATALOG_UDB_SYNC_TIMEOUT =\n      new Builder(Name.TABLE_CATALOG_UDB_SYNC_TIMEOUT)\n          .setDefaultValue(\"1h\")\n          .setDescription(\"The timeout period for a db sync to finish in the catalog. If a sync\"\n              + \"takes longer than this timeout, the sync will be terminated.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "TABLE_CATALOG_UDB_SYNC_TIMEOUT"}, {"original_string": "public static final PropertyKey TABLE_TRANSFORM_MANAGER_JOB_MONITOR_INTERVAL =\n      new Builder(Name.TABLE_TRANSFORM_MANAGER_JOB_MONITOR_INTERVAL)\n          .setDefaultValue(10 * Constants.SECOND_MS)\n          .setDescription(\"Job monitor is a heartbeat thread in the transform manager, \"\n              + \"this is the time interval in milliseconds the job monitor heartbeat is run to \"\n              + \"check the status of the transformation jobs and update table and partition \"\n              + \"locations after transformation.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TABLE_TRANSFORM_MANAGER_JOB_MONITOR_INTERVAL =\n      new Builder(Name.TABLE_TRANSFORM_MANAGER_JOB_MONITOR_INTERVAL)\n          .setDefaultValue(10 * Constants.SECOND_MS)\n          .setDescription(\"Job monitor is a heartbeat thread in the transform manager, \"\n              + \"this is the time interval in milliseconds the job monitor heartbeat is run to \"\n              + \"check the status of the transformation jobs and update table and partition \"\n              + \"locations after transformation.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "TABLE_TRANSFORM_MANAGER_JOB_MONITOR_INTERVAL"}, {"original_string": "public static final PropertyKey TABLE_TRANSFORM_MANAGER_JOB_HISTORY_RETENTION_TIME =\n      new Builder(Name.TABLE_TRANSFORM_MANAGER_JOB_HISTORY_RETENTION_TIME)\n          .setDefaultValue(\"300sec\")\n          .setDescription(\"The length of time the Alluxio Table Master should keep information \"\n              + \"about finished transformation jobs before they are discarded.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build();", "modifier": "public static final", "type": "PropertyKey", "declarator": "TABLE_TRANSFORM_MANAGER_JOB_HISTORY_RETENTION_TIME =\n      new Builder(Name.TABLE_TRANSFORM_MANAGER_JOB_HISTORY_RETENTION_TIME)\n          .setDefaultValue(\"300sec\")\n          .setDescription(\"The length of time the Alluxio Table Master should keep information \"\n              + \"about finished transformation jobs before they are discarded.\")\n          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n          .setScope(Scope.MASTER)\n          .build()", "var_name": "TABLE_TRANSFORM_MANAGER_JOB_HISTORY_RETENTION_TIME"}, {"original_string": "@Deprecated(message = \"This key is used only for testing. It is always deprecated\")\n  public static final PropertyKey TEST_DEPRECATED_KEY =\n      new Builder(\"alluxio.test.deprecated.key\")\n          .build();", "modifier": "@Deprecated(message = \"This key is used only for testing. It is always deprecated\")\n  public static final", "type": "PropertyKey", "declarator": "TEST_DEPRECATED_KEY =\n      new Builder(\"alluxio.test.deprecated.key\")\n          .build()", "var_name": "TEST_DEPRECATED_KEY"}, {"original_string": "private static final String[] CUSTOM_CREDENTIAL_NAME_SUBSTR = new String[]{\n      \"accessKeyId\",\n      \"secretKey\"\n  };", "modifier": "private static final", "type": "String[]", "declarator": "CUSTOM_CREDENTIAL_NAME_SUBSTR = new String[]{\n      \"accessKeyId\",\n      \"secretKey\"\n  }", "var_name": "CUSTOM_CREDENTIAL_NAME_SUBSTR"}, {"original_string": "private final String mName;", "modifier": "private final", "type": "String", "declarator": "mName", "var_name": "mName"}, {"original_string": "private final String mDescription;", "modifier": "private final", "type": "String", "declarator": "mDescription", "var_name": "mDescription"}, {"original_string": "private final DefaultSupplier mDefaultSupplier;", "modifier": "private final", "type": "DefaultSupplier", "declarator": "mDefaultSupplier", "var_name": "mDefaultSupplier"}, {"original_string": "private final String[] mAliases;", "modifier": "private final", "type": "String[]", "declarator": "mAliases", "var_name": "mAliases"}, {"original_string": "private final boolean mIgnoredSiteProperty;", "modifier": "private final", "type": "boolean", "declarator": "mIgnoredSiteProperty", "var_name": "mIgnoredSiteProperty"}, {"original_string": "private final boolean mIsBuiltIn;", "modifier": "private final", "type": "boolean", "declarator": "mIsBuiltIn", "var_name": "mIsBuiltIn"}, {"original_string": "private final boolean mIsHidden;", "modifier": "private final", "type": "boolean", "declarator": "mIsHidden", "var_name": "mIsHidden"}, {"original_string": "private final ConsistencyCheckLevel mConsistencyCheckLevel;", "modifier": "private final", "type": "ConsistencyCheckLevel", "declarator": "mConsistencyCheckLevel", "var_name": "mConsistencyCheckLevel"}, {"original_string": "private final Scope mScope;", "modifier": "private final", "type": "Scope", "declarator": "mScope", "var_name": "mScope"}, {"original_string": "private final DisplayType mDisplayType;", "modifier": "private final", "type": "DisplayType", "declarator": "mDisplayType", "var_name": "mDisplayType"}, {"original_string": "private static final DeprecatedKeyChecker DEPRECATED_CHECKER = new DeprecatedKeyChecker();", "modifier": "private static final", "type": "DeprecatedKeyChecker", "declarator": "DEPRECATED_CHECKER = new DeprecatedKeyChecker()", "var_name": "DEPRECATED_CHECKER"}], "methods": [{"identifier": "javadocLink", "parameters": "(String fullyQualifiedClassname)", "modifiers": "private static", "return": "String", "signature": "String javadocLink(String fullyQualifiedClassname)", "full_signature": "private static String javadocLink(String fullyQualifiedClassname)", "class_method_signature": "PropertyKey.javadocLink(String fullyQualifiedClassname)", "testcase": false, "constructor": false}, {"identifier": "isValid", "parameters": "(String input)", "modifiers": "public static", "return": "boolean", "signature": "boolean isValid(String input)", "full_signature": "public static boolean isValid(String input)", "class_method_signature": "PropertyKey.isValid(String input)", "testcase": false, "constructor": false}, {"identifier": "fromString", "parameters": "(String input)", "modifiers": "public static", "return": "PropertyKey", "signature": "PropertyKey fromString(String input)", "full_signature": "public static PropertyKey fromString(String input)", "class_method_signature": "PropertyKey.fromString(String input)", "testcase": false, "constructor": false}, {"identifier": "defaultKeys", "parameters": "()", "modifiers": "public static", "return": "Collection<? extends PropertyKey>", "signature": "Collection<? extends PropertyKey> defaultKeys()", "full_signature": "public static Collection<? extends PropertyKey> defaultKeys()", "class_method_signature": "PropertyKey.defaultKeys()", "testcase": false, "constructor": false}, {"identifier": "PropertyKey", "parameters": "(String name, String description, DefaultSupplier defaultSupplier,\n      String[] aliases, boolean ignoredSiteProperty, boolean isHidden,\n      ConsistencyCheckLevel consistencyCheckLevel, Scope scope, DisplayType displayType,\n      boolean isBuiltIn)", "modifiers": "private", "return": "", "signature": " PropertyKey(String name, String description, DefaultSupplier defaultSupplier,\n      String[] aliases, boolean ignoredSiteProperty, boolean isHidden,\n      ConsistencyCheckLevel consistencyCheckLevel, Scope scope, DisplayType displayType,\n      boolean isBuiltIn)", "full_signature": "private  PropertyKey(String name, String description, DefaultSupplier defaultSupplier,\n      String[] aliases, boolean ignoredSiteProperty, boolean isHidden,\n      ConsistencyCheckLevel consistencyCheckLevel, Scope scope, DisplayType displayType,\n      boolean isBuiltIn)", "class_method_signature": "PropertyKey.PropertyKey(String name, String description, DefaultSupplier defaultSupplier,\n      String[] aliases, boolean ignoredSiteProperty, boolean isHidden,\n      ConsistencyCheckLevel consistencyCheckLevel, Scope scope, DisplayType displayType,\n      boolean isBuiltIn)", "testcase": false, "constructor": true}, {"identifier": "PropertyKey", "parameters": "(String name)", "modifiers": "private", "return": "", "signature": " PropertyKey(String name)", "full_signature": "private  PropertyKey(String name)", "class_method_signature": "PropertyKey.PropertyKey(String name)", "testcase": false, "constructor": true}, {"identifier": "register", "parameters": "(PropertyKey key)", "modifiers": "@VisibleForTesting public static", "return": "boolean", "signature": "boolean register(PropertyKey key)", "full_signature": "@VisibleForTesting public static boolean register(PropertyKey key)", "class_method_signature": "PropertyKey.register(PropertyKey key)", "testcase": false, "constructor": false}, {"identifier": "unregister", "parameters": "(PropertyKey key)", "modifiers": "@VisibleForTesting public static", "return": "void", "signature": "void unregister(PropertyKey key)", "full_signature": "@VisibleForTesting public static void unregister(PropertyKey key)", "class_method_signature": "PropertyKey.unregister(PropertyKey key)", "testcase": false, "constructor": false}, {"identifier": "getOrBuildCustom", "parameters": "(String name)", "modifiers": "public static", "return": "PropertyKey", "signature": "PropertyKey getOrBuildCustom(String name)", "full_signature": "public static PropertyKey getOrBuildCustom(String name)", "class_method_signature": "PropertyKey.getOrBuildCustom(String name)", "testcase": false, "constructor": false}, {"identifier": "equals", "parameters": "(Object o)", "modifiers": "@Override public", "return": "boolean", "signature": "boolean equals(Object o)", "full_signature": "@Override public boolean equals(Object o)", "class_method_signature": "PropertyKey.equals(Object o)", "testcase": false, "constructor": false}, {"identifier": "hashCode", "parameters": "()", "modifiers": "@Override public", "return": "int", "signature": "int hashCode()", "full_signature": "@Override public int hashCode()", "class_method_signature": "PropertyKey.hashCode()", "testcase": false, "constructor": false}, {"identifier": "toString", "parameters": "()", "modifiers": "@Override public", "return": "String", "signature": "String toString()", "full_signature": "@Override public String toString()", "class_method_signature": "PropertyKey.toString()", "testcase": false, "constructor": false}, {"identifier": "compareTo", "parameters": "(PropertyKey o)", "modifiers": "@Override public", "return": "int", "signature": "int compareTo(PropertyKey o)", "full_signature": "@Override public int compareTo(PropertyKey o)", "class_method_signature": "PropertyKey.compareTo(PropertyKey o)", "testcase": false, "constructor": false}, {"identifier": "length", "parameters": "()", "modifiers": "public", "return": "int", "signature": "int length()", "full_signature": "public int length()", "class_method_signature": "PropertyKey.length()", "testcase": false, "constructor": false}, {"identifier": "isNested", "parameters": "(String key)", "modifiers": "public", "return": "boolean", "signature": "boolean isNested(String key)", "full_signature": "public boolean isNested(String key)", "class_method_signature": "PropertyKey.isNested(String key)", "testcase": false, "constructor": false}, {"identifier": "getName", "parameters": "()", "modifiers": "public", "return": "String", "signature": "String getName()", "full_signature": "public String getName()", "class_method_signature": "PropertyKey.getName()", "testcase": false, "constructor": false}, {"identifier": "getAliases", "parameters": "()", "modifiers": "public", "return": "String[]", "signature": "String[] getAliases()", "full_signature": "public String[] getAliases()", "class_method_signature": "PropertyKey.getAliases()", "testcase": false, "constructor": false}, {"identifier": "getDescription", "parameters": "()", "modifiers": "public", "return": "String", "signature": "String getDescription()", "full_signature": "public String getDescription()", "class_method_signature": "PropertyKey.getDescription()", "testcase": false, "constructor": false}, {"identifier": "getDefaultValue", "parameters": "()", "modifiers": "@Nullable public", "return": "String", "signature": "String getDefaultValue()", "full_signature": "@Nullable public String getDefaultValue()", "class_method_signature": "PropertyKey.getDefaultValue()", "testcase": false, "constructor": false}, {"identifier": "getDefaultSupplier", "parameters": "()", "modifiers": "public", "return": "DefaultSupplier", "signature": "DefaultSupplier getDefaultSupplier()", "full_signature": "public DefaultSupplier getDefaultSupplier()", "class_method_signature": "PropertyKey.getDefaultSupplier()", "testcase": false, "constructor": false}, {"identifier": "isIgnoredSiteProperty", "parameters": "()", "modifiers": "public", "return": "boolean", "signature": "boolean isIgnoredSiteProperty()", "full_signature": "public boolean isIgnoredSiteProperty()", "class_method_signature": "PropertyKey.isIgnoredSiteProperty()", "testcase": false, "constructor": false}, {"identifier": "isBuiltIn", "parameters": "()", "modifiers": "public", "return": "boolean", "signature": "boolean isBuiltIn()", "full_signature": "public boolean isBuiltIn()", "class_method_signature": "PropertyKey.isBuiltIn()", "testcase": false, "constructor": false}, {"identifier": "isHidden", "parameters": "()", "modifiers": "public", "return": "boolean", "signature": "boolean isHidden()", "full_signature": "public boolean isHidden()", "class_method_signature": "PropertyKey.isHidden()", "testcase": false, "constructor": false}, {"identifier": "getConsistencyLevel", "parameters": "()", "modifiers": "public", "return": "ConsistencyCheckLevel", "signature": "ConsistencyCheckLevel getConsistencyLevel()", "full_signature": "public ConsistencyCheckLevel getConsistencyLevel()", "class_method_signature": "PropertyKey.getConsistencyLevel()", "testcase": false, "constructor": false}, {"identifier": "getScope", "parameters": "()", "modifiers": "public", "return": "Scope", "signature": "Scope getScope()", "full_signature": "public Scope getScope()", "class_method_signature": "PropertyKey.getScope()", "testcase": false, "constructor": false}, {"identifier": "getDisplayType", "parameters": "()", "modifiers": "public", "return": "DisplayType", "signature": "DisplayType getDisplayType()", "full_signature": "public DisplayType getDisplayType()", "class_method_signature": "PropertyKey.getDisplayType()", "testcase": false, "constructor": false}, {"identifier": "isDeprecated", "parameters": "(PropertyKey key)", "modifiers": "public static", "return": "boolean", "signature": "boolean isDeprecated(PropertyKey key)", "full_signature": "public static boolean isDeprecated(PropertyKey key)", "class_method_signature": "PropertyKey.isDeprecated(PropertyKey key)", "testcase": false, "constructor": false}, {"identifier": "isDeprecated", "parameters": "(String name)", "modifiers": "public static", "return": "boolean", "signature": "boolean isDeprecated(String name)", "full_signature": "public static boolean isDeprecated(String name)", "class_method_signature": "PropertyKey.isDeprecated(String name)", "testcase": false, "constructor": false}, {"identifier": "isRemoved", "parameters": "(String key)", "modifiers": "public static", "return": "boolean", "signature": "boolean isRemoved(String key)", "full_signature": "public static boolean isRemoved(String key)", "class_method_signature": "PropertyKey.isRemoved(String key)", "testcase": false, "constructor": false}, {"identifier": "getDeprecationMessage", "parameters": "(PropertyKey key)", "modifiers": "public static", "return": "String", "signature": "String getDeprecationMessage(PropertyKey key)", "full_signature": "public static String getDeprecationMessage(PropertyKey key)", "class_method_signature": "PropertyKey.getDeprecationMessage(PropertyKey key)", "testcase": false, "constructor": false}, {"identifier": "getRemovalMessage", "parameters": "(String key)", "modifiers": "public static", "return": "String", "signature": "String getRemovalMessage(String key)", "full_signature": "public static String getRemovalMessage(String key)", "class_method_signature": "PropertyKey.getRemovalMessage(String key)", "testcase": false, "constructor": false}], "file": "core/common/src/main/java/alluxio/conf/PropertyKey.java"}, "focal_method": {"identifier": "isValid", "parameters": "(String input)", "modifiers": "public static", "return": "boolean", "body": "public static boolean isValid(String input) {\n    // Check if input matches any default keys or aliases\n    if (DEFAULT_KEYS_MAP.containsKey(input) || DEFAULT_ALIAS_MAP.containsKey(input)) {\n      return true;\n    }\n    // Regex matching for templates can be expensive when checking properties frequently.\n    // Use a cache to store regexp matching results to reduce CPU overhead.\n    Boolean result = REGEXP_CACHE.getIfPresent(input);\n    if (result != null) {\n      return result;\n    }\n    // Check if input matches any parameterized keys\n    result = false;\n    for (Template template : Template.values()) {\n      if (template.matches(input)) {\n        result = true;\n        break;\n      }\n    }\n    REGEXP_CACHE.put(input, result);\n    return result;\n  }", "signature": "boolean isValid(String input)", "full_signature": "public static boolean isValid(String input)", "class_method_signature": "PropertyKey.isValid(String input)", "testcase": false, "constructor": false, "invocations": ["containsKey", "containsKey", "getIfPresent", "values", "matches", "put"]}, "repository": {"repo_id": 7276954, "url": "https://github.com/Alluxio/alluxio", "stars": 4494, "created": "12/21/2012 5:43:46 PM +00:00", "updates": "2020-01-24T20:27:46+00:00", "fork": "False", "license": "licensed"}}