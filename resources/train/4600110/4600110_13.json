{"test_class": {"identifier": "FsCrawlerCliTest", "superclass": "extends AbstractFSCrawlerTestCase", "interfaces": "", "fields": [{"original_string": "private static Path metadataDir;", "modifier": "private static", "type": "Path", "declarator": "metadataDir", "var_name": "metadataDir"}], "file": "cli/src/test/java/fr/pilato/elasticsearch/crawler/fs/cli/FsCrawlerCliTest.java"}, "test_case": {"identifier": "testRestartCommand", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testRestartCommand() throws Exception {\n        String jobName = \"fscrawler_restart_command\";\n\n        // We generate a fake status first in metadata dir\n        FsSettingsFileHandler fsSettingsFileHandler = new FsSettingsFileHandler(metadataDir);\n        FsJobFileHandler fsJobFileHandler = new FsJobFileHandler(metadataDir);\n\n        Path jobDir = metadataDir.resolve(jobName);\n        Files.createDirectories(jobDir);\n\n\n        fsSettingsFileHandler.write(FsSettings.builder(jobName).build());\n        fsJobFileHandler.write(jobName, FsJob.builder().build());\n\n        assertThat(Files.exists(jobDir.resolve(FsJobFileHandler.FILENAME)), is(true));\n\n        String[] args = { \"--config_dir\", metadataDir.toString(), \"--loop\", \"0\", \"--restart\", jobName };\n\n        FsCrawlerCli.main(args);\n\n        assertThat(Files.exists(jobDir.resolve(FsJobFileHandler.FILENAME)), is(false));\n    }", "signature": "void testRestartCommand()", "full_signature": "@Test public void testRestartCommand()", "class_method_signature": "FsCrawlerCliTest.testRestartCommand()", "testcase": true, "constructor": false, "invocations": ["resolve", "createDirectories", "write", "build", "builder", "write", "build", "builder", "assertThat", "exists", "resolve", "is", "toString", "main", "assertThat", "exists", "resolve", "is"]}, "focal_class": {"identifier": "FsCrawlerCli", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final long CLOSE_POLLING_WAIT_MS = 100;", "modifier": "private static final", "type": "long", "declarator": "CLOSE_POLLING_WAIT_MS = 100", "var_name": "CLOSE_POLLING_WAIT_MS"}, {"original_string": "private static final Logger logger = LogManager.getLogger(FsCrawlerCli.class);", "modifier": "private static final", "type": "Logger", "declarator": "logger = LogManager.getLogger(FsCrawlerCli.class)", "var_name": "logger"}], "methods": [{"identifier": "main", "parameters": "(String[] args)", "modifiers": "@SuppressWarnings(\"deprecation\") public static", "return": "void", "signature": "void main(String[] args)", "full_signature": "@SuppressWarnings(\"deprecation\") public static void main(String[] args)", "class_method_signature": "FsCrawlerCli.main(String[] args)", "testcase": false, "constructor": false}, {"identifier": "checkForDeprecatedResources", "parameters": "(Path configDir, String elasticsearchVersion)", "modifiers": "private static", "return": "void", "signature": "void checkForDeprecatedResources(Path configDir, String elasticsearchVersion)", "full_signature": "private static void checkForDeprecatedResources(Path configDir, String elasticsearchVersion)", "class_method_signature": "FsCrawlerCli.checkForDeprecatedResources(Path configDir, String elasticsearchVersion)", "testcase": false, "constructor": false}, {"identifier": "sleep", "parameters": "()", "modifiers": "private static", "return": "void", "signature": "void sleep()", "full_signature": "private static void sleep()", "class_method_signature": "FsCrawlerCli.sleep()", "testcase": false, "constructor": false}], "file": "cli/src/main/java/fr/pilato/elasticsearch/crawler/fs/cli/FsCrawlerCli.java"}, "focal_method": {"identifier": "main", "parameters": "(String[] args)", "modifiers": "@SuppressWarnings(\"deprecation\") public static", "return": "void", "body": "@SuppressWarnings(\"deprecation\")\n    public static void main(String[] args) throws Exception {\n        // create a scanner so we can read the command-line input\n        Scanner scanner = new Scanner(System.in);\n\n        FsCrawlerCommand commands = new FsCrawlerCommand();\n        JCommander jCommander = new JCommander(commands);\n        jCommander.parse(args);\n\n        // Change debug level if needed\n        if (commands.debug || commands.trace || commands.silent) {\n            LoggerContext ctx = (LoggerContext) LogManager.getContext(false);\n            Configuration config = ctx.getConfiguration();\n            LoggerConfig loggerConfig = config.getLoggerConfig(FsCrawlerCli.class.getPackage().getName());\n\n            if (commands.silent) {\n                // Check if the user also asked for --debug or --trace which is contradictory\n                if (commands.debug || commands.trace) {\n                    logger.warn(\"--debug or --trace can't be used when --silent is set. Only silent mode will be activated.\");\n                }\n                // If the user did not enter any job name, nothing will be displayed\n                if (commands.jobName == null) {\n                    logger.warn(\"--silent is set but no job has been defined. Add a job name or remove --silent option. Exiting.\");\n                    jCommander.usage();\n                    return;\n                }\n                // We change the full rootLogger level\n                LoggerConfig rootLogger = config.getLoggerConfig(LogManager.ROOT_LOGGER_NAME);\n                loggerConfig.setLevel(Level.OFF);\n                rootLogger.setLevel(Level.OFF);\n            } else {\n                loggerConfig.setLevel(commands.debug ? Level.DEBUG : Level.TRACE);\n            }\n            ctx.updateLoggers();\n        }\n\n        if (commands.help) {\n            jCommander.usage();\n            return;\n        }\n\n        BootstrapChecks.check();\n\n        Path configDir;\n\n        if (commands.configDir == null) {\n            configDir = MetaFileHandler.DEFAULT_ROOT;\n        } else {\n            configDir = Paths.get(commands.configDir);\n        }\n\n        // Create the config dir if needed\n        FsCrawlerUtil.createDirIfMissing(configDir);\n\n        // We copy default mapping and settings to the default settings dir .fscrawler/_default/\n        copyDefaultResources(configDir);\n\n        FsSettings fsSettings;\n        FsSettingsFileHandler fsSettingsFileHandler = new FsSettingsFileHandler(configDir);\n\n        String jobName;\n\n        if (commands.jobName == null) {\n            // The user did not enter a job name.\n            // We can list available jobs for him\n            logger.info(\"No job specified. Here is the list of existing jobs:\");\n\n            List<String> files = FsCrawlerJobsUtil.listExistingJobs(configDir);\n\n            if (!files.isEmpty()) {\n                for (int i = 0; i < files.size(); i++) {\n                    logger.info(\"[{}] - {}\", i+1, files.get(i));\n                }\n                int chosenFile = 0;\n                while (chosenFile <= 0 || chosenFile > files.size()) {\n                    logger.info(\"Choose your job [1-{}]...\", files.size());\n                    chosenFile = scanner.nextInt();\n                }\n                jobName = files.get(chosenFile - 1);\n            } else {\n                logger.info(\"No job exists in [{}].\", configDir);\n                logger.info(\"To create your first job, run 'fscrawler job_name' with 'job_name' you want\");\n                return;\n            }\n\n        } else {\n            jobName = commands.jobName.get(0);\n        }\n\n        // If we ask to reinit, we need to clean the status for the job\n        if (commands.restart) {\n            logger.debug(\"Cleaning existing status for job [{}]...\", jobName);\n            new FsJobFileHandler(configDir).clean(jobName);\n        }\n\n        try {\n            logger.debug(\"Starting job [{}]...\", jobName);\n            fsSettings = fsSettingsFileHandler.read(jobName);\n\n            // Check default settings\n            if (fsSettings.getFs() == null) {\n                fsSettings.setFs(Fs.DEFAULT);\n            }\n            if (fsSettings.getElasticsearch() == null) {\n                fsSettings.setElasticsearch(Elasticsearch.DEFAULT());\n            }\n\n            String username = commands.username;\n            if (fsSettings.getElasticsearch().getUsername() != null) {\n                username = fsSettings.getElasticsearch().getUsername();\n            }\n\n            if (username != null && fsSettings.getElasticsearch().getPassword() == null) {\n                logger.info(\"Password for \" +  username + \":\");\n                String password = scanner.next();\n                fsSettings.getElasticsearch().setUsername(username);\n                fsSettings.getElasticsearch().setPassword(password);\n            }\n\n        } catch (NoSuchFileException e) {\n            logger.warn(\"job [{}] does not exist\", jobName);\n\n            String yesno = null;\n            while (!\"y\".equalsIgnoreCase(yesno) && !\"n\".equalsIgnoreCase(yesno)) {\n                logger.info(\"Do you want to create it (Y/N)?\");\n                yesno = scanner.next();\n            }\n\n            if (\"y\".equalsIgnoreCase(yesno)) {\n                fsSettings = FsSettings.builder(commands.jobName.get(0))\n                        .setFs(Fs.DEFAULT)\n                        .setElasticsearch(Elasticsearch.DEFAULT())\n                        .build();\n                fsSettingsFileHandler.write(fsSettings);\n\n                Path config = configDir.resolve(jobName).resolve(FsSettingsFileHandler.SETTINGS_YAML);\n                logger.info(\"Settings have been created in [{}]. Please review and edit before relaunch\", config);\n            }\n\n            return;\n        }\n\n        logger.trace(\"settings used for this crawler: [{}]\", FsSettingsParser.toYaml(fsSettings));\n        if (FsCrawlerValidator.validateSettings(logger, fsSettings, commands.rest)) {\n            // We don't go further as we have critical errors\n            return;\n        }\n\n        FsCrawlerImpl fsCrawler = new FsCrawlerImpl(configDir, fsSettings, commands.loop, commands.rest);\n        Runtime.getRuntime().addShutdownHook(new FSCrawlerShutdownHook(fsCrawler));\n\n        try {\n            // Let see if we want to upgrade an existing cluster to latest version\n            if (commands.upgrade) {\n                logger.info(\"Upgrading job [{}]. No rule implemented. Skipping.\", jobName);\n            } else {\n                try {\n                    fsCrawler.getEsClient().start();\n                } catch (Exception t) {\n                    logger.fatal(\"We can not start Elasticsearch Client. Exiting.\", t);\n                    return;\n                }\n                String elasticsearchVersion = fsCrawler.getEsClient().getVersion();\n                checkForDeprecatedResources(configDir, elasticsearchVersion);\n                fsCrawler.start();\n\n                // Start the REST Server if needed\n                if (commands.rest) {\n                    RestServer.start(fsSettings, fsCrawler.getEsClient());\n                }\n\n                // We just have to wait until the process is stopped\n                while (!fsCrawler.getFsParser().isClosed()) {\n                    sleep();\n                }\n            }\n        } catch (Exception e) {\n            logger.fatal(\"Fatal error received while running the crawler: [{}]\", e.getMessage());\n            logger.debug(\"error caught\", e);\n        } finally {\n            fsCrawler.close();\n        }\n    }", "signature": "void main(String[] args)", "full_signature": "@SuppressWarnings(\"deprecation\") public static void main(String[] args)", "class_method_signature": "FsCrawlerCli.main(String[] args)", "testcase": false, "constructor": false, "invocations": ["parse", "getContext", "getConfiguration", "getLoggerConfig", "getName", "getPackage", "warn", "warn", "usage", "getLoggerConfig", "setLevel", "setLevel", "setLevel", "updateLoggers", "usage", "check", "get", "createDirIfMissing", "copyDefaultResources", "info", "listExistingJobs", "isEmpty", "size", "info", "get", "size", "info", "size", "nextInt", "get", "info", "info", "get", "debug", "clean", "debug", "read", "getFs", "setFs", "getElasticsearch", "setElasticsearch", "DEFAULT", "getUsername", "getElasticsearch", "getUsername", "getElasticsearch", "getPassword", "getElasticsearch", "info", "next", "setUsername", "getElasticsearch", "setPassword", "getElasticsearch", "warn", "equalsIgnoreCase", "equalsIgnoreCase", "info", "next", "equalsIgnoreCase", "build", "setElasticsearch", "setFs", "builder", "get", "DEFAULT", "write", "resolve", "resolve", "info", "trace", "toYaml", "validateSettings", "addShutdownHook", "getRuntime", "info", "start", "getEsClient", "fatal", "getVersion", "getEsClient", "checkForDeprecatedResources", "start", "start", "getEsClient", "isClosed", "getFsParser", "sleep", "fatal", "getMessage", "debug", "close"]}, "repository": {"repo_id": 4600110, "url": "https://github.com/dadoonet/fscrawler", "stars": 716, "created": "6/8/2012 5:23:03 PM +00:00", "updates": "2020-01-25T22:05:52+00:00", "fork": "False", "license": "licensed"}}